[{"path":"/articles/metapsyTools.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"metapsyTools","text":"metapsyTools package part Metapsy project. Functions included package can used run meta-analyses Metapsy databases, databases adhere data standard, “box” using R. package also contains set tools can used prepare meta-analytic data sets based Metapsy data standard, calculate effect sizes (Hedges’ \\(g\\) risk ratios, \\(RR\\)). package consists two modules: module check data format calculate effect sizes possible study comparisons (preparation module); module select relevant comparisons specific meta-analysis, calculate results (including subgroup, meta-regression, publication bias analyses), generate tables (analysis module). idea use two modules different contexts. example, preparation module can used every time database updated gather information, calculate effect sizes, bring data format suitable analyses. Prepared data sets follow Metapsy data standard build basis analysis module. Researchers simply filter comparisons relevant investigation, can use functions package run full meta-analysis, including sensitivity subgroup analyses.   Important: preparation module requires familiarity general structure database, well intermediate-level knowledge R metapsyTools package , order diagnose (potential) issues. advise preparation step (.e. checking data format calculating effect sizes time database updated) conducted person proficiency R & data wrangling. analysis module, hand, usable researchers.  companion package metapsyTools metapsyData (data.metapsy.org). Using metapsyData, meta-analytic databases can automatically downloaded R environment. Databases retrieved using metapsyData can directly analyzed using metapsyTools. -depth introduction metapsyTools package, please visit Get Started page online.","code":""},{"path":"/articles/web/get-started.html","id":"introduction","dir":"Articles > Web","previous_headings":"","what":"Introduction","title":"Get Started","text":"metapsyTools package part Metapsy project. Functions included package can used run meta-analyses Metapsy databases, databases adhere data standard, “box” using R. package also contains set tools can used prepare meta-analytic data sets based Metapsy data standard, calculate effect sizes (Hedges’ \\(g\\) risk ratios, \\(RR\\)). package consists two modules: module check data format calculate effect sizes possible study comparisons (preparation module); module select relevant comparisons specific meta-analysis, calculate results (including subgroup, meta-regression, publication bias analyses), generate tables (analysis module). idea use two modules different contexts. example, preparation module can used every time database updated gather information, calculate effect sizes, bring data format suitable analyses. Prepared data sets follow Metapsy data standard build basis analysis module. Researchers simply filter comparisons relevant investigation, can use functions package run full meta-analysis, including sensitivity subgroup analyses.   Important: preparation module requires familiarity general structure database, well intermediate-level knowledge R metapsyTools package , order diagnose (potential) issues. advise preparation step (.e. checking data format calculating effect sizes time database updated) conducted person proficiency R & data wrangling. analysis module, hand, usable researchers.  companion package metapsyTools metapsyData. Using metapsyData, meta-analytic databases can automatically downloaded R environment. Databases retrieved using metapsyData can directly analyzed using metapsyTools. goal analyze existing databases included Metapsy, analysis module metapsyTools relevant . Click navigate directly analysis module section.","code":""},{"path":"/articles/web/get-started.html","id":"the-preparation-module","dir":"Articles > Web","previous_headings":"","what":"The Preparation Module","title":"Get Started","text":"preparation module metapsyTools allows : check classes variables imported data set required, using checkDataFormat function. check formatting conflicts resolved prior steps, using checkConflicts function. calculate Hedges’ \\(g\\) /risk ratios (\\(RR\\)) comparison, provided suitable data available, generate data set ready meta-analyses, using calculateEffectSizes function.","code":""},{"path":"/articles/web/get-started.html","id":"required-data-structure","dir":"Articles > Web","previous_headings":"The Preparation Module","what":"Required Data Structure","title":"Get Started","text":"convenience, highly advised strictly follow data formatting rules prior importing data set effect size calculations. rules followed closely, minimizes risk receiving error messages, producing conflicts, etc. detailed description preferred data structure can found Metapsy documentation. metapsyTools package also includes “toy” data set called depressionPsyCtr, already pre-formatted follow required data format. use data preparation module (.e. calculate effect sizes), study design () effect size data variables (II) must included data set.","code":""},{"path":"/articles/web/get-started.html","id":"study-design-variables-i","dir":"Articles > Web","previous_headings":"The Preparation Module > Required Data Structure","what":"Study Design Variables (I)","title":"Get Started","text":"study: study name, formatted “last name first author”, “year” (e.g. \"Smith, 2011\"). condition_arm1: Condition first trial arm. condition name standardized ensure comparability across trials (e.g. cbt trial arms employed cognitive-behavioral psychotherapy). condition_arm2: Condition second trial arm. condition name standardized ensure comparability across trials (e.g. wlc trial arms employed waitlist control group). multi_arm1: multiarm trials, variable provides “specification” type treatment used first arm. variable set NA (missing) study multiarm trial. example, multiarm trial employed two types CBT interventions, face--face Internet-based, variable set f2f Internet, respectively. multi_arm2: multiarm trials, variable provides “specification” type treatment used second arm. variable set NA (missing) study multiarm trial. example, multiarm trial employed two types control groups, waitlist placebo, variable set wl plac, respectively. outcome_type: variable encodes type outcome builds basis comparison, e.g. \"response\", \"remission\" \"deterioration\". variable particularly relevant dichotomous effect size data, indicates event counts refer . \"msd\" factor level used outcomes expressed means standard deviations. instrument: variable describes instrument relevant outcome measured. time: measurement point outcome obtained (e.g. post follow-). time_weeks: measurement point outcome obtained, weeks randomization (set NA information available). rating: variable encodes reported outcome self-reported (\"self-report\") clinician-rated (\"clinician\").","code":""},{"path":"/articles/web/get-started.html","id":"effect-size-data-variables-ii","dir":"Articles > Web","previous_headings":"The Preparation Module > Required Data Structure","what":"Effect Size Data Variables (II)","title":"Get Started","text":"Metapsy database also contains variables (raw pre-calculated) effect size data stored. row, one following variable groups () (d) specified, depending type outcome data reported paper. rest variable groups contain NA row. preparing effect size data, important row data provided one variable group (defined ), variable groups NA (.e., missing values). Otherwise, calculateEffectSizes function use later know type effect size calculated.  () Continuous Outcome Data mean_arm1: Mean outcome first arm measured time point. mean_arm2: Mean outcome second arm measured time point. sd_arm1: Standard deviation outcome first arm measured time point. sd_arm2: Standard deviation outcome second arm measured time point. n_arm1: Sample size first trial arm. n_arm2: Sample size second trial arm.  (b) Change Score Data mean_change_arm1: Mean score change baseline measured time point first arm. mean_change_arm2: Mean score change baseline measured time point second arm. sd_change_arm1: Standard deviation mean change first arm. sd_change_arm2: Standard deviation mean change second arm. n_change_arm1: Sample size first trial arm. n_change_arm2: Sample size second trial arm.  (c) Dichotomous Outcome Data (Response, Remission, Deterioration, …) event_arm1: Number events (responders, remission, deterioration cases) first trial arm. event_arm2: Number events (responders, remission, deterioration cases) second trial arm. totaln_arm1: Sample size first trial arm. totaln_arm2: Sample size second trial arm.  (d) Pre-calculated Hedges’ \\(g\\) precalc_g: pre-calculated value Hedges’ \\(g\\) (small-sample bias corrected standardized mean difference; Hedges, 1981). precalc_g_se: Standard error \\(g\\), viz. \\(\\sqrt{V_g}\\).  (d) Pre-calculated log-risk ratio precalc_log_rr: pre-calculated value log-risk ratio \\(\\log_{e}\\text{RR}\\), comparing events first arm events second arm. precalc_log_rr_se: standard error log-risk ratio \\(\\log_{e}\\text{RR}\\), comparing events first arm events second arm.","code":""},{"path":"/articles/web/get-started.html","id":"additional-considerations","dir":"Articles > Web","previous_headings":"The Preparation Module > Required Data Structure","what":"Additional Considerations","title":"Get Started","text":"Metapsy databases also contain additional variables. used, example, collect subject-specific information relevant indications. Nevertheless, several formatting rules variables/columns follow: variable names snake_case. Variable names start standard letter (_ allowed, . allowed metapsyTools variables). Variable names contain special characters (like @, ğ). Semicolons (;) used; neither variable names cell content. Character values contain leading/trailing white spaces. Missing values encoded using NA.","code":""},{"path":"/articles/web/get-started.html","id":"data-format-conflict-check","dir":"Articles > Web","previous_headings":"The Preparation Module","what":"Data Format & Conflict Check","title":"Get Started","text":"data set pre-structured correctly, metapsyTools allows check required variable format control potential formatting conflicts. formatting rules followed, none default behavior preparation module changed. first, one can run checkDataFormat. illustration, use depressionPsyCtr data frame, pre-installed “toy” data set directly available installing metapsyTools. see function checked required variables class. divergent, function also try convert variable desired format.  Required variables unique IDs: function properly, metapsyTools functions must able generate unique ID comparison. default, achieved combining information study, condition_arm1, condition_arm2, multi_arm1, multi_arm2, outcome_type, instrument, time, time_weeks, rating variables. variables included default must.contain argument checkDataFormat function. required variables detected, OK message returned; case example.  can also check data potential formatting issues, using checkConflicts function. case, data format conflicts detected. data pre-structured correctly. data conflicts exist, output looks similar : ID conflicts typically occur information variables used build IDs (see box ) sufficient create unique ID comparison. Studies non-unique IDs subsequently printed . checkConflicts function also argument called vars..id, can used define (additional) columns used ID generation. can sometimes help create unique IDs. illustration, now define extended variable list used IDs checkConflicts:","code":"# Load metapsyTools & dplyr library(metapsyTools) library(dplyr)  # Load preinstalled \"toy\" dataset data(\"depressionPsyCtr\")  # Check data format depressionPsyCtr <- checkDataFormat(depressionPsyCtr) # - [OK] Data set contains all variables in 'must.contain'. # - [OK] 'study' has desired class character. # - [OK] 'condition_arm1' has desired class character. # [...] depressionPsyCtr <- checkConflicts(depressionPsyCtr) # - [OK] No data format conflicts detected. # - [!] Data format conflicts detected! # ID conflicts  # - check if variable(s) study create(s) unique assessment point IDs  # - check if specification uniquely identifies all trial arms in multiarm trials  # -------------------- # Abas, 2018 # Ammerman, 2013 # Andersson, 2005 # [...] # Define extended ID list  # \"target_group\" is now also included id.list <- c(\"study\", \"outcome_type\",              \"instrument\", \"time\", \"time_weeks\",              \"rating\", \"target_group\")  # Use id.list as input for vars.for.id argument checkConflicts(depressionPsyCtr,                vars.for.id = id.list)"},{"path":"/articles/web/get-started.html","id":"effect-size-calculation","dir":"Articles > Web","previous_headings":"The Preparation Module","what":"Effect Size Calculation","title":"Get Started","text":"data set pre-formatted correctly, ID conflicts resolved, calculateEffectSizes function can used calculate effect sizes (Hedges’ \\(g\\) risk ratios, \\(RR\\)) comparisons database. calculateEffectSizes function uses information stored effect size data variables calculate \\(g\\) /\\(RR\\), depending information available. Therefore, important make sure variables defined correctly running calculateEffectSizes. calculateEffectSizes function adds nine columns data set, start dot (.). included meta-analysis functions metapsyTools can applied “box”. .id: Unique identifier trial arm comparison/row. .g: Calculated effect size (Hedges’ \\(g\\)). .g_se: Standard error Hedges’ \\(g\\). .log_rr: Calculated effect size (\\(\\log_{e}\\text{RR}\\)). .log_rr_se: Standard error \\(\\log_{e}\\text{RR}\\). .event_arm1: Number events (e.g. responders) first trial arm. .event_arm2: Number events (e.g. responders) second trial arm. .totaln_arm1: Total sample size first trial arm. .totaln_arm2: Total sample size second trial arm. Now, let us look calculated effect sizes (\\(g\\) \\(\\log_eRR\\)) random slice data: see one important detail . dichotomous outcome data provided, calculateEffectSizes function automatically calculates log-risk ratio, estimate \\(g\\). Therefore, effects remission, response, etc. default also included meta-analyses based Hedges’ \\(g\\). Please make sure filter effect sizes want included meta-analysis. filterPoolingData function, cover later, allows .","code":"data <- calculateEffectSizes(depressionPsyCtr) # Show rows 10 to 15, and variables \"study\", \".g\", and \".log_rr\" data %>%    slice(10:15) %>%    select(\"study\", \".g\", \".log_rr\") #                   study         .g    .log_rr # 10     Ahmadpanah, 2016  1.7788677         NA # 11    Alexopoulos, 2016  0.2151835 -0.2436221 # 12    Alexopoulos, 2016 -0.2151835  0.2436221 # 13 Allart van Dam, 2003 -0.5696379         NA # 14 Allart van Dam, 2003  0.5696379         NA # 15       Ammerman, 2013 -0.9439887         NA"},{"path":"/articles/web/get-started.html","id":"change-effect-size-sign","dir":"Articles > Web","previous_headings":"The Preparation Module > Effect Size Calculation","what":"Change Effect Size Sign","title":"Get Started","text":"change.sign argument calculateEffectSizes can used change sign one several calculated effect sizes (e.g. change calculated effect size \\(g\\)=0.30 \\(g\\)=—0.30, vice versa). illustrated : see .g now changed ever sign_change set TRUE. also see affect estimates \\(\\log_eRR\\).","code":"# Take a slice of the data for illustration depressionPsyCtrSubset <- depressionPsyCtr %>% slice(10:15)  # Create a logical variable which, for each row, # indicates if the sign of g should be changed depressionPsyCtrSubset$sign_change <- c(TRUE, TRUE, TRUE,                                          TRUE, TRUE, FALSE)  # Calculate effect sizes while defining the variable in  # our data in which the change sign information is stored data.change.sign <- calculateEffectSizes(                       depressionPsyCtrSubset,                       change.sign = \"sign_change\")  # Show the relevant columns data.change.sign %>%    select(study, .g, .log_rr) #                  study         .g    .log_rr # 1     Ahmadpanah, 2016 -1.7788677         NA # 2    Alexopoulos, 2016  0.2151835 -0.2436221 # 3    Alexopoulos, 2016  0.2151835  0.2436221 # 4 Allart van Dam, 2003  0.5696379         NA # 5 Allart van Dam, 2003 -0.5696379         NA # 6       Ammerman, 2013 -0.9439887         NA"},{"path":"/articles/web/get-started.html","id":"including-switched-arms","dir":"Articles > Web","previous_headings":"The Preparation Module > Effect Size Calculation","what":"Including Switched Arms","title":"Get Started","text":"default, Metapsy databases include unique trial arm combinations, unique comparisons. show difference matters, let us consider small example. Imagine data four-arm trial. Say trial included CBT, PST, CAU wait-list condition. trial provides 6 unique trial arm combinations1, number unique comparisons higher: \\(\\frac{n!}{(n-k)!} = \\frac{4!}{2!} = 12\\). sign calculated effect size depends treatment serves reference. effect CBT vs. PST, example, depends arm serves reference group (.e. CBT vs. PST PST vs. CBT). Depending arm chosen (assuming non-zero mean differences), calculated effect size (e.g. Hedges’ \\(g\\)) value either negative (e.g. \\(g\\)=-0.31) positive (\\(g\\)=0.31). see visualized graph . now two directed arrows comparison (12 total), arrow reads “compared ”: truly calculate unique comparisons, set include.switched.arms argument TRUE running calculateEffectSizes. resulting data frame data now includes effect sizes can theoretically calculated (assuming relevant combinations included original data).  use include.switched.arms? essential calculate possible arm comparisons. However, possible comparisons data set convenient, required comparisons pertaining particular research question (e.g. “effective PST CBT reference group?”) can directly filtered ; typically need data manipulation steps . include.switched.arms argument can also helpful want prepare network meta-analysis data (subsequently analyzed using, e.g., netmeta package). However, assumes data set already contains unique combinations multi-arm trials (e.g. 6 combinations four-arm study , just selection).  leads final data set can used analysis module, described next.","code":"data.switched.arms <- calculateEffectSizes(                         depressionPsyCtr,                         include.switched.arms = TRUE)"},{"path":"/articles/web/get-started.html","id":"the-analysis-module","dir":"Articles > Web","previous_headings":"","what":"The Analysis Module","title":"Get Started","text":"analysis module metapsyTools allows run different kinds meta-analyses based final data set created preparation module. designed also usable researchers directly involved preparation step, less demanding terms required background knowledge. Metapsy databases included metapsyData can directly used analysis module metapsyTools. analysis module allows, among things, : Filter data using strict rules, fuzzy string matching, implementing prioritization rules (filterPoolingData filterPriorityRule)2. Run conventional random-effects meta-analysis models, well commonly reported sensitivity analyses (runMetaAnalysis). Correct effect estimates potential publication bias small-study effects (correctPublicationBias). Run subgroup analyses based fitted model (subgroupAnalysis) Create study information tables (createStudyTable).","code":""},{"path":"/articles/web/get-started.html","id":"filtering-relevant-comparisons","dir":"Articles > Web","previous_headings":"The Analysis Module","what":"Filtering Relevant Comparisons","title":"Get Started","text":"metapsyTools package contains functions allow flexibly filter comparisons relevant particular meta-analysis. filterPoolingData function main function filtering. simply provide final data set calculated effect sizes (see preparation module), well one several filtering criteria pertaining specific research question. Say want run meta-analysis studies CBT compared wait-lists, BDI-post-test analyzed outcome. can filter relevant comparisons like : see \\(k\\)=7 comparisons fulfill criteria. Note, however, select comparisons condition_arm1 exactly defined \"cbt\". also possible filter rows simply contain specific search term (fuzzy matching). example, instead \"cbt\", might want filter studies employed type “” therapy format. can achieved using Detect function within filterPoolingData: can create even complex filters. Say want examine effect, measured BDI-post-test, CBT, PST, BAT compared either CAU wait-lists. can visualize graph : can use -Operator | within filterPoolingData filter types. , use Detect function allow fuzzy matching:  Lastly, one can also filter data according specified priority rule, using filterPriorityRule function. particularly helpful select instruments. Say, example, ordered certain instruments based known reliability. Now, study, want select comparison reliable instrument used. possible , studies, used instruments relatively unreliable. However, given priority rule, can still extract comparison relatively high reliability, discard measurements within one study even less reliable. Assume priority rule employed instrument \"hdrs\" (priority 1), \"bdi-2\" (priority 2), \"phq-9\" (priority 3) \"bdi-1\" (priority 4). can implement rule like :","code":"# Load the pre-installed \"depressionPsyCtr\" dataset load(\"depressionPsyCtr\") data <- depressionPsyCtr  # Filter relevant comparisons data %>%      filterPoolingData(       condition_arm1 == \"cbt\",       condition_arm2 == \"wl\",       instrument == \"bdi-1\",       time == \"post\") %>% nrow() # [1] 7 data %>%    filterPoolingData(     Detect(condition_arm1, \"other\")) %>%   pull(condition_arm1) # [1] \"other psy\" \"other ctr\" \"other ctr\" \"other ctr\" \"other ctr\" \"other ctr\"  # [7] \"other ctr\" \"other ctr\" \"other psy\" data %>%    filterPoolingData(     Detect(condition_arm1, \"cbt|pst|bat\"),     Detect(condition_arm2, \"cau|wl\"),     instrument == \"bdi-1\",     time == \"post\") %>% nrow() # [1] 11 data %>%       # First, filter all other relevant characteristics   filterPoolingData(     Detect(condition_arm1, \"cbt|pst|bat\"),     Detect(condition_arm2, \"cau|wl\"),     time == \"post\") %>%       # Now, implement the priority rule for the outcome instrument   filterPriorityRule(     instrument = c(\"hdrs\", \"bdi-2\",                     \"phq-9\", \"bdi-1\")) %>%       # Show number of entries   nrow() # [1] 20"},{"path":"/articles/web/get-started.html","id":"pooling-effects","dir":"Articles > Web","previous_headings":"The Analysis Module","what":"Pooling Effects","title":"Get Started","text":"relevant rows filtered , can start pool effect sizes. runMetaAnalysis function serves wrapper several commonly used meta-analytic approaches, , default, applies data: \"overall\". Runs generic inverse-variance (random-effects) model. included effect sizes treated independent. raw event data available event_arm1, event_arm2, totaln_arm1, totaln_arm2 columns (see Effect Size Calculation), Mantel-Haenszel method (Greenland & Robins, 1985) used pool effects. Please note assumptions model violated whenever study contributes one effect sizes (since effect sizes assumed correlated). case, results \"combined\" \"threelevel\"/\"threelevel.che\" models reported instead. \"combined\". Aggregates effect sizes within one study calculating overall effect. ensures effect sizes independent (.e., unit--analysis error & double-counting avoided). combine effects, one assume correlation effect sizes within studies, empirical estimates typically available. default, runMetaAnalysis assumes \\(\\rho\\)=0.6. \"lowest.highest\". Runs meta-analysis, () lowest (ii) highest effect size within study included. \"outlier\". Runs meta-analysis without statistical outliers (.e. effect sizes confidence interval overlap confidence interval overall effect). \"influence\". Runs meta-analysis without influential cases, defined using influence diagnostics Viechtbauer & Cheung (2010). See also InfluenceAnalysis function dmetar, Harrer et al. (2022, chap. 5.4.2). \"rob\". Runs meta-analysis low-RoB studies included. default, studies value > 2 rob variable considered analysis. \"threelevel\". Runs multilevel (three-level) meta-analysis model, effect sizes nested studies (Harrer et al., 2022, chap. 10). \"threelevel.che\". Runs multilevel (three-level) “correlated hierarchical effects” (CHE) meta-analysis model. model, effect sizes nested studies, effects within studies assumed correlated (Pustejovsky & Tipton, 2022; default, assumed \\(\\rho\\)=0.6). typically plausible modeling assumption real-world use cases. scenarios, \"threelevel.che\" model can seen better (therefore preferable) approximation data structure hand, compared simpler \"threelevel\" model. illustrate function works, first select subset “toy” depressionPsyCtr data. , plug resulting ma.data data set runMetaAnalysis function: can see, running, runMetaAnalysis function provides us messages allow trace models fitted successfully. problems calculation, runMetaAnalysis function print warning. can inspect results calling created res object console. default, HTML table pop along console output. pre-formatted HTML results tables can easily transferred , example, MS Word using copy paste. disable feature, specify html=FALSE inside function call.  Using summary method, details analysis settings can printed. function also returns recommended citations applied methods /packages. Furthermore, creates summary forest plot pooled effects displayed.","code":"# Only select data comparing CBT to waitlists and CAU depressionPsyCtr %>%    filterPoolingData(     condition_arm1 == \"cbt\",     Detect(condition_arm2, \"wl|cau\")   ) -> ma.data res <- runMetaAnalysis(ma.data) # - Running meta-analyses... # - [OK] Using Hedges' g as effect size metric...  # - [OK] Calculating overall effect size... DONE # - [OK] Calculating effect size using only lowest effect... DONE # - [OK] Calculating effect size using only highest effect... DONE # - [OK] Calculating effect size using combined effects (rho=0.6; arm-wise)... DONE # - [OK] Calculating effect size with outliers removed... DONE # - [OK] Calculating effect size with influential cases removed... DONE # - [OK] Calculating effect size using only low RoB information... DONE # - [OK] Calculating effect size using three-level MA model... DONE # - [OK] Robust variance estimation (RVE) used for three-level MA model... DONE # - [OK] Calculating effect size using three-level CHE model (rho=0.6)... DONE # - [OK] Robust variance estimation (RVE) used for three-level CHE model... DONE # - [OK] Done! # This tells the function to only consider studies with a rob score  # above 4 in the \"low risk of bias\" sensitivity analysis runMetaAnalysis(ma.data, low.rob.filter = \"rob > 4\") # [...] # - [!] No low risk of bias studies detected! Switching to 'general'... DONE # [...] res # Model results ------------------------------------------------  # Model                       k     g g.ci           p         i2 i2.ci          prediction.ci   nnt # Overall                    26 -0.57 [-0.85; -0.28] <0.001  76.4 [65.65; 83.76] [-1.57; 0.43]  5.22 # Combined                   17 -0.54 [-0.89; -0.18] 0.005   77.1 [63.64; 85.57] [-1.64; 0.57]  5.56 # One ES/study (lowest)      14 -0.57 [-1; -0.13]    0.015   79.8 [66.82; 87.65] [-1.78; 0.64]  5.22 # One ES/study (highest)     14 -0.47 [-0.84; -0.11] 0.015   73.9 [55.75; 84.62] [-1.45; 0.5]   6.41 # Outliers removed           23 -0.46 [-0.63; -0.29] <0.001  61.6 [39.55; 75.55] [-1.11; 0.19]  6.64 # Influence Analysis         24 -0.43 [-0.6; -0.27]  <0.001  63.9 [44.18; 76.66] [-1.08; 0.22]  7.08 # Only rob > 2               13 -0.34 [-0.58; -0.11] 0.008   73.4 [53.91; 84.71] [-1.1; 0.41]   9.12 # Three-Level Model          26 -0.61 [-1.05; -0.17] 0.011   92.1 -              [-2.17; 0.96]  4.81 # Three-Level Model (CHE)    26 -0.55 [-0.92; -0.18] 0.007   88   -              [-1.8; 0.7]    5.42 #  # Variance components (three-level model) ----------------------  # Source           tau2    i2 # Between Studies 0.536  92.1 # Within Studies  0       0   # Total           0.536  92.1 #  # Variance components (three-level CHE model) ------------------  # Source           tau2    i2 # Between Studies 0.336  87.2 # Within Studies  0.003   0.8 # Total           0.339  88 summary(res) ## Analysis settings ----------------------------------------------------------  ##  ## ✓ [Overall] Random effects model assumed.  ## ✓ [Overall] Heterogeneity variance (tau2) calculated using restricted maximum-likelihood estimator.  ## ✓ [Overall] Test statistic and CI of the pooled effect calculated using the Knapp-Hartung adjustment.  ## ✓ [Outliers removed] ES removed as outliers if the CI did not overlap with pooled effect CI.  ## ✓ [Influence Analysis] Influential cases determined using diagnostics of Viechtbauer and Cheung (2010).  ## [...] ##  ##  ## Cite the following packages/methods: --------------------------------------- ##  ##  - {meta}: Balduzzi S, Rücker G, Schwarzer G (2019), ##           How to perform a meta-analysis with R: a practical tutorial, ##           Evidence-Based Mental Health; 22: 153-160.  ##  - {metafor}: Viechtbauer, W. (2010). Conducting meta-analyses in R ##           with the metafor package. Journal of Statistical Software, 36(3), 1-48. ##           https://doi.org/10.18637/jss.v036.i03.  ##  [...]"},{"path":"/articles/web/get-started.html","id":"additional-arguments","dir":"Articles > Web","previous_headings":"The Analysis Module > Pooling Effects","what":"Additional Arguments","title":"Get Started","text":"runMetaAnalysis function allows tweak many, many details specific meta-analysis models (run ?runMetaAnalysis see entire documentation). important arguments one may want specify : es.measure. default, function conducts analyses using Hedges \\(g\\) values stored data set. conduct analyses using dichotomous outcome data (.e. response, remission, etc.), one set argument \"RR\". es.type. default, analyses conducted using \"precalculated\" effect sizes stored prepared data set. risk ratios, one can alternatively set argument \"raw\", means “raw” event counts used computations (instead pre-calculated log-risk ratio standard error). typically preferable, may possible information extracted primary studies. method.tau. argument controls method used estimating -study heterogeneity variance \\(\\tau^2\\). default \"REML\" (restricted maximum likelihood), options DerSimonian-Laird estimator (\"DL\") also available (see runMetaAnalysis function documentation details). Note three-level meta-analysis models can fitted using (restricted) maximum likelihood. nnt.cer. runMetaAnalysis function uses method Furukawa Leucht (2011) calculate Number Needed Treat (NNT) pooled effect size. method needs estimate control group event rate (CER). default, nnt.cer = 0.2 used, can set another value desired. rho.within.study. combine effect sizes study level pooling (\"combined\" model), one assume within-study correlation effects. default, rho.within.study = 0.6 assumed, value can changed based better approximations. value also controls assumed within-study correlation multilevel CHE model (\"theelevel.che\"). low.rob.filter. default, function uses comparisons risk bias rating rob variable value greater 2 (low.rob.filter = \"rob > 2\"). risk bias rating another variable, another threshold used, can change argument accordingly. example runMetaAnalysis call non-default settings: Also note \"combined\" model, default, effect sizes multi-arm trials aggregated arms level. , example, study included CBT, Internet-based CBT, wait-list arm (wait-list reference condition), two separate aggregated effects calculated: one CBT vs. wait-list, one Internet-based CBT vs. wait-list. statistical perspective, typically preferable aggregate study level instead3 (example, lead one aggregated effect CBT/Internet-based CBT combined vs. wait-list), although aggregated effect sizes may difficult interpret clinical perspective. combine effect sizes study level instead, can set .combine argument \"studies\".","code":"runMetaAnalysis(ma.data,                 es.measure = \"RR\",                 es.type = \"raw\",                 method.tau = \"DL\",                 nnt.cer = 0.4,                 rho.within.study = 0.8) runMetaAnalysis(ma.data, which.combine = \"studies\")"},{"path":"/articles/web/get-started.html","id":"confidence-intervals-for-three-level-model-tau2-and-i2-values","dir":"Articles > Web","previous_headings":"The Analysis Module > Pooling Effects","what":"Confidence Intervals for Three-Level Model \\(\\tau^2\\) and \\(I^2\\) Values","title":"Get Started","text":"Please note , default, confidence intervals printed \\(^2\\) value \"threelevel\" \"threelevel.che\" model (also case \\(G^2\\) value, equivalent \\(^2\\) limit meta-analyses; see Publication Bias section)4. two heterogeneity variances three-level models: “conventional” -study heterogeneity variance \\(\\tau^2_{(1)}\\) heterogeneity variance within studies, \\(\\tau^2_{(2)}\\). means also two \\(^2\\) values, one within studies, one -study heterogeneity. Established closed-form iterative solutions (\\(Q\\)-Profile method; Viechtbauer, 2007) directly applicable , means confidence intervals calculated easily. metapsyTools, one can resort parametric bootstrap (van den Noortgate & Onghena, 2005) obtain approximate confidence intervals around \\(\\tau^2\\) \\(^2\\) values. Bootstrapping performed i2.ci.boot argument set TRUE. default, \\(n\\)=5000 bootstrap samples drawn, seen absolute lower limit; replications preferable can specified via nsim.boot argument. Please note bootstrapping computationally expensive, means can take hour longer final results obtained. bootstrapping procedure, function prints progress update users get indication long function (still) run. Confidence intervals around \\(^2\\) \\(\\tau^2\\) printed along usual results. runMetaAnalysis run i2.ci.boot set TRUE, \\(^2\\) (, correctly, \\(G^2\\)) value limit meta-analysis also calculated using parametric bootstraping, provided correctPublicationBias called afterwards (see publication bias section).","code":"res.boot <- runMetaAnalysis(ma.data,                             i2.ci.boot = TRUE,                             nsim.boot = 500) res.boot # 1% completed | 2% completed | 3% completed ... # [...] # Variance components (three-level model) ----------------------  # Source           tau2 tau2.ci           i2 i2.ci          # Between Studies 0.536 [0.178; 1.092]  92.1 [74.29; 95.72] # Within Studies  0     [0; 0.055]       0   [0; 10.43]     # Total           0.536 [0.182; 1.107]  92.1 [79.83; 96.01] #  # Variance components (three-level CHE model) ------------------  # Source           tau2 tau2.ci           i2 i2.ci          # Between Studies 0.336 [0.068; 0.667]  87.2 [56.65; 92.9]  # Within Studies  0.003 [0; 0.03]        0.8 [0; 10.31]     # Total           0.339 [0.079; 0.681]  88   [63.17; 93.67]"},{"path":"/articles/web/get-started.html","id":"complex-variance-covariance-approximation","dir":"Articles > Web","previous_headings":"The Analysis Module > Pooling Effects","what":"Complex Variance-Covariance Approximation","title":"Get Started","text":"vcov argument runMetaAnalysiscontrols effect size dependencies within data approximated using \"simple\" (default) \"complex\" (potentially accurate) method. argument relevant \"combined\" \"threelevel.che\" models. default “simple” method constructs variance-covariance matrices \\(\\Sigma_k\\) study using constant sampling correlation \\(\\rho\\) (defined rho.within.study), identical across studies, outcomes, time points. simplifying assumption part formulation CHE model originally provided Pustejovsky Tipton (2022). Naturally, employing common value \\(\\rho\\) across studies may reasonable analyses, information may available better approximate effect size dependencies collected data. Setting vcov \"complex\" allows assume correlations effect sizes may differ conditional type dependency. means variance-covariance matrix \\(\\Sigma_k\\) study \\(k\\) approximated unstructured matrix varying \\(\\rho_{ij}\\). Put simply, method allows account fact can various types effect size dependencies (e.g. effect sizes dependent different instruments used sample; dependent effects two different intervention groups compared control group multi-arm trial, ) , therefore, magnitude correlation also differs. Setting vcov = \"complex\" allows additionally incorporate assumed correlations specific multiple testing time (e.g. correlations effects post-test long-term follow-). value provided phi.within.study represents (auto-)correlation coefficient \\(\\phi\\), serves rough estimate re-test correlation 1 week. allows model gradual decrease correlation measurements time. Furthermore, possible calculate correlation coefficient \\(\\rho_w\\) multi-arm trials, directly proportional size individual trial arm. trial arms size, meaning arm’s weight \\(w\\) identical, \\(\\rho_w\\) known 0.5. Multiarm weights \\(w\\) (thus \\(\\rho_w\\)) can derived w1.var w2.var variables, containing sample size study arm, available. Using complex approximation method increases risk least one studies’ \\(\\Sigma_k\\) matrix positive definite. case, function automatically switches back constant sampling correlation approximation. supplied data set format strictly follows Metapsy data standard, possible set vcov \"complex\" without preparation steps. function inform us complex variance-covariance approximation possible, meaning function automatically reverted standard \"simple\" approach. want use complex variance-covariance matrix approximation feature, advised make sure data set contains following columns: \"n_arm1\" \"n_arm2\": sample sizes two compared groups. \"time_weeks\": post-randomization time point measurement made (weeks). correctly preformatted dataset, users referred depressionPsyCtr “toy” dataset.","code":"runMetaAnalysis(ma.data,                 vcov = \"complex\")"},{"path":"/articles/web/get-started.html","id":"internal-objects","dir":"Articles > Web","previous_headings":"The Analysis Module > Pooling Effects","what":"Internal Objects","title":"Get Started","text":"important note runMetaAnalysis wrapper function. provides common interface run several meta-analysis models, models fitted internally packages. particular, use functionality provided meta (Balduzzi, Rücker & Schwarzer, 2019), metafor (Viechtbauer, 2010), dmetar (Harrer, Cuijpers, Furukawa & Ebert, 2019) packages. returning results, runMetaAnalysis saves fitted models inside returned object. Depending type, internal meta-analysis models work just like regular meta metafor models, means functionality developed also available. also possible directly extract calculated model runMetaAnalysis results object. models identical ones one receive running metagen, metabin, rma.mv directly. means kind operation available metagen rma models also available models created runMetaAnalysis. example, can generate funnel plot “overall” model like :  feature can also used run, example, Egger’s regression test, using functions already included meta dmetar: overview available functionality, can consult specific documentation entry meta-analysis model type: \"overall\", \"combined\", \"lowest\", \"highest\", \"outliers\", \"influence\", \"rob\": run ?metagen console (effect size \\(g\\), effect size \\(RR\\) es.type \"precalculated\"); otherwise, run ?metabin. \"threelevel\" \"threelevel.che\": run ?rma.mv console. methods section documentation entry particularly relevant, since shows functions can applied model type (-called S3 methods).","code":"res$model.overall         # \"overall\" model (metagen/metabin) res$model.combined        # \"combined\" model (metagen/metabin) res$model.lowest          # lowest effect size/study only model (metagen/metabin) res$model.highest         # highest effect size/study only model (metagen/metabin) res$model.outliers        # outliers removed model (metagen/metabin) res$model.influence       # influential cases removed model (metagen/metabin) res$model.rob             # low RoB model (metagen/metabin) res$model.threelevel      # three-level model res$model.threelevel.che  # three-level CHE model library(meta)  # model.overall is a \"meta\" model, so we can directly # Apply the funnel function included in meta funnel(res$model.overall,         studlab = TRUE,         contour = c(0.9, 0.95, 0.99),        col.contour = c(\"darkgreen\", \"green\", \"lightgreen\")) # Egger's regression test applied to the \"overall\" model: library(dmetar) eggers.test(res$model.overall) # Eggers' test of the intercept  # =============================  #  #  intercept        95% CI      t           p #     -2.814 -3.97 - -1.66 -4.785 7.17608e-05 #  # Eggers' test indicates the presence of funnel plot asymmetry."},{"path":"/articles/web/get-started.html","id":"forest-plots","dir":"Articles > Web","previous_headings":"The Analysis Module > Pooling Effects","what":"Forest Plots","title":"Get Started","text":"also possible generate forest plots calculated models. plug results object plot, specify name model forest plot retrieved: \"overall\" model forest plot looks like, example: Note plot function simply wrapper forest.meta function meta package. Therefore, advanced styling options also available using extra arguments. also possible generate Baujat Leave-One-Plots (displayed ).","code":"plot(res, \"overall\")        # Overall model (ES assumed independent) plot(res, \"combined\")       # ES combined within studies before pooling plot(res, \"lowest.highest\") # Lowest and highest ES removed (creates 2 plots) plot(res, \"outliers\")       # Outliers-removed model plot(res, \"influence\")      # Influential cases-removed model plot(res, \"threelevel\")     # Three-level model plot(res, \"threelevel.che\") # Three-level CHE model plot(res, \"overall\") plot(res, \"overall\",       col.predict = \"lightgreen\",       col.square = \"gray\",      fontfamily = \"Palatino\") plot(res, \"baujat\") plot(res, \"loo-es\") plot(res, \"loo-i2\")"},{"path":"/articles/web/get-started.html","id":"replacement-functions","dir":"Articles > Web","previous_headings":"The Analysis Module > Pooling Effects","what":"Replacement Functions","title":"Get Started","text":"model fitted using runMetaAnalysis, replacement functions defined function argument. allows quickly tweak one analysis settings, implemented rerun function called. , example, want check results using different estimator \\(\\tau^2\\), different CER calculate number needed treat, leaving settings , can run: , call rerun function: list available setting replacement functions provided . Replacement functions may particularly helpful sensitivity analyses.","code":"method.tau(res) <- \"PM\" nnt.cer(res) <- 0.7 rerun(res)"},{"path":"/articles/web/get-started.html","id":"publication-bias","dir":"Articles > Web","previous_headings":"The Analysis Module","what":"Publication Bias","title":"Get Started","text":"also possible correct effect size estimates potential publication bias /small-study effects using correctPublicationBias function. apply three correction methods time, providing range (less) plausible corrected values. Using .run argument, can apply methods specific model fitted previously.5 , select \"combined\" analysis. reason three publication bias methods applied time publication bias methods based (extent) untestable assumptions, assumption differ methods: trim--fill method included mostly “legacy” method, given popularity last decades. method also frequently requested reviewers. However, found method perform well way correct publication bias, especially -study heterogeneity high. trim--fill method assumes publication bias results funnel plot asymmetry, provides algorithm imputes studies asymmetry removed, results re-estimated. limit meta-analysis method assumes publication bias manifests -called small-study effects (.e., assumes small studies high standard errors likely affected publication bias). calculates expected (“shrunken”) pooled effect standard error \\(\\epsilon_k\\) goes zero, accounting -study heterogeneity. Importantly, methods controls small-study effects , can associated publication bias, . Lastly, step function selection model calculated, allows account possibility results less likely get published depending \\(P\\) value. default, selmodel.steps argument set 0.05, means assume results \\(p\\)<0.1 likely get published. also possible define one selection threshold, e.g. setting selmodel.steps c(0.025, 0.05). details, see Harrer, Cuijpers, Furukawa & Ebert (2022, chap. 9.3). correctPublicationBias function also allows provide additional arguments applied match ones defined trimfill limitmeta functions meta metasens (Schwarzer, Carpenter & Rücker, 2022), respectively. can find example :","code":"correctPublicationBias(res, which.run = \"combined\") # [...] # Publication bias correction ('combined' model) -----------------------  # Model                    k     g g.ci           p         i2 i2.ci          prediction.ci   nnt # Trim-and-fill method    24 -0.16 [-0.62; 0.31]  0.490   85.4 [79.41; 89.61] [-2.16; 1.85] 24.4  # Limit meta-analysis     17  0.1  [-0.32; 0.52]  0.649   95.1 -              [-1.05; 1.25] 35.4  # Selection model         17 -0.87 [-1.38; -0.36] <0.001  85.7 [64.72; 94.57] [-1.98; 0.24]  6.38 # [...] correctPublicationBias(                  res, which.run = \"combined\",                              # Use the R-type estimator to trim & fill               type = \"R\",                              # Use a random-effects model without bias parameter               # to shrink effects in the limi meta-analysis               method.adjust = \"mulim\")"},{"path":"/articles/web/get-started.html","id":"subgroup-analysis","dir":"Articles > Web","previous_headings":"The Analysis Module","what":"Subgroup Analysis","title":"Get Started","text":"subgroupAnalysis function can used perform subgroup analyses. Every column included data set initially supplied runMetaAnalysis can used subgroup variable. example, might want check effects differ country (country) intervention type (condition_arm1): default, HTML table also pop . p column right represents significance overall subgroup effect (, example, significant moderator effect country). also possible conduct subgroup analyses using another model, say, three-level model. specify ..run: number studies subgroups small, sensible use common estimate -study heterogeneity variance \\(\\tau^2\\) (lieu subgroup-specific estimates). can done setting .tau.common argument TRUE function:","code":"sg <- subgroupAnalysis(res, country, condition_arm2) sg # Subgroup analysis results ----------------------  # variable       group n.comp     g g.ci              i2 i2.ci        nnt   p     # country        3         13 -0.61 [-1.3; 0.07]    81.5 [69.5; 88.8] 4.80  0.666 # .              1         13 -0.76 [-0.93; -0.58]   0   [0; 56.6]    3.74  .     # condition_arm2 cau       12 -0.32 [-0.54; -0.09]  71.9 [49.6; 84.3] 9.90  0.025 # .              wl        14 -0.96 [-1.54; -0.38]  70.6 [49.4; 83]   2.88  . sg <- subgroupAnalysis(res,                         country, condition_arm2,                        .which.run = \"threelevel\") sg <- subgroupAnalysis(res,                         country, condition_arm2,                        .which.run = \"combined\",                        .tau.common = TRUE)"},{"path":"/articles/web/get-started.html","id":"meta-regression","dir":"Articles > Web","previous_headings":"The Analysis Module","what":"Meta-Regression","title":"Get Started","text":"Since runMetaAnalysis function saves fitted models internally, also possible extract individually computations. Say, example, want perform multiple meta-regression using threelevel model. want use risk bias rating, well scaled study year predictors. can achieved extracting model analyzed using $ operator, using metaRegression fit model. Please note , available metaRegression, necessary moderator variable(s) already included data set originally used call runMetaAnalysis.","code":"metaRegression(res$model.threelevel,                 ~ scale(as.numeric(rob)) + scale(year)) # Multivariate Meta-Analysis Model (k = 26; method: REML) #  # Variance Components: #  #             estim    sqrt  nlvls  fixed       factor  # sigma^2.1  0.3821  0.6181     14     no        study  # sigma^2.2  0.0000  0.0000     26     no  study/es.id  #  # Test for Residual Heterogeneity: # QE(df = 23) = 64.6042, p-val < .0001 #  # Test of Moderators (coefficients 2:3): # F(df1 = 2, df2 = 23) = 3.0051, p-val = 0.0693 #  # Model Results: #  #                         estimate      se     tval  df    pval    ci.lb    ci.ub      # intrcpt                  -0.6999  0.1923  -3.6394  23  0.0014  -1.0978  -0.3021  **  # scale(as.numeric(rob))    0.5538  0.2364   2.3428  23  0.0282   0.0648   1.0428   *  # scale(year)              -0.2656  0.2827  -0.9395  23  0.3572  -0.8503   0.3192      #  # --- # Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1"},{"path":"/articles/web/get-started.html","id":"risk-of-bias","dir":"Articles > Web","previous_headings":"The Analysis Module","what":"Risk of Bias","title":"Get Started","text":"Databases formatted using Metapsy data standard typically also contain risk bias ratings included study. metapsyTools package also includes functionality include display information analysis. include risk bias data, data.rob argument specified running runMetaAnalysis. particular, need first create provide list element specifications. documentation specify list element provided . set , can use runMetaAnalysis object easily produce forest plots include risk bias information.  also possible create summary risk bias plot, using createRobSummary function.","code":"# Define ROB data to be added to the models robData = list(   domains = c(\"sg\", \"ac\", \"ba\", \"itt\"),   domain.names = c(\"Sequence Generation\",                     \"Allocation Concealment\",                     \"Blinding of Assessors\",                     \"ITT Analyses\"),   categories = c(\"0\", \"1\", \"sr\"),   symbols = c(\"-\", \"+\", \"s\"),   colors = c(\"red\", \"green\", \"yellow\"))  # Re-run model with appended ROB data res = runMetaAnalysis(ma.data, rob.data = robData) plot(res, \"combined\",       smlab = \"\", fontfamily = \"Tahoma\",      col.square = \"lavender\",       col.predict = \"black\") createRobSummary(res,                   name.low = \"1\",                   name.high = \"0\",                   name.unclear = \"sr\")"},{"path":"/articles/web/get-started.html","id":"study-tables","dir":"Articles > Web","previous_headings":"","what":"Study Tables","title":"Get Started","text":"createStudyTable function allows create overview table included studies/comparisons. One supply filtered data set first, names desired variables order appear table. also possible rename factor labels directly function, determine far values rounded, variable names changed: default, createStudyTable also returns HTML table one can copy paste MS Word.  Still questions? vignette provides superficial overview metapsyTools’ functionality. Every function also comes detailed documentation, may consult learn available options covered use cases. Please note metapsyTools still active development, means errors problems may still occur circumstances. report issue ask help, can contact Mathias (mathias.harrer@tum.de).","code":"createStudyTable(      # Dataset. Alternatively, a runMetaAnalysis   # object can also be used.   ma.data,                     ## Columns --------------------------------------   # Simply add columns in the order in which   # they should appear in the table   study, age_group, mean_age, percent_women,      # You can directly recode values within a variable   condition_arm1 = c(\"CBT\" = \"cbt\"),    multi_arm1,   condition_arm2 = c(\"Wait-List\" = \"wl\",                       \"Care-As-Usual\" = \"cau\"),   n_arm1, n_arm2,    country = c(\"Europe\" = \"3\", \"USA\" = \"1\"),   sg, ac, itt,         ## Specifications -------------------------------   # .round.by.digits controls the number of rounded digits for   # specified columns   .round.by.digits = list(mean_age = 0,                            n_arm1 = 0,                           n_arm2 = 0),      # .column.names allows to rename columns   .column.names = list(age_group = \"age group\",                        mean_age = \"mean age\",                        percent_women = \"% female\",                        condition_arm1 = \"Intervention\",                        condition_arm2 = \"Control\",                        n_arm1 = \"N (IG)\",                         n_arm2 = \"N (CG)\",                        multi_arm1 = \"Specification\"))"},{"path":"/articles/web/installation.html","id":"installation","dir":"Articles > Web","previous_headings":"","what":"Installation","title":"Installation Guide","text":"metapsyTools package submitted CRAN, means installation using install.packages() function work. install package, download latest version package metapsyTools Github repository. fairly easy achieve using install_github function devtools package. run following code R: R automatically check devtools installed computer, install necessary; download metapsyTools package Github; install package. Following succesfull installation, package can loaded library ready used. installation process, may receive following prompts: get message, best tell installation manager packages updated. example, means pasting 3 console hitting Enter. vein, installation manager asks question: best choose n (). installation fails strategy (meaning get Error), run installation , update packages time.","code":"if (!require(\"devtools\"))   install.packages(\"devtools\")  devtools::install_github(     \"metapsy-project/metapsyTools\",     build_vignettes = TRUE) library(metapsyTools) ## These packages have more recent versions available. ## Which would you like to update? ## ## 1: All ## 2: CRAN packages only ## 3: None ## 4: ggpubr (0.2.2 -> 0.2.3) [CRAN] ## 5: zip    (2.0.3 -> 2.0.4) [CRAN] ## ## Enter one or more numbers, or an empty line to skip updates: ## There are binary versions available but the source versions are later: ## ##  [...] ## ##   Do you want to install from sources the package which needs compilation? ##   y/n:"},{"path":"/articles/web/installation.html","id":"updating-the-package","dir":"Articles > Web","previous_headings":"","what":"Updating the Package","title":"Installation Guide","text":"metapsyTools package active development time, new version may available. can check current version metapsyTools installed computer using code: header website displays recent version package available users. use novel functionalities integrated package since last installation, update package version locally computer. update package, first de-install current version computer. can using following code: can use code used (re-)install latest package version.","code":"packageVersion(\"metapsyTools\") # Note: this code assumes you are working with RStudio remove.packages(\"metapsyTools\") .rs.restartR()"},{"path":"/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Mathias Harrer. Maintainer. Paula Kuper. Author. Antonia Sprenger. Author. Pim Cuijpers. Author.","code":""},{"path":"/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Harrer, M., Kuper, P., Sprenger, . & Cuijpers, P. (2022). metapsyTools: Several R Helper Functions \"Metapsy\" Database. DOI: 10.5281/zenodo.6566632.","code":"@Manual{,   title = {{metapsyTools}: Several {R} Helper Functions For The {\"Metapsy\"} Database},   author = {Mathias Harrer and Paula Kuper and Antonia Sprenger and Pim Cuijpers},   year = {2022},   url = {https://tools.metapsy.org}, }"},{"path":"/index.html","id":"overview","dir":"","previous_headings":"","what":"Overview","title":"Several R Helper Functions For The ","text":"metapsyTools package facilitates calculation effect sizes meta-analyses based Metapsy database (databases adhering format). Databases loaded R using metapsyData package can automatically analyzed using analysis module package.","code":""},{"path":"/index.html","id":"usage-example","dir":"","previous_headings":"","what":"Usage Example","title":"Several R Helper Functions For The ","text":"","code":"# Load metapsyData library(metapsyData)  # Load database, filter trials, and analyze getData(\"depression-inpatients\") %>%      filterPoolingData(       condition_arm1 == \"cbt\",       instrument == \"bdi\") %>%      runMetaAnalysis()"},{"path":"/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Several R Helper Functions For The ","text":"metapsyTools package lives GitHub repository. can downloaded using code : details install update package can found installation guide.","code":"if (!require(\"remotes\"))   install.packages(\"remotes\")  remotes::install_github(     \"metapsy-project/metapsyTools\")"},{"path":"/reference/Detect.html","id":null,"dir":"Reference","previous_headings":"","what":"String detection wrapper — Detect","title":"String detection wrapper — Detect","text":"Wrapper str_detect stringr package.","code":""},{"path":"/reference/Detect.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"String detection wrapper — Detect","text":"","code":"Detect(...)"},{"path":"/reference/Detect.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"String detection wrapper — Detect","text":"... Arguments passed str_detect.","code":""},{"path":"/reference/Replacement-functions.html","id":null,"dir":"Reference","previous_headings":"","what":"Replacement functions for ","title":"Replacement functions for ","text":"model fitted using runMetaAnalysis, replacement functions defined function argument. allows quickly tweak one analysis settings, implemented rerun function called.","code":""},{"path":"/reference/Replacement-functions.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Replacement functions for ","text":"","code":"data(x) <- value which.run(x) <- value es.measure(x) <- value es.type(x) <- value es.var(x) <- value se.var(x) <- value es.binary.raw.vars(x) <- value method.tau(x) <- value i2.ci.threelevel(x) <- value nsim.boot(x) <- value hakn(x) <- value study.var(x) <- value arm.var.1(x) <- value arm.var.2(x) <- value measure.var(x) <- value low.rob.filter(x) <- value method.tau.ci(x) <- value which.combine(x) <- value which.combine.var(x) <- value which.outliers(x) <- value which.influence(x) <- value which.rob(x) <- value nnt.cer(x) <- value rho.within.study(x) <- value phi.within.study(x) <- value w1.var(x) <- value w2.var(x) <- value vcov(x) <- value near.pd(x) <- value use.rve(x) <- value html(x) <- value lower.is.better(x) <- value selmodel.steps(x) <- value rerun(m)"},{"path":"/reference/Replacement-functions.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Replacement functions for ","text":"x Object class runMetaAnalysis. value Value one arguments runMetaAnalysis correctPublicationBias m (Adapted) object class runMetaAnalysis.","code":""},{"path":[]},{"path":"/reference/Replacement-functions.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Replacement functions for ","text":"","code":"if (FALSE) { data(\"depressionPsyCtr\") depressionPsyCtr %>%   checkDataFormat() %>%   checkConflicts() %>%   calculateEffectSizes() %>%    filterPoolingData(condition_arm2 %in%                        c(\"wl\", \"other ctr\")) -> data  m <- runMetaAnalysis(data, \"combined\")  # Compare results when other tau^2 estimator is used method.tau(m) <- \"DL\" rerun(m) }"},{"path":"/reference/addAllCombinations.html","id":null,"dir":"Reference","previous_headings":"","what":"Add all trial arm combinations for multiarm trials in NMA. — addAllCombinations","title":"Add all trial arm combinations for multiarm trials in NMA. — addAllCombinations","text":"Add trial arm combinations multiarm trials NMA.","code":""},{"path":"/reference/addAllCombinations.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add all trial arm combinations for multiarm trials in NMA. — addAllCombinations","text":"","code":"addAllCombinations(   data,   vars.for.id = c(\"study\", \"outcome_type\", \"instrument\", \"time\", \"time_weeks\", \"rating\"),   vars.for.es = c(\"mean\", \"sd\", \"n\", \"mean_change\", \"sd_change\", \"n_change\", \"event\",     \"totaln\"),   condition = \"condition\",   condition.specification = \"multi\",   groups.column.indicator = c(\"_arm1\", \"_arm2\") )"},{"path":"/reference/addRobData.html","id":null,"dir":"Reference","previous_headings":"","what":"Add meta::rob() element to model — addRobData","title":"Add meta::rob() element to model — addRobData","text":"Add meta::rob() element model","code":""},{"path":"/reference/addRobData.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add meta::rob() element to model — addRobData","text":"","code":"addRobData(mdl, rob.data)"},{"path":"/reference/addTrialArmInfo.html","id":null,"dir":"Reference","previous_headings":"","what":"Add information that varies between trial arms as extra columns to your meta-analysis dataset — addTrialArmInfo","title":"Add information that varies between trial arms as extra columns to your meta-analysis dataset — addTrialArmInfo","text":"Creates two additional columns selected variable information stored separately intervention control group. typically useful trial-level variables (.e. variables differ trial arms) included final meta-analysis dataset.","code":""},{"path":"/reference/addTrialArmInfo.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add information that varies between trial arms as extra columns to your meta-analysis dataset — addTrialArmInfo","text":"","code":"addTrialArmInfo(.data, ...,             .group.indicator = \"condition\",             .name.intervention.group = \"ig\",             .name.control.group = \"cg\",             .vars.for.id = c(\"study\", \"primary\",                              \"Outc_measure\",                              \"Time\", \"Time_weeks\"))"},{"path":"/reference/addTrialArmInfo.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add information that varies between trial arms as extra columns to your meta-analysis dataset — addTrialArmInfo","text":".data data.frame containing unique intervention-control group comparisons, created expandMultiarmTrials function. ... <dplyr_data_masking>. name several columns (included .data) trial-level variables added columns .data. add multiple variables, simply separate using comma. .group.indicator character. Name column .data encodes intervention/control group rows. .name.intervention.group character. Name used .group.indicator variable identify intervention group rows. .name.control.group character. Name used .group.indicator variable identify control group rows. .vars..id character vector, containing column names variables used construct unique comparison IDs.","code":""},{"path":"/reference/addTrialArmInfo.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Add information that varies between trial arms as extra columns to your meta-analysis dataset — addTrialArmInfo","text":"addTrialArmInfo returns dataset class data.frame. dataset contains information previously stored .data, plus two columns selected trial arm variable (one intervention one control group).","code":""},{"path":"/reference/addTrialArmInfo.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Add information that varies between trial arms as extra columns to your meta-analysis dataset — addTrialArmInfo","text":"running meta-analysis, necessary select rows containing calculated effect sizes ('es'). results information loss data differs trial arms within one study (e.g. sample size n often identical arms study); row \"active\"/intervention arm selected, information control group arm discarded. addTrialArmInfo convenience function allows avoid information loss adding trial-specific information extra columns dataset. Two columns created feature: one containing value intervention arm, another containing information control arm. function applicable datasets expanded multiarm trial; , output expandMultiarmTrials (expandMultiarmTrials, followed calculateEffectSizes). details see help vignette: vignette(\"metapsyTools\").","code":""},{"path":[]},{"path":"/reference/addTrialArmInfo.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Add information that varies between trial arms as extra columns to your meta-analysis dataset — addTrialArmInfo","text":"Mathias Harrer mathias.h.harrer@gmail.com, Paula Kuper paula.r.kuper@gmail.com, Pim Cuijpers p.cuijpers@vu.nl","code":""},{"path":"/reference/addTrialArmInfo.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Add information that varies between trial arms as extra columns to your meta-analysis dataset — addTrialArmInfo","text":"","code":"if (FALSE) {  # Example 1: calculate effect sizes # then add \"Post_N\" as trial arm variable data(\"inpatients\") inpatients %>%   checkDataFormat() %>%   expandMultiarmTrials() %>%   calculateEffectSizes() %>%   addTrialArmInfo(Post_N) %>%   filterPoolingData(primary == 1)  # Example 2: add several trial arm variables simultaneously inpatients %>%   checkDataFormat() %>%   expandMultiarmTrials() %>%   calculateEffectSizes() %>%   addTrialArmInfo(Post_N, Rand_N, Cond_spec) %>%   filterPoolingData(primary == 1) }"},{"path":"/reference/binaryES.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate Hedges' g using binary outcome data. — binaryES","title":"Calculate Hedges' g using binary outcome data. — binaryES","text":"Calculate Hedges' g binary outcome data. meant used part calculateEffectSizes.","code":""},{"path":"/reference/binaryES.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate Hedges' g using binary outcome data. — binaryES","text":"","code":"binaryES(x, ...)"},{"path":"/reference/binaryES.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate Hedges' g using binary outcome data. — binaryES","text":"x data ... Binary effect size data. Must Improved_N_trt1, Improved_N_trt2, Rand_N_trt1, Rand_N_trt2 (numeric).","code":""},{"path":"/reference/binaryRR.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate the log-risk ratio using binary outcome data. — binaryRR","title":"Calculate the log-risk ratio using binary outcome data. — binaryRR","text":"Calculate log risk ratio using binary outcome data. meant used part calculateEffectSizes.","code":""},{"path":"/reference/binaryRR.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate the log-risk ratio using binary outcome data. — binaryRR","text":"","code":"binaryRR(x, ...)"},{"path":"/reference/binaryRR.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate the log-risk ratio using binary outcome data. — binaryRR","text":"x data ... Binary effect size data. Must Improved_N_trt1, Improved_N_trt2, Rand_N_trt1, Rand_N_trt2 (numeric).","code":""},{"path":"/reference/blup.html","id":null,"dir":"Reference","previous_headings":"","what":"blup: Empirical Bayes estimates — blup","title":"blup: Empirical Bayes estimates — blup","text":"Best Linear Unbiased Predictions (BLUPs) 'runMetaAnalysis' models.","code":""},{"path":"/reference/blup.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"blup: Empirical Bayes estimates — blup","text":"","code":"blup(x, ...)"},{"path":"/reference/blup.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"blup: Empirical Bayes estimates — blup","text":"x Model ... arguments","code":""},{"path":"/reference/blup.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"blup: Empirical Bayes estimates — blup","text":"Generates empirical Bayes (EB) estimates, also known best linear unbiased predictions (BLUPs), merging fitted values obtained fixed effects estimated contributions random effects. estimates represent study-specific true effect sizes outcomes accompanied standard errors prediction interval bounds.","code":""},{"path":"/reference/blup.runMetaAnalysis.html","id":null,"dir":"Reference","previous_headings":"","what":"Best Linear Unbiased Predictions (BLUPs) for 'runMetaAnalysis' models. — blup.runMetaAnalysis","title":"Best Linear Unbiased Predictions (BLUPs) for 'runMetaAnalysis' models. — blup.runMetaAnalysis","text":"Generates empirical Bayes (EB) estimates, also known best linear unbiased predictions (BLUPs), merging fitted values obtained fixed effects estimated contributions random effects. estimates represent study-specific true effect sizes outcomes accompanied standard errors prediction interval bounds. Uses metafor::blup.rma.uni() function internally.","code":""},{"path":"/reference/blup.runMetaAnalysis.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Best Linear Unbiased Predictions (BLUPs) for 'runMetaAnalysis' models. — blup.runMetaAnalysis","text":"","code":"# S3 method for runMetaAnalysis blup(x, which = NULL, ...)"},{"path":"/reference/blup.runMetaAnalysis.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Best Linear Unbiased Predictions (BLUPs) for 'runMetaAnalysis' models. — blup.runMetaAnalysis","text":"x object class runMetaAnalysis. Model estimates printed. Can one \"overall\", \"combined\", \"lowest.highest\", \"outliers\", \"influence\", \"threelevel\", \"threelevel.che\". ... Additional arguments.","code":""},{"path":"/reference/calculateEffectSizes.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate effect sizes — calculateEffectSizes","title":"Calculate effect sizes — calculateEffectSizes","text":"function calculate effect sizes meta-analysis data prepared Metapsy data format.","code":""},{"path":"/reference/calculateEffectSizes.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate effect sizes — calculateEffectSizes","text":"","code":"calculateEffectSizes(data,                      funcs.g = list(g.m.sd = g.m.sd,                                     g.change.m.sd = g.change.m.sd,                                     g.binary = g.binary,                                     g.precalc = g.precalc),                      funcs.rr = list(rr.binary = rr.binary,                                      rr.precalc = rr.precalc),                      include.switched.arms = FALSE,                      change.sign = NULL,                      vars.for.id = c(\"study\", \"outcome_type\",                                      \"instrument\", \"time\",                                      \"time_weeks\",                                      \"rating\"),                      .condition = \"condition\",                      .condition.specification = \"multi\",                      .groups.column.indicator = c(\"_arm1\", \"_arm2\"),                      .trt.indicator = \"arm\")"},{"path":"/reference/calculateEffectSizes.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate effect sizes — calculateEffectSizes","text":"data Meta-analysis data set formatted using Metapsy guidelines. funcs.g list functions. functions used calculate effect sizes (Hedges' g) based raw data (see Details). funcs.rr list functions. functions used calculate risk ratios based raw event data (see Details). include.switched.arms logical. unique arm comparisons (lieu unique arm combinations) calculated? Default FALSE. change.sign character. Name logical column data, encoding sign calculated effect size reversed (TRUE) (FALSE). Set NULL (default) changes made. vars..id character vector, containing column names variables used construct unique comparison IDs. .condition character. prefix two variables data conditions (e.g. \"guided iCBT\", \"waitlist\") trial arm comparison stored. .condition.specification character. prefix two variables dataset provide \"specification\" trial arm condition multiarm trials. .groups.column.indicator character. character vector two elements, representing suffix used differentiate first second arm comparison. .trt.indicator character. character specifying name used indicate treatment arm.","code":""},{"path":"/reference/calculateEffectSizes.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate effect sizes — calculateEffectSizes","text":"calculateEffectSizes returns meta-analysis data set class data.frame wide format (results saved variable). also generates following columns, wich added data: .id: Unique identifier trial arm comparison/row. .g: Calculated effect size (Hedges' g). .g_se: Standard error Hedges' g. .log_rr: Calculated effect size (logRR). .log_rr_se: Standard error logRR. .event_arm1: Number events (responders, remission, deterioration cases) first trial arm. .event_arm2: Number events (responders, remission, deterioration cases) second trial arm. .totaln_arm1: Total sample size first trial arm. .totaln_arm2: Total sample size second trial arm.","code":""},{"path":"/reference/calculateEffectSizes.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Calculate effect sizes — calculateEffectSizes","text":"default, calculateEffectSizes calculates small-sample bias corrected standardized mean difference  (Hedges' g) log-risk ratios, well respective standard errors, adequate raw effect size data available comparison. essential data set data contains required columns work. overview required data format provided \"Get Started\" page metapsyTools documentation. Standardized mean differences (Hedges' g) can calculated following column types: (1) Continuous Outcome Data mean_arm1: Mean outcome first arm measured time point. mean_arm2: Mean outcome second arm measured time point. sd_arm1: Standard deviation outcome first arm measured time point. sd_arm2: Standard deviation outcome second arm measured time point. n_arm1: Sample size first trial arm. n_arm2: Sample size second trial arm. (2) Change Score Data mean_change_arm1: Mean score change baseline measured time point first arm. mean_change_arm2: Mean score change baseline measured time point second arm. sd_change_arm1: Standard deviation mean change first arm. sd_change_arm2: Standard deviation mean change second arm. n_change_arm1: Sample size first trial arm. n_change_arm2: Sample size second trial arm. (3) Dichotomous Outcome Data event_arm1: Number events (responders, remission, deterioration cases) first trial arm. event_arm2: Number events (responders, remission, deterioration cases) second trial arm. totaln_arm1: Sample size first trial arm. totaln_arm2: Sample size second trial arm. (4) Pre-calculated Hedges' g precalc_g: pre-calculated value Hedges' g (small-sample bias corrected standardized mean difference; Hedges, 1981). precalc_g_se: Standard error g. log-risk ratio standard error can calculated followin column types: (1) Dichotomous Outcome Data event_arm1: Number events (responders, remission, deterioration cases) first trial arm. event_arm2: Number events (responders, remission, deterioration cases) second trial arm. totaln_arm1: Sample size first trial arm. totaln_arm2: Sample size second trial arm. (2) Pre-calculated log-risk ratio precalc_log_rr: pre-calculated value log-risk ratio logRR, comparing events first arm events second arm. precalc_log_rr_se: standard error log-risk ratio logRR, comparing events first arm events second arm. functions can added list provided funcs.g funcs.rr. However, results function must result data.frame contains following columns: .id: Unique identifier trial arm comparison/row. .g: Calculated effect size (Hedges' g). .g_se: Standard error Hedges' g. .log_rr: Calculated effect size (logRR). .log_rr_se: Standard error logRR. .event_arm1: Number events (responders, remission, deterioration cases) first trial arm. .event_arm2: Number events (responders, remission, deterioration cases) second trial arm. .totaln_arm1: Total sample size first trial arm. .totaln_arm2: Total sample size second trial arm. possible set one several column entries NA; columns must included. details see Get Started vignette.","code":""},{"path":[]},{"path":"/reference/calculateEffectSizes.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Calculate effect sizes — calculateEffectSizes","text":"Mathias Harrer mathias.h.harrer@gmail.com, Paula Kuper paula.r.kuper@gmail.com, Pim Cuijpers p.cuijpers@vu.nl","code":""},{"path":"/reference/calculateEffectSizes.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate effect sizes — calculateEffectSizes","text":"","code":"if (FALSE) { data(\"depressionPsyCtr\") depressionPsyCtr %>%     checkDataFormat() %>%     checkConflicts() %>%      calculateEffectSizes() }"},{"path":"/reference/catch.html","id":null,"dir":"Reference","previous_headings":"","what":"Catch variables from parent frame — catch","title":"Catch variables from parent frame — catch","text":"Catch variables parent frame","code":""},{"path":"/reference/catch.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Catch variables from parent frame — catch","text":"","code":"catch(argname, matchcall, data, encl)"},{"path":"/reference/catchName.html","id":null,"dir":"Reference","previous_headings":"","what":"Catch variable names from parent frame — catchName","title":"Catch variable names from parent frame — catchName","text":"Catch variable names parent frame","code":""},{"path":"/reference/catchName.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Catch variable names from parent frame — catchName","text":"","code":"catchName(argname, matchcall, data, encl)"},{"path":"/reference/changeES.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate Hedges' g based on change data. — changeES","title":"Calculate Hedges' g based on change data. — changeES","text":"Calculate Hedges' g based change data. meant used part calculateEffectSizes.","code":""},{"path":"/reference/changeES.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate Hedges' g based on change data. — changeES","text":"","code":"changeES(x, ...)"},{"path":"/reference/changeES.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate Hedges' g based on change data. — changeES","text":"x data ... Change score effect size data. Must Change_m_trt1, Change_m_trt2, Change_SD_trt1, Change_SD_trt2, Change_N_trt1, Change_N_trt2 (numeric).","code":""},{"path":"/reference/checkConflicts.html","id":null,"dir":"Reference","previous_headings":"","what":"Check for (potential) data format conflicts — checkConflicts","title":"Check for (potential) data format conflicts — checkConflicts","text":"function checks potential data formatting conflicts may produce errors incorrect results applying calculateEffectSizes() runMetaAnalysis() function later .","code":""},{"path":"/reference/checkConflicts.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check for (potential) data format conflicts — checkConflicts","text":"","code":"checkConflicts(.data,                vars.for.id = c(\"study\", \"outcome_type\",                                \"instrument\", \"time\",                                \"time_weeks\",                                \"rating\"),                .condition = \"condition\",                .condition.specification = \"multi\",                .groups.column.indicator = c(\"_arm1\", \"_arm2\"))"},{"path":"/reference/checkConflicts.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check for (potential) data format conflicts — checkConflicts","text":".data Meta-analysis data stored data.frame, checked function. vars..id character vector, containing column names variables used construct unique comparison IDs. .condition character. prefix two variables data conditions (e.g. \"guided iCBT\", \"waitlist\") trial arm comparison stored. .condition.specification character, name column containing specific condition trial arm. multiarm trials, conditions must distinct (e.g. \"cbt-guided\" \"cbt-unguided\"). .groups.column.indicator character. character vector two elements, representing suffix used differentiate first second arm comparison.","code":""},{"path":"/reference/checkConflicts.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check for (potential) data format conflicts — checkConflicts","text":"type data returned checkConflicts depends outcome evaluation. problems detected, function simply returns data set provided .data. (potential) formatting formatting issues detected, function throws message returns affected studies/data.frame columns. particular, results provided within list three objects: allConflicts, data.frame containing affected rows, regardless conflict type. idConflicts, data.frame containing rows ID/number arms conflicts. cgConflicts, data.frame containing rows reference arm conflicts (must unique control/reference group comparison). returned list class checkConflicts.","code":""},{"path":[]},{"path":"/reference/checkConflicts.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Check for (potential) data format conflicts — checkConflicts","text":"Mathias Harrer mathias.h.harrer@gmail.com, Paula Kuper paula.r.kuper@gmail.com, Pim Cuijpers p.cuijpers@vu.nl","code":""},{"path":"/reference/checkConflicts.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Check for (potential) data format conflicts — checkConflicts","text":"","code":"if (FALSE) { data(\"depressionPsyCtr\")  # Example 1: Use defaults and simply run checks depressionPsyCtr %>%   checkDataFormat() %>%   checkConflicts() -> res  # Example 2: Overrule defaults; this will produce a conflict depressionPsyCtr %>%   checkDataFormat() %>%   checkConflicts(vars.for.id = \"study\") -> res  }"},{"path":"/reference/checkDataFormat.html","id":null,"dir":"Reference","previous_headings":"","what":"Check data format — checkDataFormat","title":"Check data format — checkDataFormat","text":"function checks data.frame object conforms Metapsy data standard.","code":""},{"path":"/reference/checkDataFormat.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check data format — checkDataFormat","text":"","code":"checkDataFormat(data,                 must.contain = c(\"study\", \"condition_arm1\",                                  \"condition_arm2\",                                   \"multi_arm1\",                                   \"multi_arm2\",                                  \"outcome_type\", \"instrument\",                                  \"time\", \"time_weeks\",                                  \"rating\", \"mean_arm1\", \"mean_arm2\",                                  \"sd_arm1\", \"sd_arm2\",                                  \"n_arm1\", \"n_arm2\",                                  \"event_arm1\", \"event_arm2\",                                  \"totaln_arm1\", \"totaln_arm2\"),                 variable.class = list(\"study\" = \"character\",                                        \"condition_arm1\" = \"character\",                                       \"condition_arm2\" = \"character\",                                        \"multi_arm1\" = \"character\",                                        \"multi_arm2\" = \"character\",                                       \"outcome_type\" = \"character\",                                        \"instrument\" = \"character\",                                       \"time\" = \"character\",                                        \"time_weeks\" = \"numeric\",                                       \"rating\" = \"character\",                                        \"mean_arm1\" = \"numeric\",                                        \"mean_arm2\" = \"numeric\",                                       \"sd_arm1\" = \"numeric\",                                        \"sd_arm2\" = \"numeric\",                                       \"n_arm1\" = \"numeric\",                                        \"n_arm2\" = \"numeric\",                                       \"event_arm1\" = \"numeric\",                                        \"event_arm2\" = \"numeric\",                                       \"totaln_arm1\" = \"numeric\",                                        \"totaln_arm2\" = \"numeric\"))"},{"path":"/reference/checkDataFormat.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check data format — checkDataFormat","text":"data data.frame containint meta-analysis data. must.contain character vector, containing variable names data set contain. Defaults correspond Metapsy data standard. variable.class list, defining required class variables. class differs data, function try convert variable desired class. Defaults correspond Metapsy data standard.","code":""},{"path":"/reference/checkDataFormat.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check data format — checkDataFormat","text":"checkDataFormat returns messages specify input variables, values classes variables defined. default settings used, checkDataFormat() can used combination checkConflicts() determine dataset follows Metapsy data standard. Datasets formatted using standard can directly used analysis module metapsyTools; example runMetaAnalysis() function.","code":""},{"path":"/reference/checkDataFormat.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Check data format — checkDataFormat","text":"function checks : data set contains relevant variables variables desired class (, tries convert).","code":""},{"path":[]},{"path":"/reference/checkDataFormat.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Check data format — checkDataFormat","text":"Mathias Harrer mathias.h.harrer@gmail.com, Paula Kuper paula.r.kuper@gmail.com, Pim Cuijpers p.cuijpers@vu.nl","code":""},{"path":"/reference/checkDataFormat.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Check data format — checkDataFormat","text":"","code":"if (FALSE) { data(\"depressionPsyCtr\")  # Example 1: Check with default arguments checkDataFormat(depressionPsyCtr)  #Example 2: Check for non-default arguments checkDataFormat(depressionPsyCtr,                 must.contain = c(\"study\", \"condition\",                                  \"primary\", \"year\"),                 variable.class = list(study = \"character\",                                       no.arms = \"numeric\")) }"},{"path":"/reference/checkProblemsNMA.html","id":null,"dir":"Reference","previous_headings":"","what":"Check for problems in data sets prepared for netmeta. — checkProblemsNMA","title":"Check for problems in data sets prepared for netmeta. — checkProblemsNMA","text":"Check problems data sets prepared netmeta.","code":""},{"path":"/reference/checkProblemsNMA.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check for problems in data sets prepared for netmeta. — checkProblemsNMA","text":"","code":"checkProblemsNMA(dat.netmeta)"},{"path":"/reference/convertNetmeta.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert Metapsy database into network meta-analysis format — convertNetmeta","title":"Convert Metapsy database into network meta-analysis format — convertNetmeta","text":"function converts database following Metapsy data standard format suitable network meta-analysis (e.g. using netmeta::netmeta()).","code":""},{"path":"/reference/convertNetmeta.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert Metapsy database into network meta-analysis format — convertNetmeta","text":"","code":"convertNetmeta(                                # Continuous outcomes (endpoint scores)                mean_arm1, mean_arm2, sd_arm1, sd_arm2,                 n_arm1, n_arm2,                                # Continuous outcomes (change scores)                mean_change_arm1, mean_change_arm2,                 sd_change_arm1, sd_change_arm2,                n_change_arm1, n_change_arm2,                                 # Response (event counts)                event_arm1, event_arm2, totaln_arm1,                 totaln_arm2,                                 # Study characteristics                condition_arm1, condition_arm2, study,                 ..., data = NULL)"},{"path":"/reference/convertNetmeta.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert Metapsy database into network meta-analysis format — convertNetmeta","text":"mean_arm1 Mean score first trial arm. mean_arm2 Mean score second trial arm. sd_arm1 Standard deviation first trial arm. sd_arm2 Standard deviation second trial arm. n_arm1 Sample size first trial arm. n_arm2 Sample size second trial arm. mean_change_arm1 Mean change scores first trial arm. mean_change_arm2 Mean change scores second trial arm. sd_change_arm1 Standard deviation change scores first trial arm. sd_change_arm2 Standard deviation change scores second trial arm. n_change_arm1 Sample size change scores first trial arm. n_change_arm2 Sample size change scores second trial arm. event_arm1 Number responders first trial arm. event_arm2 Number responders second trial arm. totaln_arm1 Total number participants first trial arm. totaln_arm2 Total number participants second trial arm. condition_arm1 Treatment format first trial arm. condition_arm2 Treatment format second trial arm. study Study labels comparison. ... Additional arguments. Can used specify additional columns included output (see Details). data Dataset following Metapsy data standard (optional).","code":""},{"path":"/reference/convertNetmeta.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert Metapsy database into network meta-analysis format — convertNetmeta","text":"Returns data.frame wide-format, containing calculated effect sizes (standardized mean differences, SMDs) required comparison. following columns included outputs: studlab: Study label comparison. response counts used outcome, \"(response)\" appended study name. treat1: Condition format used first trial arm. treat2: Condition format used second trial arm. TE: calculated effect size (SMD). seTE: Standard error calculated effect size. Depending whether continuous binary outcomes () used, dataset also include columns containing raw data used obtain effect size: n1: Sample size first trial arm. n2: Sample size second trial arm. mean1: Mean (change) scores first trial arm. mean2: Mean (change) scores second trial arm. sd1: Standard deviation first trial arm. sd2: Standard deviation second trial arm. event1: Responders first trial arm. event2: Responders second trial arm. Studies effect sizes calculated saved character vector removed.studies attribute. can extracted using attr(res, \"removed.studies\"), res returned data frame.","code":""},{"path":"/reference/convertNetmeta.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Convert Metapsy database into network meta-analysis format — convertNetmeta","text":"function converts Metapsy database \"wider\" format dataset can used run network meta-analyses. Returned objects optimized netmeta::netmeta() can used \"--box\" package. function perform expansion multi-arm trials, required network meta-analysis implementations. Thus, function calculate three unique comparisons three-arm trials, six comparisons four-arm trials, etc. Two additional formatting requirements must met conduct conversion: comparison trial allowed provide exactly one effect size/contrast. may resolved filtering dataset beforehand using filterPoolingData filterPriorityRule. function return informative error message non-unique comparisons found. function can use raw continuous outcome binary response data calculate SMDs comparison. Rows effect size information (e.g. pre-calculated effects based t F-tests) included. comparisons removed, affected studies printed console added manually. also possible add additional columns (e.g., columns included dataset provided data) final data frame. columns specified additional arguments function call, argument name used column name (see Examples).","code":""},{"path":[]},{"path":"/reference/convertNetmeta.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Convert Metapsy database into network meta-analysis format — convertNetmeta","text":"Mathias Harrer mathias.h.harrer@gmail.com, Paula Kuper paula.r.kuper@gmail.com, Pim Cuijpers p.cuijpers@vu.nl","code":""},{"path":"/reference/convertNetmeta.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convert Metapsy database into network meta-analysis format — convertNetmeta","text":"","code":"if (FALSE) {  # Filter database so that only unique comparisons remain for each study. data <- depressionPsyCtr %>%    filterPriorityRule(     instrument = c(\"ces-d\", \"phq-9\", \"scl\",                     \"hdrs\", \"bdi-2\", \"scid\")) %>%    filterPoolingData(year >= 1985, study != \"Barrett, 2001\")   # Convert endpoint, change score, and response data. dat.netmeta <- convertNetmeta(      # Continuous outcome data   mean_arm1, mean_arm2, sd_arm1, sd_arm2, n_arm1, n_arm2,   mean_change_arm1, mean_change_arm2, sd_change_arm1,    sd_change_arm2, n_change_arm1, n_change_arm2,       # Response data   event_arm1 = event_arm1, event_arm2 = event_arm2,    totaln_arm1 = totaln_arm1, totaln_arm2 = totaln_arm2,       # Treatments to be used in NMA   condition_arm1 = condition_arm1,    condition_arm2 = condition_arm2,       # Additional column to be added   scale = instrument,      # Study label and data   study = study, data = data)  # Load netmeta and perform NMA library(netmeta) netmeta(TE, seTE, treat1, treat2, studlab,          data = dat.netmeta, reference.group = \"wl\")                   # Example using metapsyData database library(metapsyData) d <- getData(\"depression-psyctr\", version = \"22.0.2\")  d$data %>%    filterPriorityRule(instrument = c(\"phq-9\", \"ces-d\", \"hdrs\")) %>%    filterPoolingData(!study %in%                       c('Baumgartner, 2021', 'Brown, 1984', 'Fann, 2015',                          'Fledderus, 2012', 'Floyd, 2004', 'Kleiboer, 2015',                          'Lemma, 2013', 'Mohr, 2013', 'Nezu, 1989',                          'NystrÃ¶m, 2017', 'Pecheur, 1984', 'Propst, 1992',                          'Rehm, 1981', 'Rohan, 2007', 'Scogin, 1989', 'Selmi, 1990',                          'Smith, 2017a', 'Titov, 2010', 'Tomasino, 2017',                          'Watt, 2000', 'Westerhof, 2019', 'Araya, 2021',                          'Choi, 2014')) %>%    convertNetmeta(mean_arm1, mean_arm2, sd_arm1, sd_arm2, n_arm1, n_arm2,                  event_arm1 = event_arm1, event_arm2 = event_arm2,                   totaln_arm1 = totaln_arm1, totaln_arm2 = totaln_arm2,                  condition_arm1 = condition_arm1, condition_arm2 = condition_arm2,                  study = study, format = format, data = .) -> dat.netmeta  # Extract studies for which no effect sizes could be calculated attr(dat.netmeta, \"removed.studies\")  # Run network meta-analysis netmeta(TE, seTE, treat1, treat2, studlab, data = dat.netmeta)   # Multi-arm expansion with single trials: # - Using continuous outcome convertNetmeta(mean_arm1 = c(4.12, 5.74),                mean_arm2 = c(5.74, 6.41),                sd_arm1 = c(4.22, 5.15),                sd_arm2 = c(5.15, 2.79),                n_arm1 = c(50, 50),                n_arm2 = c(50, 50),                condition_arm1 = c(\"cbt\", \"dyn\"),                condition_arm2 = c(\"dyn\", \"wl\"),                study = c(\"Doe, 1999\", \"Doe, 1999\"))  # - using response outcome convertNetmeta(event_arm1 = c(22, 12),                event_arm2 = c(12, 5),                totaln_arm1 = c(87, 89),                totaln_arm2 = c(89, 92),                condition_arm1 = c(\"cbt\", \"dyn\"),                condition_arm2 = c(\"dyn\", \"wl\"),                study = c(\"Doe, 1999\", \"Doe, 1999\"))                 # - using study format instead of conditions format.data <- data.frame(study = c(\"Doe, 1999\", \"Doe, 1999\", \"Miller, 2000\",                                     \"Willms, 2017\", \"Willms, 2017\"),                           format_arm1 = c(\"gsh\", \"ush\", \"ush\", \"gsh\", \"ush\"),                           format_arm2 = c(\"ush\", \"wl\",  \"cau\", \"ush\", \"cau\"),                           mean_arm1 = c(4.12, 5.74, 3.21, 4.99, 6.23),                           mean_arm2 = c(5.74, 6.41, 6.29, 6.23, 6.41),                           sd_arm1 = c(4.22, 5.15, 4.21, 4.00, 5.92),                           sd_arm2 = c(5.15, 2.79, 4.52, 5.92, 3.12),                           n_arm1 = c(50, 50, 76, 30, 30),                           n_arm2 = c(50, 50, 75, 30, 30))  convertNetmeta(mean_arm1, mean_arm2, sd_arm1, sd_arm2, n_arm1, n_arm2,                condition_arm1 = format_arm1, condition_arm2 = format_arm2,                study = study, data = format.data) }"},{"path":"/reference/correctPublicationBias.html","id":null,"dir":"Reference","previous_headings":"","what":"Correct the effect size for publication bias/small-study effects — correctPublicationBias","title":"Correct the effect size for publication bias/small-study effects — correctPublicationBias","text":"function allows add effect sizes estimates corrected publication bias/ small-study effects results runMetaAnalysis function.","code":""},{"path":"/reference/correctPublicationBias.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Correct the effect size for publication bias/small-study effects — correctPublicationBias","text":"","code":"correctPublicationBias(model,                         which.run = model$which.run[1],                        lower.is.better = TRUE,                        selmodel.steps = 0.05,                        ...)"},{"path":"/reference/correctPublicationBias.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Correct the effect size for publication bias/small-study effects — correctPublicationBias","text":"model object class runMetaAnalysis, created runMetaAnalysis function. .run model model used publication bias analyses. Uses default analysis model value specified user. Possible values \"overall\", \"combined\", \"lowest\", \"highest\", \"outliers\", \"influence\" \"rob\". lower..better lower values indicate better outcomes (.e. higher effects)? Default TRUE. selmodel.steps Thresholds assumed step function selection model. Must vector numbers referring cut-points selection models. two-sided testing assumed included studies, cut-point must doubled obtain assumed p-value (e.g. selmodel.steps = c(0.03, 0.05) means p=0.06 p=0.10 assumed selection thresholds). default 0.05. ... Additional arguments. See trimfill.default limitmeta.","code":""},{"path":"/reference/correctPublicationBias.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Correct the effect size for publication bias/small-study effects — correctPublicationBias","text":"Returns object class \"runMetaAnalysis\" \"correctPublicationBias\". object includes original objects included model, adds list object name correctPublicationBias. list object includes three fitted publication bias analysis models, well generated results.","code":""},{"path":"/reference/correctPublicationBias.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Correct the effect size for publication bias/small-study effects — correctPublicationBias","text":"correctPublicationBias function wrapper running three meta-analytic methods control pooled effect size publication bias /small-study effects: \"trimfill\". Applies Duval Tweedie's (2000a, 2000b) trim--fill algorithm, using trimfill method meta package. \"limitmeta\". Runs limit meta-analysis described Rücker et al. (2011), using implementation limitmeta package. \"selection\". Runs step function selection model using selmodel function metafor. details see e.g. Vevea Hedges (1995).","code":""},{"path":"/reference/correctPublicationBias.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Correct the effect size for publication bias/small-study effects — correctPublicationBias","text":"Duval S & Tweedie R (2000a): nonparametric \"Trim Fill\" method accounting publication bias meta-analysis. Journal American Statistical Association, 95, 89–98 Duval S & Tweedie R (2000b): Trim Fill: simple funnel-plot-based method testing adjusting publication bias meta-analysis. Biometrics, 56, 455–63 Rücker G, Schwarzer G, Carpenter JR, Binder H, Schumacher M (2011): Treatment-effect estimates adjusted small-study effects via limit meta-analysis. Biostatistics, 12, 122–42 Vevea, J. L., & Hedges, L. V. (1995). general linear model estimating effect size presence publication bias. Psychometrika, 60(3), 419–435.  ⁠https://doi.org/10.1007/BF02294384⁠","code":""},{"path":[]},{"path":"/reference/correctPublicationBias.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Correct the effect size for publication bias/small-study effects — correctPublicationBias","text":"Mathias Harrer mathias.h.harrer@gmail.com, Paula Kuper paula.r.kuper@gmail.com, Pim Cuijpers p.cuijpers@vu.nl","code":""},{"path":"/reference/correctPublicationBias.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Correct the effect size for publication bias/small-study effects — correctPublicationBias","text":"","code":"if (FALSE) { data(\"depressionPsyCtr\") depressionPsyCtr %>%   checkDataFormat() %>%   checkConflicts() %>%   calculateEffectSizes() %>%   filterPoolingData(condition_arm1 %in% c(\"cbt\", \"pst\")) %>%   runMetaAnalysis() -> res  # Correct for small-study-effects/publication bias res %>% correctPublicationBias() # Use additional arguments to control settings of the trim-and-fill # and limit meta-analysis correctPublicationBias(res,                        which.run = \"combined\",                        type = \"R\",                        method.adjust = \"mulim\")    # Generate plots correctPublicationBias(res) %>% plot(\"trimfill\") correctPublicationBias(res) %>% plot(\"limitmeta\") correctPublicationBias(res) %>% plot(\"selection\")  # Returned object is of class \"runMetaAnalysis\"; therefore, # all S3 methods are available: res <- res %>% correctPublicationBias() metaRegression(res$model.overall, ~country) }"},{"path":"/reference/createRobSummary.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a summary risk of bias plot — createRobSummary","title":"Create a summary risk of bias plot — createRobSummary","text":"rob.data argument specified, function allows create summary risk bias plot results runMetaAnalysis() function.","code":""},{"path":"/reference/createRobSummary.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a summary risk of bias plot — createRobSummary","text":"","code":"createRobSummary(model,                   name.low,                   name.high,                   name.unclear,                   which.run = model$which.run[1])"},{"path":"/reference/createRobSummary.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a summary risk of bias plot — createRobSummary","text":"model object class runMetaAnalysis, created runMetaAnalysis() function. name.low character vector, specifying code(s) used original data studies low risk bias. name.high character vector, specifying code(s) used original data studies high risk bias. name.unclear character vector, specifying code(s) used original data studies unclear risk bias. .run model model used summary risk bias plot. Uses default analysis model value specified user. Possible values \"overall\", \"combined\", \"lowest\", \"highest\", \"outliers\", \"influence\" \"rob\".","code":""},{"path":"/reference/createRobSummary.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a summary risk of bias plot — createRobSummary","text":"Creates RevMan-type risk bias summary plot.","code":""},{"path":[]},{"path":"/reference/createRobSummary.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Create a summary risk of bias plot — createRobSummary","text":"Mathias Harrer mathias.h.harrer@gmail.com, Paula Kuper paula.r.kuper@gmail.com, Pim Cuijpers p.cuijpers@vu.nl","code":""},{"path":"/reference/createRobSummary.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a summary risk of bias plot — createRobSummary","text":"","code":"if (FALSE) {   # Define ROB data to be added to the models robData = list(   # Names of ROB variables included in 'data'   domains = c(\"sg\", \"ac\", \"ba\", \"itt\"),   # Long-format labels for each ROB domain   domain.names = c(\"Sequence Generation\",                     \"Allocation Concealment\",                     \"Blinding of Assessors\",                     \"ITT Analyses\"),   # Codes used to rate the risk of bias (sr=self-report)   categories = c(\"0\", \"1\", \"sr\"),   # Symbols that should be used for these codes in forest plots   symbols = c(\"-\", \"+\", \"s\"),   # Colors to be used in forest plots for each of these codes   colors = c(\"red\", \"green\", \"yellow\"))  # Run meta-analyses with ROB data res <- depressionPsyCtr %>%    filterPoolingData(condition_arm1 %in% c(\"cbt\", \"pst\", \"3rd\")) %>%    runMetaAnalysis(rob.data = robData)  # Create a summary plot createRobSummary(res,                   name.low = \"1\",                   name.high = \"0\",                   name.unclear = \"sr\")  # Create a summary plot for the \"combined\" model # - Recode 'sr' (self-report) as low risk of bias createRobSummary(res,                   name.low = c(\"1\", \"sr\"),                   name.high = \"0\",                   name.unclear = NULL,                  which.run = \"combined\")                                     }"},{"path":"/reference/createStudyTable.html","id":null,"dir":"Reference","previous_headings":"","what":"Create study table — createStudyTable","title":"Create study table — createStudyTable","text":"function creates overview table containing selected study information.","code":""},{"path":"/reference/createStudyTable.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create study table — createStudyTable","text":"","code":"createStudyTable(.data, ...,                  .round.by.digits = NULL,                  .column.names = NULL,                  .na.replace = \"nr\",                  .html = TRUE)"},{"path":"/reference/createStudyTable.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create study table — createStudyTable","text":".data Meta-analysis study data; typically data created expandMultiarmTrials calculateEffectSizes function. Trial arm-specific information (e.g. sample size group) can added via addTrialArmInfo. See 'Details'. ... <dplyr_data_masking>. name several columns (included .data) added study table. Also allows alter individual values/factor labels within variable. See 'Details'. .round..digits named list. contain number digits round numeric column .data. name column must specified list element's name. Set NULL rounding performed (default). .column.names named list. variable names renamed producing study table, new name included list. original column name must specified name list element. Set NULL renaming performed (default). .na.replace character replace NA values ; \"nr\" default. .html logical. HTML table produced? TRUE default. See 'Details'.","code":""},{"path":"/reference/createStudyTable.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create study table — createStudyTable","text":"Returns data.frame selected variables. .html TRUE, HTML table also produced.","code":""},{"path":"/reference/createStudyTable.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create study table — createStudyTable","text":"General Purpose: function allows select variables included study table. study tables typically part meta-analysis report/article. Variables included adding names function call separating commas. columns appear exact order specified function. Trial-Arm Variables: producing final table, createStudyTable filter redundant rows based selected variables. want include information differs (two ) trial arms (e.g. sample size group) separate columns, use addTrialArmInfo first. ensures individual columns created intervention control group (e.g. N_ig N_cg), can included call createStudyTable. Changing Values: function also allows change specified values within variable. Factor levels encoded numbers, example (e.g. country = 1 European studies, forth) can changed adding concatenated (c) vector name variable. vector contain new value character left side, old value right side, separated '=' (e.g. country = c(\"Europe\" = \"1\")). values recoded producing table. HTML Table: default, createStudyTable produces HTML table using kable. HTML table makes copy & paste easier, particularly working MS Word, since table formatting kept. details see help vignette: vignette(\"metapsyTools\").","code":""},{"path":[]},{"path":"/reference/createStudyTable.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Create study table — createStudyTable","text":"Mathias Harrer mathias.h.harrer@gmail.com, Paula Kuper paula.r.kuper@gmail.com, Pim Cuijpers p.cuijpers@vu.nl","code":""},{"path":"/reference/createStudyTable.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create study table — createStudyTable","text":"","code":"if (FALSE) { # Filter out all primary outcomes, check data, # calculate effect sizes, then produce study table  # using selected information. data(\"depressionPsyCtr\")  depressionPsyCtr %>%  filterPriorityRule(    instrument = c(\"phq-9\", \"bdi-1\",                    \"hdrs\", \"ces-d\")) %>%  checkDataFormat() %>%  checkConflicts() %>%  calculateEffectSizes() %>%  createStudyTable(    study,    diagnosis = c(\"Cutoff\" = \"3\", \"Mood\" = \"2\",                  \"MDD\" = \"1\"),    age_group, instrument,    mean_age, percent_women,    condition_arm1 = c(\"CBT\" = \"cbt\", \"PST\" = \"pst\",                       \"BA\" = \"bat\", \"LR\" = \"lrt\",                       \"PDT\" = \"dyn\", \"IPT\" = \"ipt\"),    condition_arm2, n_arm1, n_arm2,    country = c(\"Canada\" = \"4\", \"Europe\" = \"3\", \"USA\" = \"1\",                \"Middle East\" = \"7\"),    sg, ac, ba, itt,    .round.by.digits = list(mean_age = 0, n_arm1 = 0,                             n_arm2 = 0),    .column.names = list(age_group = \"age group\",                         n_arm1 = \"N (arm1)\",                         n_arm2 = \"N (arm2)\",                         percent_women = \"% female\")) -> table }"},{"path":"/reference/database2021Subset.html","id":null,"dir":"Reference","previous_headings":"","what":"The 'database2021Subset' dataset — database2021Subset","title":"The 'database2021Subset' dataset — database2021Subset","text":"example dataset containing subset 2021 depression trials database. format equals format data \"Metapsy\" database.","code":""},{"path":"/reference/database2021Subset.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"The 'database2021Subset' dataset — database2021Subset","text":"","code":"data(\"database2021Subset\")"},{"path":"/reference/database2021Subset.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"The 'database2021Subset' dataset — database2021Subset","text":"data.frame 381 rows 63 variables.","code":""},{"path":"/reference/database2021Subset.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"The 'database2021Subset' dataset — database2021Subset","text":"dataset included showcase correct formatting necessary use metapsyTools.","code":""},{"path":"/reference/database2021Subset.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"The 'database2021Subset' dataset — database2021Subset","text":"Mathias Harrer, Paula Kuper, Pim Cuijpers","code":""},{"path":"/reference/depressionPsyCtr.html","id":null,"dir":"Reference","previous_headings":"","what":"The 'depressionPsyCtr' dataset — depressionPsyCtr","title":"The 'depressionPsyCtr' dataset — depressionPsyCtr","text":"example data set containing subset 2021 depression trials database. data set formatted following Metapsy data standard.","code":""},{"path":"/reference/depressionPsyCtr.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"The 'depressionPsyCtr' dataset — depressionPsyCtr","text":"","code":"data(\"depressionPsyCtr\")"},{"path":"/reference/depressionPsyCtr.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"The 'depressionPsyCtr' dataset — depressionPsyCtr","text":"data.frame 102 rows 46 variables.","code":""},{"path":"/reference/depressionPsyCtr.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"The 'depressionPsyCtr' dataset — depressionPsyCtr","text":"dataset can used runMetaAnalysis function without additional preparation required.","code":""},{"path":"/reference/depressionPsyCtr.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"The 'depressionPsyCtr' dataset — depressionPsyCtr","text":"Mathias Harrer, Paula Kuper, Clara Miguel, Pim Cuijpers","code":""},{"path":"/reference/eb.html","id":null,"dir":"Reference","previous_headings":"","what":"eb: Empirical Bayes estimates — eb","title":"eb: Empirical Bayes estimates — eb","text":"Best Linear Unbiased Predictions (BLUPs) 'runMetaAnalysis' models.","code":""},{"path":"/reference/eb.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"eb: Empirical Bayes estimates — eb","text":"","code":"eb(x, ...)"},{"path":"/reference/eb.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"eb: Empirical Bayes estimates — eb","text":"x Model ... arguments","code":""},{"path":"/reference/eb.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"eb: Empirical Bayes estimates — eb","text":"Generates empirical Bayes (EB) estimates, also known best linear unbiased predictions (BLUPs), merging fitted values obtained fixed effects estimated contributions random effects. estimates represent study-specific true effect sizes outcomes accompanied standard errors prediction interval bounds.","code":""},{"path":"/reference/eb.runMetaAnalysis.html","id":null,"dir":"Reference","previous_headings":"","what":"Best Linear Unbiased Predictions (BLUPs) for 'runMetaAnalysis' models. — eb.runMetaAnalysis","title":"Best Linear Unbiased Predictions (BLUPs) for 'runMetaAnalysis' models. — eb.runMetaAnalysis","text":"Generates empirical Bayes (EB) estimates, also known best linear unbiased predictions (BLUPs), merging fitted values obtained fixed effects estimated contributions random effects. estimates represent study-specific true effect sizes outcomes accompanied standard errors prediction interval bounds. Uses metafor::blup.rma.uni() function internally.","code":""},{"path":"/reference/eb.runMetaAnalysis.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Best Linear Unbiased Predictions (BLUPs) for 'runMetaAnalysis' models. — eb.runMetaAnalysis","text":"","code":"# S3 method for runMetaAnalysis eb(x, which = NULL, ...)"},{"path":"/reference/eb.runMetaAnalysis.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Best Linear Unbiased Predictions (BLUPs) for 'runMetaAnalysis' models. — eb.runMetaAnalysis","text":"x object class runMetaAnalysis. Model estimates printed. Can one \"overall\", \"combined\", \"lowest.highest\", \"outliers\", \"influence\", \"threelevel\", \"threelevel.che\". ... Additional arguments.","code":""},{"path":"/reference/expandMultiarmTrials.html","id":null,"dir":"Reference","previous_headings":"","what":"Expand multiarm trials — expandMultiarmTrials","title":"Expand multiarm trials — expandMultiarmTrials","text":"function expand format meta-analysis data applicability calculateEffectSizes function metapsyTools-package.","code":""},{"path":"/reference/expandMultiarmTrials.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Expand multiarm trials — expandMultiarmTrials","text":"","code":"expandMultiarmTrials(data,                      vars.for.id = c(\"study\", \"primary\",                                      \"Outc_measure\",                                      \"Time\", \"Time_weeks\",                                      \"sr_clinician\"),                      study.indicator = \"study\",                      multiarm.indicator = \"is.multiarm\",                      no.arms.indicator = \"no.arms\",                      group.indicator = \"condition\",                      condition.specification = \"Cond_spec\",                      groups.column.indicator = c(\"_trt1\", \"_trt2\"),                      group.names = list(\"ig\" = \"ig\",                                         \"cg\" = \"cg\"),                      data.format = NULL)"},{"path":"/reference/expandMultiarmTrials.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Expand multiarm trials — expandMultiarmTrials","text":"data Meta-analysis data stored data.frame. vars..id character vector, containing column names variables used construct unique comparison IDs. study.indicator character, signifying name variable containing study name. multiarm.indicator numeric, signifying row part multiarm study (1) (0). .arms.indicator character, signifying name variable containing number arms included study (typically 2). group.indicator character, column name variable storing study name. condition.specification character, column name variable storing trial condition name. groups.column.indicator character. dataset wide format: character vector two elements, representing suffix used differentiate first second treatment comparison. group.names list, storing name value corresponding intervention group (\"ig\") control group (\"cg\"). data.format character. Either \"long\" \"wide\", depending format dataset data. NULL default, lets user define format function called.","code":""},{"path":"/reference/expandMultiarmTrials.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Expand multiarm trials — expandMultiarmTrials","text":"expandMultiarmTrials returns meta-analysis data set class data.frame (results saved variable). rows multiarm studies expanded intervention group unambiguously assigned control group. also generates following columns: id comparison-specific ID variable. study.id study-specific ID variable. study study-specific variable containing study name. multiarm studies, variable also specifies active treatment indicated multiarm.group.indicator behind name study (e.g. \"Hauksson, 2017 -grp\").","code":""},{"path":"/reference/expandMultiarmTrials.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Expand multiarm trials — expandMultiarmTrials","text":"function expands multiarm studies meta-analysis data set, thereby ensuring comparison (intervention group vs. control group condition) unique specific outcome, thus two rows. purpose, duplicates corresponding row control group condition required. specific study indicator variable created enables use, e.g. 3-level models. details see help vignette: vignette(\"metapsyTools\").","code":""},{"path":[]},{"path":"/reference/expandMultiarmTrials.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Expand multiarm trials — expandMultiarmTrials","text":"Mathias Harrer mathias.h.harrer@gmail.com, Paula Kuper paula.r.kuper@gmail.com, Pim Cuijpers p.cuijpers@vu.nl","code":""},{"path":"/reference/expandMultiarmTrials.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Expand multiarm trials — expandMultiarmTrials","text":"","code":"if (FALSE) { data(\"inpatients\") expandMultiarmTrials(inpatients) }"},{"path":"/reference/exploreStudies.html","id":null,"dir":"Reference","previous_headings":"","what":"Explore included treatments and comparisons — exploreStudies","title":"Explore included treatments and comparisons — exploreStudies","text":"function allows summarize included treatments treatment comparisons data set.","code":""},{"path":"/reference/exploreStudies.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Explore included treatments and comparisons — exploreStudies","text":"","code":"exploreStudies(data,                which = c(\"treatments\", \"comparisons\"),                                # Metapsy standard variables                .study.var = \"study\",                .condition = \"condition\",                .condition.specification = \"multi\",                .groups.column.indicator = c(\"_arm1\", \"_arm2\"),                .trt.indicator = \"arm\",                .n.vars = c(\"n\", \"n_change\", \"totaln\", \"N\"),                                # Output                html = TRUE)"},{"path":"/reference/exploreStudies.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Explore included treatments and comparisons — exploreStudies","text":"data data.frame. Effect size data wide format, created calculateEffectSizes. default settings applicable, data set follow Metapsy data standard. Alternatively, one can also provide metapsyDatabase object returned metapsyData::getData(), meta-analysis object returned runMetaAnalysis(). data set summarized respect included treatments (\"treatments\") treatment comparisons (\"comparisons\")? Defaults \"treatments\". .study.var character. name variable data set study labels stored. .condition character. prefix two variables data conditions (e.g. \"guided iCBT\", \"waitlist\") trial arm comparison stored. .condition.specification character. prefix two variables dataset provide \"specification\" trial arm condition multiarm trials. .groups.column.indicator character. character vector two elements, representing suffix used differentiate first second arm comparison. .trt.indicator character. character specifying name used indicate treatment arm. .n.vars character. character vector includes names variables data set sample size information stored. prefix needed, .groups.column.indicator provides suffixes. html logical. HTML table created results? Default TRUE.","code":""},{"path":"/reference/exploreStudies.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Explore included treatments and comparisons — exploreStudies","text":"Returns object class \"exploreStudies\". object includes list object called summary counts distinct treatments (conditions) comparisons (comparisons) summarized, well data.frame  data. data frame includes initially provided data set collapsed study (row represents one study). data set, variables added encode many arms specific condition included trial (e.g. cbt=2, means two CBT groups included trial), well number distinct comparisons, sample size (columns start n.). can helpful perform descriptive analyses.","code":""},{"path":"/reference/exploreStudies.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Explore included treatments and comparisons — exploreStudies","text":"Using variables provided .n.vars argument, exploreStudies calculates arm- study-specific sample sizes. adequate information provided, sample sizes calculated study. case, warning printed, pointing studies missing sample size information.","code":""},{"path":[]},{"path":"/reference/exploreStudies.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Explore included treatments and comparisons — exploreStudies","text":"Mathias Harrer mathias.h.harrer@gmail.com, Paula Kuper paula.r.kuper@gmail.com, Pim Cuijpers p.cuijpers@vu.nl","code":""},{"path":"/reference/exploreStudies.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Explore included treatments and comparisons — exploreStudies","text":"","code":"if (FALSE) { # Explore studies in built-in dataset data(\"depressionPsyCtr\") exploreStudies(depressionPsyCtr, \"treatments\")  exploreStudies(depressionPsyCtr, \"comparisons\")   # - Extract metapsy database using metapsyData # - Filter CBT and PST studies # - Run a meta-analysis and explore synthesize studies library(metapsyData) getData(\"depression-psyctr\", version=\"22.0.2\") %>%    filterPoolingData(condition_arm1 %in% c(\"cbt\", \"pst\")) %>%    runMetaAnalysis(which.run = c(\"combined\")) -> res  exploreStudies(res) exploreStudies(res, \"comparisons\") }"},{"path":"/reference/extractG.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract Hedges g values — extractG","title":"Extract Hedges g values — extractG","text":"Extract Hedges g values","code":""},{"path":"/reference/extractG.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract Hedges g values — extractG","text":"","code":"extractG(x)"},{"path":"/reference/extractG.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract Hedges g values — extractG","text":"x data.frame effect size results.","code":""},{"path":"/reference/filterPoolingData.html","id":null,"dir":"Reference","previous_headings":"","what":"Filter data to be pooled for meta-analysis — filterPoolingData","title":"Filter data to be pooled for meta-analysis — filterPoolingData","text":"convenience function allows create filtered data set, ready used meta-analytic pooling.","code":""},{"path":"/reference/filterPoolingData.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Filter data to be pooled for meta-analysis — filterPoolingData","text":"","code":"filterPoolingData(.data, ...,                   .filter.missing.rows = FALSE,                   .es.column = es)"},{"path":"/reference/filterPoolingData.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Filter data to be pooled for meta-analysis — filterPoolingData","text":".data data.frame containing calculated effect sizes, created calculateEffectSizes function. ... <dplyr_data_masking>. number filtering statements (using variables .data) return logical value. apply multiple filters, simply separate using comma. \"\" statements can provided using | operator. Multiple filter statements separated using commas combined using (&) operator. See \"Details\". .filter.missing.rows logical. rows effect sizes filtered ? Default FALSE. .es.column Name column .data used filtering rows effect sizes. Default es.","code":""},{"path":"/reference/filterPoolingData.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Filter data to be pooled for meta-analysis — filterPoolingData","text":"filterPoolingData returns filtered data set class data.frame. filtered data set ready meta-analytic pooling, example using runMetaAnalysis().","code":""},{"path":"/reference/filterPoolingData.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Filter data to be pooled for meta-analysis — filterPoolingData","text":"filterPoolingData function allows apply several filters meta-analysis data set . used pipe (%>%), need supply several filtering statements separated commas, using column names appear data set (e.g. primary == 1, meanage == 58). filtering statements connected using \"\" (&). want apply \"\" filter, simply use | instead comma (e.g. type == \"cbt\" | format == 6). select rows contain one several values variable, use %%; e.g. study %% c(\"Bailey, 2017\", \"Barth 2005\"). Detect function can used within function call search variable elements contain one several selected words (separated |). include rows contain word \"cbt\" \"wl\" \"cau\" \"Cond_spec_trt2\" variable, can use Detect(Cond_spect_trt2, \"cbt|wl|cau\"). also filter elements like \"cbt (online)\", \"cbt\" included. details see Get Started vignette.","code":""},{"path":[]},{"path":"/reference/filterPoolingData.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Filter data to be pooled for meta-analysis — filterPoolingData","text":"Mathias Harrer mathias.h.harrer@gmail.com, Paula Kuper paula.r.kuper@gmail.com, Pim Cuijpers p.cuijpers@vu.nl","code":""},{"path":"/reference/filterPoolingData.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Filter data to be pooled for meta-analysis — filterPoolingData","text":"","code":"if (FALSE) {  # Example 1: calculate effect sizes and then use multiple AND filters. data(\"depressionPsyCtr\") depressionPsyCtr %>%   calculateEffectSizes() %>%   filterPoolingData(time == \"post\", instrument == \"hdrs\")  # Example 2: use OR filter data(\"depressionPsyCtr\") depressionPsyCtr %>%   calculateEffectSizes() %>%   filterPoolingData(time == \"post\" | instrument == \"hdrs\")  # Example 3: use %in% operator data(\"depressionPsyCtr\") depressionPsyCtr %>%   calculateEffectSizes() %>%   filterPoolingData(instrument %in% c(\"hdrs\", \"phq-9\"))  # Example 4: Search for studies using \"fuzzy-ish\" matching data(\"depressionPsyCtr\") depressionPsyCtr %>%   calculateEffectSizes() %>%   filterPoolingData(Detect(instrument, \"bdi\")) }"},{"path":"/reference/filterPriorityRule.html","id":null,"dir":"Reference","previous_headings":"","what":"Filter data based on a priority rule — filterPriorityRule","title":"Filter data based on a priority rule — filterPriorityRule","text":"function filters rows dataset based priority rule specific variables defined user.","code":""},{"path":"/reference/filterPriorityRule.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Filter data based on a priority rule — filterPriorityRule","text":"","code":"filterPriorityRule(.data, ..., .study.indicator = \"study\")"},{"path":"/reference/filterPriorityRule.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Filter data based on a priority rule — filterPriorityRule","text":".data data.frame containing calculated effect sizes, created calculateEffectSizes function. ... <dplyr_data_masking>. number prioritized filtering rules variables. follow form variable = c(\"prio1\", \"prio2\", ...). apply multiple priority filters, simply separate using comma. study, rows selected based specified hierarchy variable. priorities provided concatenated vector, representing variable levels. level appear first vector highest priority, second one second-largest priority, . study contains none variable levels specified function call, study omitted entirely. .study.indicator character. Name variable study IDs stored.","code":""},{"path":"/reference/filterPriorityRule.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Filter data based on a priority rule — filterPriorityRule","text":"filterPriorityRule returns filtered data set class data.frame. filtered data set ready meta-analytic pooling, example using metagen. filters can applied using filterPoolingData.","code":""},{"path":[]},{"path":"/reference/filterPriorityRule.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Filter data based on a priority rule — filterPriorityRule","text":"Mathias Harrer mathias.h.harrer@gmail.com, Paula Kuper paula.r.kuper@gmail.com, Pim Cuijpers p.cuijpers@vu.nl","code":""},{"path":"/reference/filterPriorityRule.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Filter data based on a priority rule — filterPriorityRule","text":"","code":"if (FALSE) { # Load data and calculate effect size data(\"depressionPsyCtr\") depressionPsyCtr %>%   checkDataFormat() %>%   checkConflicts() %>%   calculateEffectSizes() -> data  # Filter using four priority rules filterPriorityRule(data,                    condition_arm1 = c(\"cbt\", \"pst\"),                    condition_arm2 = c(\"cau\", \"wl\", \"cbt\"),                    instrument = c(\"cesd\", \"phq-9\", \"scl\", \"hdrs\"),                    time = c(\"post\", \"fu\")) -> res }"},{"path":"/reference/fitCombinedHACEModel.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit 'combined' complex model — fitCombinedHACEModel","title":"Fit 'combined' complex model — fitCombinedHACEModel","text":"Fit 'combined' complex model","code":""},{"path":"/reference/fitCombinedHACEModel.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit 'combined' complex model — fitCombinedHACEModel","text":"","code":"fitCombinedHACEModel(   which.combine,   which.combine.var,   measure.var,   data,   study.var,   multi.study,   es.var,   se.var,   mGeneral,   .type.es,   round.digits,   hakn,   .raw.bin.es,   nnt.cer,   rho.within.study,   method.tau,   method.tau.ci,   dots,   es.binary.raw.vars,   arm.var.1,   arm.var.2,   phi.within.study,   n.var.arm1,   n.var.arm2,   w1.var,   w2.var,   time.var,   near.pd,   rob.data )"},{"path":"/reference/fitCombinedModel.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit 'combined' model — fitCombinedModel","title":"Fit 'combined' model — fitCombinedModel","text":"Fit 'combined' model","code":""},{"path":"/reference/fitCombinedModel.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit 'combined' model — fitCombinedModel","text":"","code":"fitCombinedModel(   which.combine,   which.combine.var,   data,   study.var,   multi.study,   es.var,   se.var,   mGeneral,   .type.es,   round.digits,   hakn,   .raw.bin.es,   nnt.cer,   rho.within.study,   method.tau,   method.tau.ci,   dots,   es.binary.raw.vars,   phi.within.study,   rob.data )"},{"path":"/reference/fitHighestModel.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit 'highest' model — fitHighestModel","title":"Fit 'highest' model — fitHighestModel","text":"Fit 'highest' model","code":""},{"path":"/reference/fitHighestModel.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit 'highest' model — fitHighestModel","text":"","code":"fitHighestModel(   data,   study.var,   multi.study,   mGeneral,   .type.es,   round.digits,   .raw.bin.es,   nnt.cer,   rob.data )"},{"path":"/reference/fitInfluenceModel.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit 'influence' model — fitInfluenceModel","title":"Fit 'influence' model — fitInfluenceModel","text":"Fit 'influence' model","code":""},{"path":"/reference/fitInfluenceModel.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit 'influence' model — fitInfluenceModel","text":"","code":"fitInfluenceModel(   which.influence,   mComb,   mGeneral,   which.run,   method.tau,   .raw.bin.es,   .type.es,   round.digits,   nnt.cer,   rob.data )"},{"path":"/reference/fitLowestModel.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit 'lowest' model — fitLowestModel","title":"Fit 'lowest' model — fitLowestModel","text":"Fit 'lowest' model","code":""},{"path":"/reference/fitLowestModel.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit 'lowest' model — fitLowestModel","text":"","code":"fitLowestModel(   data,   study.var,   multi.study,   mGeneral,   .type.es,   round.digits,   .raw.bin.es,   nnt.cer,   rob.data )"},{"path":"/reference/fitOutliersModel.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit 'outliers' model — fitOutliersModel","title":"Fit 'outliers' model — fitOutliersModel","text":"Fit 'outliers' model","code":""},{"path":"/reference/fitOutliersModel.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit 'outliers' model — fitOutliersModel","text":"","code":"fitOutliersModel(   data,   study.var,   multi.study,   mGeneral,   .type.es,   round.digits,   .raw.bin.es,   nnt.cer,   which.run,   which.outliers,   method.tau,   m.for.outliers,   rob.data )"},{"path":"/reference/fitOverallModel.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit 'overall' model — fitOverallModel","title":"Fit 'overall' model — fitOverallModel","text":"Fit 'overall' model","code":""},{"path":"/reference/fitOverallModel.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit 'overall' model — fitOverallModel","text":"","code":"fitOverallModel(   data,   es.var,   se.var,   arm.var.1,   arm.var.2,   measure.var,   study.var,   .raw.bin.es,   .type.es,   hakn,   method.tau.meta,   method.tau.ci,   method.tau,   dots,   es.binary.raw.vars,   round.digits,   nnt.cer,   which.run,   rob.data )"},{"path":"/reference/fitRobModel.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit 'rob' model — fitRobModel","title":"Fit 'rob' model — fitRobModel","text":"Fit 'rob' model","code":""},{"path":"/reference/fitRobModel.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit 'rob' model — fitRobModel","text":"","code":"fitRobModel(   which.run,   which.rob,   which.outliers,   mGeneral,   mComb,   low.rob.filter,   method.tau,   .raw.bin.es,   .type.es,   round.digits,   nnt.cer,   rob.data )"},{"path":"/reference/fitThreeLevelCHEModel.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit 'threelevel.che' model — fitThreeLevelCHEModel","title":"Fit 'threelevel.che' model — fitThreeLevelCHEModel","text":"Fit 'threelevel.che' model","code":""},{"path":"/reference/fitThreeLevelCHEModel.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit 'threelevel.che' model — fitThreeLevelCHEModel","text":"","code":"fitThreeLevelCHEModel(   data,   es.var,   se.var,   arm.var.1,   arm.var.2,   measure.var,   study.var,   .raw.bin.es,   .type.es,   hakn,   method.tau.meta,   method.tau.ci,   method.tau,   dots,   es.binary.raw.vars,   round.digits,   nnt.cer,   which.run,   mGeneral,   mCombined,   use.rve,   rho.within.study,   phi.within.study,   i2.ci.boot,   nsim.boot )"},{"path":"/reference/fitThreeLevelHACEModel.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit 'threelevel' complex model — fitThreeLevelHACEModel","title":"Fit 'threelevel' complex model — fitThreeLevelHACEModel","text":"Fit 'threelevel' complex model","code":""},{"path":"/reference/fitThreeLevelHACEModel.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit 'threelevel' complex model — fitThreeLevelHACEModel","text":"","code":"fitThreeLevelHACEModel(   data,   es.var,   se.var,   arm.var.1,   arm.var.2,   measure.var,   study.var,   .raw.bin.es,   .type.es,   hakn,   method.tau.meta,   method.tau.ci,   method.tau,   dots,   es.binary.raw.vars,   round.digits,   nnt.cer,   which.run,   mGeneral,   mCombined,   use.rve,   rho.within.study,   which.combine.var,   phi.within.study,   n.var.arm1,   n.var.arm2,   w1.var,   w2.var,   time.var,   near.pd,   i2.ci.boot,   nsim.boot )"},{"path":"/reference/fitThreeLevelModel.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit 'threelevel' model — fitThreeLevelModel","title":"Fit 'threelevel' model — fitThreeLevelModel","text":"Fit 'threelevel' model","code":""},{"path":"/reference/fitThreeLevelModel.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit 'threelevel' model — fitThreeLevelModel","text":"","code":"fitThreeLevelModel(   data,   es.var,   se.var,   arm.var.1,   arm.var.2,   measure.var,   study.var,   .raw.bin.es,   .type.es,   hakn,   method.tau.meta,   method.tau.ci,   method.tau,   dots,   es.binary.raw.vars,   round.digits,   nnt.cer,   which.run,   mGeneral,   mCombined,   use.rve,   i2.ci.boot,   nsim.boot )"},{"path":"/reference/forestBlup.html","id":null,"dir":"Reference","previous_headings":"","what":"Function to generate forest plots with EB estimates — forestBlup","title":"Function to generate forest plots with EB estimates — forestBlup","text":"Function generate forest plots EB estimates","code":""},{"path":"/reference/forestBlup.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Function to generate forest plots with EB estimates — forestBlup","text":"","code":"forestBlup(   model,   which = NULL,   col.line = \"#a7a9ac\",   col.polygon = \"#6b58a6\",   leftlab = \"Study\",   rightlab = \"g [95% CI]\",   summarylab = \"Total (95% CI)\",   sort = TRUE,   hetstat = TRUE,   eb.labels = TRUE )"},{"path":"/reference/forestBlupPlotter.html","id":null,"dir":"Reference","previous_headings":"","what":"Internal helper function to generate forest plots with EB estimates — forestBlupPlotter","title":"Internal helper function to generate forest plots with EB estimates — forestBlupPlotter","text":"Internal helper function generate forest plots EB estimates","code":""},{"path":"/reference/forestBlupPlotter.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Internal helper function to generate forest plots with EB estimates — forestBlupPlotter","text":"","code":"forestBlupPlotter(   dat,   res,   sort,   col.line,   col.polygon,   hetstat,   leftlab,   rightlab,   summarylab,   M.3l,   threeLevel,   eb.labels )"},{"path":"/reference/forestBlupPlotter.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Internal helper function to generate forest plots with EB estimates — forestBlupPlotter","text":"Parts code function based van Aert et al. (2021; Supplement).","code":""},{"path":"/reference/forestBlupPlotter.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Internal helper function to generate forest plots with EB estimates — forestBlupPlotter","text":"van Aert, R. C., Schmid, C. H., Svensson, D., & Jackson, D. (2021). Study specific prediction intervals random-effects meta-analysis: tutorial: Prediction intervals meta-analysis. Research Synthesis Methods, 12(4), 429-447.","code":""},{"path":"/reference/g.binary.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate Hedges' g using binary outcome data — g.binary","title":"Calculate Hedges' g using binary outcome data — g.binary","text":"Calculates Hedges' g binary outcome data. meant used part calculateEffectSizes.","code":""},{"path":"/reference/g.binary.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate Hedges' g using binary outcome data — g.binary","text":"","code":"g.binary(x, cc = 0.5, ...)"},{"path":"/reference/g.binary.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate Hedges' g using binary outcome data — g.binary","text":"x data cc continuity correction zero cells applied? Either FALSE increment added. Default 0.5. ... Binary effect size data. Data frame must include columns event_arm1, event_arm2, totaln_arm1, totaln_arm2. See Metapsy data standard.","code":""},{"path":"/reference/g.change.m.sd.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate Hedges' g using within-group change data — g.change.m.sd","title":"Calculate Hedges' g using within-group change data — g.change.m.sd","text":"Calculate Hedges' g based change data. meant used part calculateEffectSizes.","code":""},{"path":"/reference/g.change.m.sd.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate Hedges' g using within-group change data — g.change.m.sd","text":"","code":"g.change.m.sd(x, ...)"},{"path":"/reference/g.change.m.sd.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate Hedges' g using within-group change data — g.change.m.sd","text":"x data ... Change score effect size data. Data frame must include columns mean_change_arm1, mean_change_arm2, sd_change_arm1, sd_change_arm2, n_change_arm1, n_change_arm2. See Metapsy data standard.","code":""},{"path":"/reference/g.m.sd.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate Hedges' g using means and standard deviations — g.m.sd","title":"Calculate Hedges' g using means and standard deviations — g.m.sd","text":"Calculate Hedges' g using Mean Standard Deviation. meant used part calculateEffectSizes.","code":""},{"path":"/reference/g.m.sd.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate Hedges' g using means and standard deviations — g.m.sd","text":"","code":"g.m.sd(x, ...)"},{"path":"/reference/g.m.sd.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate Hedges' g using means and standard deviations — g.m.sd","text":"x data ... Effect size data. Data frame must include columns mean_arm1, mean_arm2, sd_arm1, sd_arm2, n_arm1, n_arm2. See Metapsy data standard.","code":""},{"path":"/reference/g.precalc.html","id":null,"dir":"Reference","previous_headings":"","what":"Forward pre-calculated values of Hedges' g — g.precalc","title":"Forward pre-calculated values of Hedges' g — g.precalc","text":"Forwards pre-calculated values Hedges' g. meant used part calculateEffectSizes.","code":""},{"path":"/reference/g.precalc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Forward pre-calculated values of Hedges' g — g.precalc","text":"","code":"g.precalc(x, ...)"},{"path":"/reference/g.precalc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Forward pre-calculated values of Hedges' g — g.precalc","text":"x data ... Pre-calculated effect size data. Data frame must include columns precalc_g precalc_g_se. See Metapsy data standard.","code":""},{"path":"/reference/i2.gen.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute I-squared from tau2 using the ","title":"Compute I-squared from tau2 using the ","text":"Compute -squared tau2 using \"generalized\" formula (used, e.g., metafor). formula uses estimate \"typical\" within-study variance (v-tilde).","code":""},{"path":"/reference/i2.gen.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute I-squared from tau2 using the ","text":"","code":"i2.gen(tau2, k, vi)"},{"path":"/reference/imputeResponse.html","id":null,"dir":"Reference","previous_headings":"","what":"Impute response rates based on continuous outcome data — imputeResponse","title":"Impute response rates based on continuous outcome data — imputeResponse","text":"function allows impute response rates based post-test means, standard deviations sample size using normal-approximation method Furukawa et al. (2005). Response rates can imputed using 50% symptom decrease threshold, user-defined cut-values, reliable change index (Jacobson & Truax, 1991).","code":""},{"path":"/reference/imputeResponse.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Impute response rates based on continuous outcome data — imputeResponse","text":"","code":"imputeResponse(m.trt.pre, m.trt.post, sd.trt.post, n.trt,                 m.ctr.pre, m.ctr.post, sd.ctr.post, n.ctr,                sd.trt.pre, sd.ctr.pre,                 rho = 0.8, cutoff = NULL, lower.is.better = TRUE,                method = c(\"cutpoint\", \"rci\"))"},{"path":"/reference/imputeResponse.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Impute response rates based on continuous outcome data — imputeResponse","text":"m.trt.pre Pre-test mean (treatment) arm. m.trt.post Post-test mean (treatment) arm. sd.trt.post Post-test standard deviation (treatment) arm. n.trt Sample size (treatment) arm. m.ctr.pre Optional. Pre-test mean control arm. m.ctr.post Optional. Post-test mean control arm. sd.ctr.post Optional. Post-test standard deviation control arm. n.ctr Optional. Sample size control arm. sd.trt.pre Pre-test standard deviation (treatment) group. Required method = \"rci\". sd.ctr.pre Optional. Pre-test standard deviation control group. Required method = \"rci\". rho Reliability coefficient, used calculate reliable change method = \"rci\". Set 0.8 default. cutoff User defined cut-score response. NULL default, means 50% symptom decrease used response criterion. lower..better lower values indicate better outcomes (e.g. less depression)? TRUE default. method Method define response. Either \"cutpoint\" (default; uses 50% symptom decrease criterion, user-specified score cutoff) \"rci\", means reliable change index (Jacobson & Truax, 1991) used.","code":""},{"path":"/reference/imputeResponse.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Impute response rates based on continuous outcome data — imputeResponse","text":"values treatment arm specified, imputeResponse returns data.frame two columns: trtResponder: Number responders nTrt: Total sample size treatment arm values also specified control group, six additional columns returned: ctrResponder: Number responders control group nCtr: Total sample size treatment arm logRR: Log-risk ratio difference response rates arms seLogRR: Standard error log-risk ratio logOR: Log-odds ratio difference response rates arms seLogOR: Standard error log-odds ratio","code":""},{"path":"/reference/imputeResponse.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Impute response rates based on continuous outcome data — imputeResponse","text":"details see Get Started vignette.","code":""},{"path":"/reference/imputeResponse.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Impute response rates based on continuous outcome data — imputeResponse","text":"Furukawa, T. ., Cipriani, ., Barbui, C., Brambilla, P., & Watanabe, N. (2005). Imputing response rates means standard deviations meta-analyses. International Clinical Psychopharmacology, 20(1), 49-52. Jacobson, N. S., & Truax, P. (1991). Clinical significance: statistical approach defining meaningful change psychotherapy research. Journal Consulting Clinical Psychology, 59(1), 12–19. https://doi.org/10.1037//0022-006x.59.1.12","code":""},{"path":[]},{"path":"/reference/imputeResponse.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Impute response rates based on continuous outcome data — imputeResponse","text":"Mathias Harrer mathias.h.harrer@gmail.com","code":""},{"path":"/reference/imputeResponse.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Impute response rates based on continuous outcome data — imputeResponse","text":"","code":"if (FALSE) {  # Calculate response using 50% method for one group. imputeResponse(m.trt.pre = 20, m.trt.post = 11,                sd.trt.post = 7, n.trt = 100)  # Calculate response for two groups and calculate effect sizes imputeResponse(m.trt.pre = 20, m.trt.post = 11,                sd.trt.post = 7, n.trt = 100,                m.ctr.pre = 20, m.ctr.post = 18,                sd.ctr.post = 6, n.ctr = 120)  # Calculate using user-defined response threshold imputeResponse(m.trt.pre = 20, m.trt.post = 11,                sd.trt.post = 7, n.trt = 100,                m.ctr.pre = 20, m.ctr.post = 18,                sd.ctr.post = 6, n.ctr = 120,                cutoff = 15)  # Assuming higher outcomes are better... imputeResponse(m.trt.pre = 20, m.trt.post = 11,                sd.trt.post = 7, n.trt = 100,                m.ctr.pre = 20, m.ctr.post = 18,                sd.ctr.post = 6, n.ctr = 120,                cutoff = 15, lower.is.better = FALSE)  # Using RCI, with an assumed reliability of 0.88 imputeResponse(m.trt.pre = 20, m.trt.post = 11,                sd.trt.post = 7, n.trt = 100,                m.ctr.pre = 20, m.ctr.post = 18,                sd.ctr.post = 6, n.ctr = 120,                method = \"rci\", rho = 0.88,                sd.trt.pre = 8)  # Using a different pre-test SD in the control imputeResponse(m.trt.pre = 20, m.trt.post = 11,                sd.trt.post = 7, n.trt = 100,                m.ctr.pre = 20, m.ctr.post = 18,                sd.ctr.post = 6, n.ctr = 120,                method = \"rci\", rho = 0.88,                sd.trt.pre = 8, sd.ctr.pre = 9)  # Calculating many results at the same time set.seed(123) imputeResponse(m.trt.pre = runif(10, 10, 30), m.trt.post = runif(10, 8, 14),                sd.trt.post = runif(10, 5, 8), n.trt = rpois(10, 150),                m.ctr.pre = runif(10, 10, 30), m.ctr.post = runif(10, 13, 20),                sd.ctr.post = runif(10, 5, 8), n.ctr = rpois(10, 150),                method = \"rci\", rho = round(runif(10, 70, 90))/100,                sd.trt.pre = runif(10, 7, 9))  set.seed(123) imputeResponse(m.trt.pre = runif(10, 10, 30), m.trt.post = runif(10, 8, 14),                sd.trt.post = runif(10, 5, 8), n.trt = rpois(10, 150),                m.ctr.pre = runif(10, 10, 30), m.ctr.post = runif(10, 13, 20),                sd.ctr.post = runif(10, 5, 8), n.ctr = rpois(10, 150))  set.seed(123) imputeResponse(m.trt.pre = runif(10, 10, 30), m.trt.post = runif(10, 8, 14),                sd.trt.post = runif(10, 5, 8), n.trt = rpois(10, 150),                cutoff = 11:20) }"},{"path":"/reference/includeSwitchedArms.html","id":null,"dir":"Reference","previous_headings":"","what":"Include information of rows with switched reference group — includeSwitchedArms","title":"Include information of rows with switched reference group — includeSwitchedArms","text":"Adds effect size data study information rows switched reference arms.","code":""},{"path":"/reference/includeSwitchedArms.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Include information of rows with switched reference group — includeSwitchedArms","text":"","code":"includeSwitchedArms(dat, ...)"},{"path":"/reference/includeSwitchedArms.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Include information of rows with switched reference group — includeSwitchedArms","text":"dat Data set created calculateEffectSizes wider format, includes calculated effect sizes standard errors columns es se, respectively. data sets created calculateEffectSizes trt.indicator set \"trt\" can used. ... arguments (used).","code":""},{"path":"/reference/inpatients.html","id":null,"dir":"Reference","previous_headings":"","what":"The 'inpatients' dataset with 32 clinical trials — inpatients","title":"The 'inpatients' dataset with 32 clinical trials — inpatients","text":"example dataset containing data 32 clinical trials. format equals format data \"metapsy\" database similar long format R. dataset also contains columns study characteristics important effect size calculation .","code":""},{"path":"/reference/inpatients.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"The 'inpatients' dataset with 32 clinical trials — inpatients","text":"","code":"data(\"inpatients\")"},{"path":"/reference/inpatients.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"The 'inpatients' dataset with 32 clinical trials — inpatients","text":"data.frame 179 rows 46 variables: study character, study label containing author(s) year study. condition character, condition groups, either \"intervention group\" \"control group\". Cond_spec character, specific intervention conditions. .multiarm numeric, dichotomized indication study multiple arms . .arms numeric, number arms study. multiple.arms character, specification arms multiarm studies. Outc_type character, type outcome. primary numeric, indication outcome primary . Outc_measure character, outcome measure used. Time character, dichotomized time assessment, either \"post\" \"FU\". Time_weeks character, assessment time FU weeks. year numeric, year study. country character, country study. ...","code":""},{"path":"/reference/inpatients.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"The 'inpatients' dataset with 32 clinical trials — inpatients","text":"Mathias Harrer, Paula Kuper, Pim Cuijpers","code":""},{"path":"/reference/isNAorNaN.html","id":null,"dir":"Reference","previous_headings":"","what":"Tests if value is NA or NaN — isNAorNaN","title":"Tests if value is NA or NaN — isNAorNaN","text":"Tests value NA NaN","code":""},{"path":"/reference/isNAorNaN.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Tests if value is NA or NaN — isNAorNaN","text":"","code":"isNAorNaN(x)"},{"path":"/reference/isNAorNaN.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Tests if value is NA or NaN — isNAorNaN","text":"expr R expression.","code":""},{"path":"/reference/meanSD.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate Hedges' g using Mean and Standard Deviation. — meanSD","title":"Calculate Hedges' g using Mean and Standard Deviation. — meanSD","text":"Calculate Hedges' g using Mean Standard Deviation. meant used part calculateEffectSizes.","code":""},{"path":"/reference/meanSD.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate Hedges' g using Mean and Standard Deviation. — meanSD","text":"","code":"meanSD(x, ...)"},{"path":"/reference/meanSD.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate Hedges' g using Mean and Standard Deviation. — meanSD","text":"x data ... Effect size data. Must Post_M_trt1, Post_M_trt2, Post_SD_trt1, Post_SD_trt2, Post_N_trt1, Post_N_trt2 (numeric).","code":""},{"path":"/reference/metaRegression.html","id":null,"dir":"Reference","previous_headings":"","what":"Meta-Regression method for objects of class 'runMetaAnalysis' — metaRegression","title":"Meta-Regression method for objects of class 'runMetaAnalysis' — metaRegression","text":"Serves wrapper metareg update.rma, depending class fitted model.","code":""},{"path":"/reference/metaRegression.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Meta-Regression method for objects of class 'runMetaAnalysis' — metaRegression","text":"","code":"metaRegression(x, ...)"},{"path":"/reference/metaRegression.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Meta-Regression method for objects of class 'runMetaAnalysis' — metaRegression","text":"x model extracted object class runMetaAnalysis. ... Additional arguments.","code":""},{"path":"/reference/metaRegression.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Meta-Regression method for objects of class 'runMetaAnalysis' — metaRegression","text":"Mathias Harrer mathias.h.harrer@gmail.com, Paula Kuper paula.r.kuper@gmail.com, Pim Cuijpers p.cuijpers@vu.nl","code":""},{"path":"/reference/metaRegression.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Meta-Regression method for objects of class 'runMetaAnalysis' — metaRegression","text":"","code":"if (FALSE) { metaRegression(res$model.combined, ~ rob + scale(year)) }"},{"path":"/reference/metaRegression.meta.html","id":null,"dir":"Reference","previous_headings":"","what":"Meta-Regression method for objects of class 'runMetaAnalysis' — metaRegression.meta","title":"Meta-Regression method for objects of class 'runMetaAnalysis' — metaRegression.meta","text":"Serves wrapper metareg.","code":""},{"path":"/reference/metaRegression.meta.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Meta-Regression method for objects of class 'runMetaAnalysis' — metaRegression.meta","text":"","code":"# S3 method for meta metaRegression(x, formula = NULL, ...)"},{"path":"/reference/metaRegression.meta.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Meta-Regression method for objects of class 'runMetaAnalysis' — metaRegression.meta","text":"x model extracted object class runMetaAnalysis. formula formula object describing predictor(s) added model. Default NULL. ... Additional arguments.","code":""},{"path":"/reference/metaRegression.meta.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Meta-Regression method for objects of class 'runMetaAnalysis' — metaRegression.meta","text":"Mathias Harrer mathias.h.harrer@gmail.com, Paula Kuper paula.r.kuper@gmail.com, Pim Cuijpers p.cuijpers@vu.nl","code":""},{"path":"/reference/metaRegression.rma.html","id":null,"dir":"Reference","previous_headings":"","what":"Meta-Regression method for objects of class 'runMetaAnalysis' — metaRegression.rma","title":"Meta-Regression method for objects of class 'runMetaAnalysis' — metaRegression.rma","text":"Serves wrapper update.rma.","code":""},{"path":"/reference/metaRegression.rma.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Meta-Regression method for objects of class 'runMetaAnalysis' — metaRegression.rma","text":"","code":"# S3 method for rma metaRegression(x, formula = NULL, ...)"},{"path":"/reference/metaRegression.rma.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Meta-Regression method for objects of class 'runMetaAnalysis' — metaRegression.rma","text":"x model extracted object class runMetaAnalysis. formula formula object describing predictor(s) added model. Default NULL. ... Additional arguments.","code":""},{"path":"/reference/metaRegression.rma.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Meta-Regression method for objects of class 'runMetaAnalysis' — metaRegression.rma","text":"Mathias Harrer mathias.h.harrer@gmail.com, Paula Kuper paula.r.kuper@gmail.com, Pim Cuijpers p.cuijpers@vu.nl","code":""},{"path":"/reference/metaRegression.runMetaAnalysis.html","id":null,"dir":"Reference","previous_headings":"","what":"Meta-Regression method for objects of class 'runMetaAnalysis' — metaRegression.runMetaAnalysis","title":"Meta-Regression method for objects of class 'runMetaAnalysis' — metaRegression.runMetaAnalysis","text":"Prints information models extracted runMetaAnalysis results objects run meta-regression.s","code":""},{"path":"/reference/metaRegression.runMetaAnalysis.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Meta-Regression method for objects of class 'runMetaAnalysis' — metaRegression.runMetaAnalysis","text":"","code":"# S3 method for runMetaAnalysis metaRegression(x, formula = NULL, ...)"},{"path":"/reference/metaRegression.runMetaAnalysis.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Meta-Regression method for objects of class 'runMetaAnalysis' — metaRegression.runMetaAnalysis","text":"x object class runMetaAnalysis. formula used. ... Additional arguments.","code":""},{"path":"/reference/metaRegression.runMetaAnalysis.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Meta-Regression method for objects of class 'runMetaAnalysis' — metaRegression.runMetaAnalysis","text":"Mathias Harrer mathias.h.harrer@gmail.com, Paula Kuper paula.r.kuper@gmail.com, Pim Cuijpers p.cuijpers@vu.nl","code":""},{"path":"/reference/metapsyFindOutliers.html","id":null,"dir":"Reference","previous_headings":"","what":"Find Statistical Outliers in a Meta-Analysis — metapsyFindOutliers","title":"Find Statistical Outliers in a Meta-Analysis — metapsyFindOutliers","text":"Searches statistical outliers meta-analysis results generated meta functions rma.uni metafor package.","code":""},{"path":"/reference/metapsyFindOutliers.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Find Statistical Outliers in a Meta-Analysis — metapsyFindOutliers","text":"","code":"metapsyFindOutliers(x, ...)"},{"path":"/reference/metapsyFindOutliers.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Find Statistical Outliers in a Meta-Analysis — metapsyFindOutliers","text":"x Either (1) object class meta, generated metabin, metagen, metacont, metacor, metainc, metarate metaprop function; (2) object class rma.uni created rma.uni function metafor. ... Additional parameters rma.uni update.meta function.","code":""},{"path":"/reference/metapsyFindOutliers.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Find Statistical Outliers in a Meta-Analysis — metapsyFindOutliers","text":"Returns identified outliers meta-analysis results outliers removed. provided meta-analysis object class meta, following objects returned results function saved another object: .study.fixed: numeric vector containing names outlying studies assuming fixed-effect model. .study.random: numeric vector containing names outlying studies assuming random-effects model. \\(\\tau^{2}\\) estimator method.tau inherited x. m.fixed: object class meta containing results meta-analysis outliers removed (assuming fixed-effect model). m.random: object class meta containing results meta-analysis outliers removed (assuming random-effects model, using method.tau original analysis). provided meta-analysis object class rma.uni, following objects returned results function saved another object: .study: numeric vector containing names outlying studies. m: object class rma.uni containing results meta-analysis outliers removed (using settings meta-analysis object provided).","code":""},{"path":"/reference/metapsyFindOutliers.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Find Statistical Outliers in a Meta-Analysis — metapsyFindOutliers","text":"function searches outlying studies meta-analysis results object. Studies defined outliers 95\\ outliers found, function automatically recalculates meta-analysis results, using settings object provided x, excluding detected outliers. forest plot meta-analysis outliers removed can generated directly plugging output function forest function.","code":""},{"path":"/reference/metapsyFindOutliers.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Find Statistical Outliers in a Meta-Analysis — metapsyFindOutliers","text":"Harrer, M., Cuijpers, P., Furukawa, T., & Ebert, D. D. (2019). Meta-Analysis R: Hands-Guide. DOI: 10.5281/zenodo.2551803. Chapter 6.2","code":""},{"path":[]},{"path":"/reference/metapsyFindOutliers.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Find Statistical Outliers in a Meta-Analysis — metapsyFindOutliers","text":"Mathias Harrer & David Daniel Ebert","code":""},{"path":"/reference/metapsyFindOutliers.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Find Statistical Outliers in a Meta-Analysis — metapsyFindOutliers","text":"","code":"if (FALSE) { suppressPackageStartupMessages(library(meta)) suppressPackageStartupMessages(library(metafor)) suppressPackageStartupMessages(library(dmetar))  # Pool with meta m1 <- metagen(TE, seTE, data = ThirdWave,               studlab = ThirdWave$Author, comb.fixed = FALSE)  # Pool with metafor m2 <- rma(yi = TE, sei = seTE, data = ThirdWave,           slab = ThirdWave$Author, method = \"PM\")  # Find outliers fo1 <- find.outliers(m1) fo2 <- find.outliers(m2)  # Show summary summary(fo1) summary(fo2)  # Make forest plot # Pass additional arguments from meta & metafor's forest function forest(fo1, prediction = TRUE) forest(fo2, cex = .8, col = \"lightblue\") }"},{"path":"/reference/metapsyInfluenceAnalysis.html","id":null,"dir":"Reference","previous_headings":"","what":"Influence Diagnostics — metapsyInfluenceAnalysis","title":"Influence Diagnostics — metapsyInfluenceAnalysis","text":"Conducts influence analysis meta-analysis generated meta functions, allows produce influence diagnostic plots.","code":""},{"path":"/reference/metapsyInfluenceAnalysis.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Influence Diagnostics — metapsyInfluenceAnalysis","text":"","code":"metapsyInfluenceAnalysis(x, random = FALSE, subplot.heights = c(30,18),     subplot.widths = c(30,30), forest.lims = 'default',     return.separate.plots = FALSE, text.scale = 1)"},{"path":"/reference/metapsyInfluenceAnalysis.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Influence Diagnostics — metapsyInfluenceAnalysis","text":"x object class meta, generated metabin, metagen, metacont, metacor, metainc, metarate metaprop function. random Logical. random-effects model used generate influence diagnostics? Uses method.tau specified meta object one \"DL\", \"\", \"SJ\", \"ML\", \"REML\", \"EB\", \"PM\", \"HS\" \"GENQ\" (ensure compatibility metafor package). Otherwise, DerSimonian-Laird (\"DL\"; DerSimonian & Laird, 1986) estimator used. FALSE default. subplot.heights Concatenated array two numerics. Specifies heights first (first number) second (second number) row overall plot generated plotting results. Default c(30,18). subplot.widths Concatenated array two numerics. Specifies widths first (first number) second (second number) column overall results plot generated plotting results. Default c(30,30). forest.lims Concatenated array two numerics. Specifies x-axis limits forest plots generated plotting results. Use \"default\" standard settings used (default). return.separate.plots Logical. plotted, influence plots shown separate plots lieu returning one overall plot? text.scale Positive numeric. Scaling factor text geoms used plotting results. Values <1 shrink text, values >1 increase text size. Default 1.","code":""},{"path":"/reference/metapsyInfluenceAnalysis.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Influence Diagnostics — metapsyInfluenceAnalysis","text":"list object class influence.analysis containing following objects returned (results saved variable): BaujatPlot: Baujat plot InfluenceCharacteristics: Viechtbauer-Cheung influence characteristics plot ForestEffectSize: forest plot sorted effect size ForestI2: forest plot sorted -study heterogeneity Data: data.frame containing data used plotting. Otherwise, function prints (1) results Leave-One-Analysis (sorted \\(^2\\)), (2) Viechtbauer-Cheung Influence Diagnostics  (3) Baujat Plot data (sorted heterogeneity contribution), order. Plots can produced manually plugging saved object class InfluenceAnalysis generated function plot function. also possible produce one specific plot specifying name plot character second argument plot call (see Examples).","code":""},{"path":"/reference/metapsyInfluenceAnalysis.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Influence Diagnostics — metapsyInfluenceAnalysis","text":"function conducts influence analysis using \"Leave-One-\" paradigm internally produces data four influence diagnostics. Diagnostic plots can produced saving output function object plugging plot function. diagnostics may used determine study effect size may excessive influence overall results meta-analysis /contribute substantially -study heterogeneity analysis. may used outlier detection test robustness overall results found analysis. Results four diagnostics calculated: Baujat Plot: Baujat et al. (2002) proposed plot evaluate heterogeneity patterns meta-analysis. x-axis Baujat plot shows overall heterogeneity contribution effect size y-axis shows influence effect size pooled result. baujat function called internally produce results. Effect sizes studies high values x y-axis may considered influential cases; effect sizes studies high heterogeneity contribution (x-axis) low influence overall results can outliers might deleted reduce amount -study heterogeneity. Influence Characteristics: Several influence analysis diagnostics proposed Viechtbauer & Cheung (2010). Results calculated internal call influence.rma.uni. console output, potentially influential studies marked asterisk (*). plotted, effect sizes/studies determined influential cases using \"rules thumb\" described Viechtbauer & Cheung (2010) shown red. details, see documentation influence.rma.uni function. Forest Plot Leave-One-Analysis, sorted Effect Size: displays effect size \\(^2\\)-heterogeneity omitting one \\(k\\) studies time. plot sorted effect size determine studies effect sizes particularly affect overall effect size. Results generated internal call metainf. Forest Plot Leave-One-Analysis, sorted \\(^2\\): see ; results sorted \\(^2\\) determine study exclusion results greatest reduction heterogeneity.","code":""},{"path":"/reference/metapsyInfluenceAnalysis.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Influence Diagnostics — metapsyInfluenceAnalysis","text":"Harrer, M., Cuijpers, P., Furukawa, T., & Ebert, D. D. (2019). Meta-Analysis R: Hands-Guide. DOI: 10.5281/zenodo.2551803. Chapter 6.3 DerSimonian R. & Laird N. (1986), Meta-analysis clinical trials. Controlled Clinical Trials, 7, 177–188. Viechtbauer, W., & Cheung, M. W.-L. (2010). Outlier influence diagnostics meta-analysis. Research Synthesis Methods, 1, 112–125.","code":""},{"path":[]},{"path":"/reference/metapsyInfluenceAnalysis.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Influence Diagnostics — metapsyInfluenceAnalysis","text":"Mathias Harrer & David Daniel Ebert","code":""},{"path":"/reference/metapsyInfluenceAnalysis.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Influence Diagnostics — metapsyInfluenceAnalysis","text":"","code":"if (FALSE) { # Load 'ThirdWave' data data(ThirdWave)  # Create 'meta' meta-analysis object suppressPackageStartupMessages(library(meta)) meta = metagen(TE, seTE, studlab = paste(ThirdWave$Author), data=ThirdWave)  # Run influence analysis; specify to return separate plots when plotted inf.an = InfluenceAnalysis(meta, return.separate.plots = TRUE)  # Show results in console inf.an  # Generate all plots plot(inf.an)  # For baujat plot plot(inf.an, \"baujat\")  # For influence diagnostics plot plot(inf.an, \"influence\")  # For forest plot sorted by effect size plot(inf.an, \"ES\")  # For forest plot sorted by I-squared plot(inf.an, \"I2\")}"},{"path":"/reference/metapsyNNT.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate NNTs — metapsyNNT","title":"Calculate NNTs — metapsyNNT","text":"Calculate NNTs (extracted dmetar)","code":""},{"path":"/reference/metapsyNNT.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate NNTs — metapsyNNT","text":"","code":"metapsyNNT(d, CER, event.e, n.e, event.c, n.c, names, method)"},{"path":"/reference/metapsyNNT.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate NNTs — metapsyNNT","text":"d single numeric concatenated vector numerics representing effect size expressed Cohen's \\(d\\) Hedges' \\(g\\). parameter specified function, method Kraemer Kupfer used automatically calculate \\(NNT\\)s. CER control group event ratio. Furukawa's method (Furukawa & Leucht, 2011) calculate NNTs d requires assumed response (\"event\") ratio control group (\\(\\frac{n_{responders}}{N_{total}}\\)) specified. CER can assume values 0 1. value specified CER, Furukawa's method used automatically. Argument method set \"KraemerKupfer\" override . event.e Single number numeric vector. number (favourable) events experimental group. n.e Single number numeric vector. number participants experimental group. event.c Single number numeric vector. number (favourable) events control group. n.c Single number numeric vector. number participants control group. names Optional. Character vector equal length vector supplied d event.e containing study/effect size labels. method method used calculate NNT d. Either \"KraemerKupfer\" method proposed Kraemer Kupfer (2006) \"Furukawa\" Furukawa method (Furukawa & Leucht, 2011). Please note Furukawa's method can used CER specified.","code":""},{"path":"/reference/metapsyTools.html","id":null,"dir":"Reference","previous_headings":"","what":"metapsyTools: Several Helper Functions for Metapsy Databases — metapsyTools","title":"metapsyTools: Several Helper Functions for Metapsy Databases — metapsyTools","text":"metapsyTools companion R package Metapsy database. aims facilitate calculation meta-analytic effect sizes included trials. purpose, data can checked converted required format calculate effect sizes R. possible run meta-analysis using output effect sizes.","code":""},{"path":[]},{"path":"/reference/metapsyTools.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"metapsyTools: Several Helper Functions for Metapsy Databases — metapsyTools","text":"Mathias Harrer mathias.h.harrer@gmail.com, Paula Kuper paula.r.kuper@gmail.com, Pim Cuijpers p.cuijpers@vu.nl","code":""},{"path":"/reference/multiarmExpander.html","id":null,"dir":"Reference","previous_headings":"","what":"Expander function for multiarm trials — multiarmExpander","title":"Expander function for multiarm trials — multiarmExpander","text":"Expands multiarm trial.","code":""},{"path":"/reference/multiarmExpander.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Expander function for multiarm trials — multiarmExpander","text":"","code":"multiarmExpander(study, condition.specification, group.indicator, group.names)"},{"path":"/reference/multiarmExpander.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Expander function for multiarm trials — multiarmExpander","text":"study data one study, one unique assessment point. condition.specification trial condition specification. group.indicator group indicator (IG CG). group.names group names (list).","code":""},{"path":"/reference/pipe.html","id":null,"dir":"Reference","previous_headings":"","what":"Pipe operator — %>%","title":"Pipe operator — %>%","text":"See magrittr::%>% details.","code":""},{"path":"/reference/pipe.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pipe operator — %>%","text":"","code":"lhs %>% rhs"},{"path":"/reference/pipe.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Pipe operator — %>%","text":"lhs value magrittr placeholder. rhs function call using magrittr semantics.","code":""},{"path":"/reference/pipe.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Pipe operator — %>%","text":"result calling rhs(lhs).","code":""},{"path":"/reference/plot.proportionMID.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot method for objects of class 'proportionMID' — plot.proportionMID","title":"Plot method for objects of class 'proportionMID' — plot.proportionMID","text":"Plot S3 method objects class proportionMID.","code":""},{"path":"/reference/plot.proportionMID.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot method for objects of class 'proportionMID' — plot.proportionMID","text":"","code":"# S3 method for proportionMID plot(x, ...)"},{"path":"/reference/plot.proportionMID.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot method for objects of class 'proportionMID' — plot.proportionMID","text":"x object class proportionMID. ... Additional arguments.","code":""},{"path":"/reference/plot.proportionMID.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Plot method for objects of class 'proportionMID' — plot.proportionMID","text":"Mathias Harrer mathias.h.harrer@gmail.com, Paula Kuper paula.r.kuper@gmail.com, Pim Cuijpers p.cuijpers@vu.nl","code":""},{"path":"/reference/plot.runMetaAnalysis.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot method for objects of class 'runMetaAnalysis' — plot.runMetaAnalysis","title":"Plot method for objects of class 'runMetaAnalysis' — plot.runMetaAnalysis","text":"Plot S3 method objects class runMetaAnalysis.","code":""},{"path":"/reference/plot.runMetaAnalysis.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot method for objects of class 'runMetaAnalysis' — plot.runMetaAnalysis","text":"","code":"# S3 method for runMetaAnalysis plot(x, which = NULL, eb = FALSE, eb.labels = FALSE, ...)"},{"path":"/reference/plot.runMetaAnalysis.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot method for objects of class 'runMetaAnalysis' — plot.runMetaAnalysis","text":"x object class runMetaAnalysis. Model plotted. Can one \"overall\", \"combined\", \"lowest.highest\", \"outliers\", \"influence\", \"threelevel\", \"threelevel.che\", \"baujat\", \"loo-es\", \"loo-i2\", \"trimfill\", \"limitmeta\" \"selection\". eb Prints forest plot empirical Bayes point estimates study-specific prediction intervals proposed van Aert (2021). Defaults FALSE. eb.labels eb TRUE, empirical Bayes estimates prediction intervals study printed right side forest plot? Defaults FALSE. ... Additional arguments.","code":""},{"path":"/reference/plot.runMetaAnalysis.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Plot method for objects of class 'runMetaAnalysis' — plot.runMetaAnalysis","text":"van Aert, R. C., Schmid, C. H., Svensson, D., & Jackson, D. (2021). Study specific prediction intervals random-effects meta-analysis: tutorial. Research Synthesis Methods, 12(4), 429-447.","code":""},{"path":"/reference/plot.runMetaAnalysis.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Plot method for objects of class 'runMetaAnalysis' — plot.runMetaAnalysis","text":"Mathias Harrer mathias.h.harrer@gmail.com, Paula Kuper paula.r.kuper@gmail.com, Pim Cuijpers p.cuijpers@vu.nl","code":""},{"path":"/reference/plot.subgroupAnalysis.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot method for objects of class 'runMetaAnalysis' — plot.subgroupAnalysis","title":"Plot method for objects of class 'runMetaAnalysis' — plot.subgroupAnalysis","text":"Plot S3 method objects class runMetaAnalysis.","code":""},{"path":"/reference/plot.subgroupAnalysis.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot method for objects of class 'runMetaAnalysis' — plot.subgroupAnalysis","text":"","code":"# S3 method for subgroupAnalysis plot(x, which = NULL, ...)"},{"path":"/reference/plot.subgroupAnalysis.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot method for objects of class 'runMetaAnalysis' — plot.subgroupAnalysis","text":"x object class runMetaAnalysis. character. Subgroup analysis plotted (variable name). ... Additional arguments.","code":""},{"path":"/reference/plot.subgroupAnalysis.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Plot method for objects of class 'runMetaAnalysis' — plot.subgroupAnalysis","text":"Mathias Harrer mathias.h.harrer@gmail.com, Paula Kuper paula.r.kuper@gmail.com, Pim Cuijpers p.cuijpers@vu.nl","code":""},{"path":"/reference/print.checkConflicts.html","id":null,"dir":"Reference","previous_headings":"","what":"Print method for the 'checkConflicts' function — print.checkConflicts","title":"Print method for the 'checkConflicts' function — print.checkConflicts","text":"S3 method prints studies potential formatting conflicts.","code":""},{"path":"/reference/print.checkConflicts.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print method for the 'checkConflicts' function — print.checkConflicts","text":"","code":"# S3 method for checkConflicts print(x, ...)"},{"path":"/reference/print.checkConflicts.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print method for the 'checkConflicts' function — print.checkConflicts","text":"x list object class checkConflicts. ... Additional arguments (used).","code":""},{"path":[]},{"path":"/reference/print.checkConflicts.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Print method for the 'checkConflicts' function — print.checkConflicts","text":"Mathias Harrer & David Daniel Ebert","code":""},{"path":"/reference/print.exploreStudies.html","id":null,"dir":"Reference","previous_headings":"","what":"Print method for objects of class 'exploreStudies' — print.exploreStudies","title":"Print method for objects of class 'exploreStudies' — print.exploreStudies","text":"Print S3 method objects class exploreStudies.","code":""},{"path":"/reference/print.exploreStudies.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print method for objects of class 'exploreStudies' — print.exploreStudies","text":"","code":"# S3 method for exploreStudies print(x, ...)"},{"path":"/reference/print.exploreStudies.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print method for objects of class 'exploreStudies' — print.exploreStudies","text":"x object class exploreStudies. ... Additional arguments.","code":""},{"path":"/reference/print.exploreStudies.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Print method for objects of class 'exploreStudies' — print.exploreStudies","text":"Mathias Harrer mathias.h.harrer@gmail.com, Paula Kuper paula.r.kuper@gmail.com, Pim Cuijpers p.cuijpers@vu.nl","code":""},{"path":"/reference/print.proportionMID.html","id":null,"dir":"Reference","previous_headings":"","what":"Print method for objects of class 'proportionMID' — print.proportionMID","title":"Print method for objects of class 'proportionMID' — print.proportionMID","text":"Print S3 method objects class proportionMID.","code":""},{"path":"/reference/print.proportionMID.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print method for objects of class 'proportionMID' — print.proportionMID","text":"","code":"# S3 method for proportionMID print(x, ...)"},{"path":"/reference/print.proportionMID.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print method for objects of class 'proportionMID' — print.proportionMID","text":"x object class proportionMID. ... Additional arguments.","code":""},{"path":"/reference/print.proportionMID.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Print method for objects of class 'proportionMID' — print.proportionMID","text":"Mathias Harrer mathias.h.harrer@gmail.com, Paula Kuper paula.r.kuper@gmail.com, Pim Cuijpers p.cuijpers@vu.nl","code":""},{"path":"/reference/print.runMetaAnalysis.html","id":null,"dir":"Reference","previous_headings":"","what":"Print method for objects of class 'runMetaAnalysis' — print.runMetaAnalysis","title":"Print method for objects of class 'runMetaAnalysis' — print.runMetaAnalysis","text":"Print S3 method objects class runMetaAnalysis. Print S3 method objects class runMetaAnalysis.","code":""},{"path":"/reference/print.runMetaAnalysis.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print method for objects of class 'runMetaAnalysis' — print.runMetaAnalysis","text":"","code":"# S3 method for runMetaAnalysis print(x, ...)  # S3 method for runMetaAnalysis print(x, ...)"},{"path":"/reference/print.runMetaAnalysis.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print method for objects of class 'runMetaAnalysis' — print.runMetaAnalysis","text":"x object class runMetaAnalysis. ... Additional arguments.","code":""},{"path":"/reference/print.runMetaAnalysis.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Print method for objects of class 'runMetaAnalysis' — print.runMetaAnalysis","text":"Mathias Harrer mathias.h.harrer@gmail.com, Paula Kuper paula.r.kuper@gmail.com, Pim Cuijpers p.cuijpers@vu.nl","code":""},{"path":"/reference/print.subgroupAnalysis.html","id":null,"dir":"Reference","previous_headings":"","what":"Print method for objects of class 'subgroupAnalysis' — print.subgroupAnalysis","title":"Print method for objects of class 'subgroupAnalysis' — print.subgroupAnalysis","text":"Print S3 method objects class subgroupAnalysis.","code":""},{"path":"/reference/print.subgroupAnalysis.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print method for objects of class 'subgroupAnalysis' — print.subgroupAnalysis","text":"","code":"# S3 method for subgroupAnalysis print(x, ...)"},{"path":"/reference/print.subgroupAnalysis.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print method for objects of class 'subgroupAnalysis' — print.subgroupAnalysis","text":"x object class subgroupAnalysis. ... Additional arguments.","code":""},{"path":"/reference/print.subgroupAnalysis.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Print method for objects of class 'subgroupAnalysis' — print.subgroupAnalysis","text":"Mathias Harrer mathias.h.harrer@gmail.com, Paula Kuper paula.r.kuper@gmail.com, Pim Cuijpers p.cuijpers@vu.nl","code":""},{"path":"/reference/profile.runMetaAnalysis.html","id":null,"dir":"Reference","previous_headings":"","what":"Profile Likelihood Plots for 'runMetaAnalysis' models. — profile.runMetaAnalysis","title":"Profile Likelihood Plots for 'runMetaAnalysis' models. — profile.runMetaAnalysis","text":"Profiles restricted log-likelihood threelevel threelevel.che models, using metafor::profile.rma() function. functionality can used check two heterogeneity variances (\\(\\tau^2\\) within studies) identifiable correctly estimated.","code":""},{"path":"/reference/profile.runMetaAnalysis.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Profile Likelihood Plots for 'runMetaAnalysis' models. — profile.runMetaAnalysis","text":"","code":"# S3 method for runMetaAnalysis profile(fitted, which = NULL, ...)"},{"path":"/reference/profile.runMetaAnalysis.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Profile Likelihood Plots for 'runMetaAnalysis' models. — profile.runMetaAnalysis","text":"fitted object class runMetaAnalysis. Model estimates printed. Can one \"threelevel\" \"threelevel.che\". ... Additional arguments.","code":""},{"path":"/reference/proportionMID.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate the proportion of true effect sizes above a meaningful threshold — proportionMID","title":"Calculate the proportion of true effect sizes above a meaningful threshold — proportionMID","text":"Based results runMetaAnalysis(), function allows estimate proportion true effect sizes exceed user-defined meaningful (e.g. clinically relevant) threshold.","code":""},{"path":"/reference/proportionMID.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate the proportion of true effect sizes above a meaningful threshold — proportionMID","text":"","code":"proportionMID(model,                mid = NULL,                which = \"all\",                test = \"smaller\",                plot = FALSE)"},{"path":"/reference/proportionMID.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate the proportion of true effect sizes above a meaningful threshold — proportionMID","text":"model class runMetaAnalysis object, created runMetaAnalysis() function. mid numeric value, indicating clinically relevant effect threshold (e.g. minimally important difference; \\(MID\\); Cuijpers et al., 2014) used estimate proportion true effect sizes exceed cut-. outcome measure used model Hedges' \\(g\\), provided value also standardized mean difference. outcome measure model risk ratio, treshold also provided (untransformed) risk ratio. model model used estimate proportions. Defaults \"\", means proportions calculated models. Alternatively, possible values \"overall\", \"combined\", \"lowest\", \"highest\", \"outliers\", \"influence\" \"rob\", models available model object. correctPublicationBias() run, \"trimfill\", limitmeta selection also possible options. also possible concatenate model names, meaning proportions calculated supplied models. test default, function estimates proportion true effects provided threshold mid (test=\"smaller\"). Alternatively, one can specify test=\"bigger\". calculate proportion true effects treshold. plot density plot illustrating proportions returned? Defaults FALSE. Please note S3 plot method available outputs function even plot=FALSE (see \"Details\").","code":""},{"path":"/reference/proportionMID.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate the proportion of true effect sizes above a meaningful threshold — proportionMID","text":"Returns object class \"proportionMID\". S3 plot method defined object class, allows create density plot illustrating estimated proportions, using model-based estimate pooled effect size -study heterogeneity \\(\\tau^2\\).","code":""},{"path":"/reference/proportionMID.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Calculate the proportion of true effect sizes above a meaningful threshold — proportionMID","text":"proportionMID function implements approach estimate proportion true effect sizes exceeding (scientifically clinically) relevant threshold, proposed Mathur & VanderWeele (2019). estimated proportions suggested useful metric determine impact -study heterogeneity meta-analysis \"real-life\" interpretation results. , example, pooled effect significant, high -study heterogeneity can still mean substantial proportion true effects studies population practicially irrelevant, even negative. Conversely overall non-significant effects, face large heterogeneity, can still mean substantial proportion studies non-negligible true effects. recommended Mathur & VanderWeele (2019), proportionMID function also automatically calculates proportion true effects exceeding \"inverse\" user-defined effect (e.g., mid=-0.24, default, function also estimates proportion true effects larger \\(g\\)=0.24; note changed sign). can used check e.g. clinically relevant negative effects. plot method used, plot set TRUE function, plot showing assumed distribution true effects based estimated meta-analytic model created. Notably, assumed random-effects distribution true effect sizes approximately normal. simplifying assumption required (many meta-analytic methods; Jackson & White, 2018) hold. Confidence intervals provided functions calculated using asymptotic closed-form solution derived using Delta method Mathur & VanderWeele (2019). Following recommendations, warning printed \\(p\\)<0.15 \\(p\\)>0.85, since case asymptotic CIs interpreted cautiously; CIs based boostrapping preferable scenario can calculated using MetaUtility::prop_stronger() function.","code":""},{"path":"/reference/proportionMID.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Calculate the proportion of true effect sizes above a meaningful threshold — proportionMID","text":"Cuijpers, P., Turner, E. H., Koole, S. L., Van Dijke, ., & Smit, F. (2014). threshold clinically relevant effect? case major depressive disorders. Depression Anxiety, 31(5), 374-378. Jackson, D., & White, . R. (2018). meta-analysis avoid making hidden normality assumptions?. Biometrical Journal, 60(6), 1040-1058. Mathur, M. B., & VanderWeele, T. J. (2019). New metrics meta-analyses heterogeneous effects. Statistics Medicine, 38(8), 1336-1342.","code":""},{"path":[]},{"path":"/reference/proportionMID.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Calculate the proportion of true effect sizes above a meaningful threshold — proportionMID","text":"Mathias Harrer mathias.h.harrer@gmail.com, Paula Kuper paula.r.kuper@gmail.com, Pim Cuijpers p.cuijpers@vu.nl","code":""},{"path":"/reference/proportionMID.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate the proportion of true effect sizes above a meaningful threshold — proportionMID","text":"","code":"if (FALSE) { # Run meta-analysis; then estimate the proportion depressionPsyCtr %>%    filterPoolingData(condition_arm1 == \"cbt\") %>%    runMetaAnalysis()  -> x  proportionMID(x, mid = -0.24) proportionMID(x, mid = -0.24, \"outliers\") %>% plot()   # If bootstrap CIs are requested in runMetaAnalysis, # calculation of CIs around p is possible for all available # models. depressionPsyCtr %>%    filterPoolingData(condition_arm1 == \"cbt\") %>%    runMetaAnalysis(i2.ci.boot = TRUE, nsim.boot = 1000) %>%    correctPublicationBias() -> x  proportionMID(x, mid = -0.33)  # Run meta-analysis based on RRs; then estimate proportion # of true effects bigger than the defined threshold depressionPsyCtr %>%    filterPoolingData(     condition_arm1 %in% c(\"cbt\", \"pst\",                            \"dyn\", \"3rd wave\")) %>%    runMetaAnalysis(es.measure = \"RR\") %>%    proportionMID(mid = 1.13, test = \"bigger\") }"},{"path":"/reference/psyCtrSubset.html","id":null,"dir":"Reference","previous_headings":"","what":"The 'psyCtrSubset' dataset — psyCtrSubset","title":"The 'psyCtrSubset' dataset — psyCtrSubset","text":"example dataset containing subset 2021 depression trials database. format equals format data \"metapsy\" database, similar long format R. dataset also contains columns study characteristics important effect size calculation .","code":""},{"path":"/reference/psyCtrSubset.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"The 'psyCtrSubset' dataset — psyCtrSubset","text":"","code":"data(\"psyCtrSubset\")"},{"path":"/reference/psyCtrSubset.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"The 'psyCtrSubset' dataset — psyCtrSubset","text":"data.frame 503 rows 60 variables.","code":""},{"path":"/reference/psyCtrSubset.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"The 'psyCtrSubset' dataset — psyCtrSubset","text":"dataset included showcase correct formatting necessary use metapsyTools.","code":""},{"path":"/reference/psyCtrSubset.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"The 'psyCtrSubset' dataset — psyCtrSubset","text":"Mathias Harrer, Paula Kuper, Pim Cuijpers","code":""},{"path":"/reference/psyCtrSubsetWide.html","id":null,"dir":"Reference","previous_headings":"","what":"The 'psyCtrSubset' dataset (wide format) — psyCtrSubsetWide","title":"The 'psyCtrSubset' dataset (wide format) — psyCtrSubsetWide","text":"example dataset containing subset 2021 depression trials database. constrast , e.g., psyCtrSubset dataset, psyCtrSubsetWide structured \"wide(r)\" format. dataset also contains columns study characteristics important effect size calculation .","code":""},{"path":"/reference/psyCtrSubsetWide.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"The 'psyCtrSubset' dataset (wide format) — psyCtrSubsetWide","text":"","code":"data(\"psyCtrSubsetWide\")"},{"path":"/reference/psyCtrSubsetWide.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"The 'psyCtrSubset' dataset (wide format) — psyCtrSubsetWide","text":"data.frame 175 rows 64 variables.","code":""},{"path":"/reference/psyCtrSubsetWide.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"The 'psyCtrSubset' dataset (wide format) — psyCtrSubsetWide","text":"dataset included showcase correct formatting necessary use metapsyTools.","code":""},{"path":"/reference/psyCtrSubsetWide.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"The 'psyCtrSubset' dataset (wide format) — psyCtrSubsetWide","text":"Mathias Harrer, Paula Kuper, Clara Miguel, Pim Cuijpers","code":""},{"path":"/reference/robSummary.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a RevMan-style risk of bias summary chart — robSummary","title":"Create a RevMan-style risk of bias summary chart — robSummary","text":"function generates summary plots study quality assessments using Cochrance Risk Bias Tool. Summary plots follow style RevMan Risk Bias (RoB) summary charts.","code":""},{"path":"/reference/robSummary.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a RevMan-style risk of bias summary chart — robSummary","text":"","code":"robSummary(data, name.high=\"High\", name.unclear=\"Unclear\",     name.low=\"Low\", studies, name.missing, table = FALSE)"},{"path":"/reference/robSummary.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a RevMan-style risk of bias summary chart — robSummary","text":"data data.frame containing column risk bias criterion, rows represent individual studies. risk bias assessment criterion study must coded character string. four codes can used, referring low risk bias, unclear risk bias, high risk bias, missing information. string used specify categories must specified name.high, name.unclear, name.low /name.missing, unless defaults parameters used. name.high Character specifying \"high risk bias\" category coded data (e.g., name.high = \"high\"). Default \"High\". name.unclear Character specifying \"unclear risk bias\" category coded data (e.g., name.unclear = \"unclear\"). Default \"Unclear\". name.low Character specifying \"low risk bias\" category coded data (e.g., name.low = \"low\"). Default \"Low\". studies vector length number rows data specifying study labels risk bias ratings. specified table = TRUE. name.missing Character specifying missing information coded data (e.g., name.missing = \"missing\"). Default \"Missing\". ratings, including missing information, must coded strings, using NA data signify missing information valid. table additional RevMan style risk bias table produced? set TRUE, studies must specified. FALSE default.","code":""},{"path":"/reference/robSummary.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create a RevMan-style risk of bias summary chart — robSummary","text":"function automatically removes separators like \"-\" \".\" column names/risk bias criteria. produce \"clean\" plot, may therefore separate words column names data data frame using symbols (e.g. \"Allocation_Concealment\" return \"Allocation Concealment\").","code":""},{"path":"/reference/robSummary.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Create a RevMan-style risk of bias summary chart — robSummary","text":"Harrer, M., Cuijpers, P., Furukawa, T., & Ebert, D. D. (2019). Meta-Analysis R: Hands-Guide. DOI: 10.5281/zenodo.2551803. Chapter 10","code":""},{"path":"/reference/robSummary.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Create a RevMan-style risk of bias summary chart — robSummary","text":"Mathias Harrer & David Daniel Ebert","code":""},{"path":"/reference/rr.binary.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate the log-risk ratio using binary outcome data — rr.binary","title":"Calculate the log-risk ratio using binary outcome data — rr.binary","text":"Calculate log risk ratio using binary outcome data. meant used part calculateEffectSizes.","code":""},{"path":"/reference/rr.binary.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate the log-risk ratio using binary outcome data — rr.binary","text":"","code":"rr.binary(x, cc = 0.5, ...)"},{"path":"/reference/rr.binary.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate the log-risk ratio using binary outcome data — rr.binary","text":"x data cc continuity correction zero cells applied? Either FALSE increment added. Default 0.5. ... Binary effect size data. Data frame must include columns event_arm1, event_arm2, totaln_arm1, totaln_arm2. See Metapsy data standard.","code":""},{"path":"/reference/rr.precalc.html","id":null,"dir":"Reference","previous_headings":"","what":"Forward pre-calculated log-risk ratios — rr.precalc","title":"Forward pre-calculated log-risk ratios — rr.precalc","text":"Forwards pre-calculated log-risk ratios. meant used part calculateEffectSizes.","code":""},{"path":"/reference/rr.precalc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Forward pre-calculated log-risk ratios — rr.precalc","text":"","code":"rr.precalc(x, ...)"},{"path":"/reference/rr.precalc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Forward pre-calculated log-risk ratios — rr.precalc","text":"x data ... Pre-calculated effect size data. Data frame must include columns precalc_log_rr precalc_log_rr_se. See Metapsy data standard.","code":""},{"path":"/reference/runMetaAnalysis.html","id":null,"dir":"Reference","previous_headings":"","what":"Run different types of meta-analyses — runMetaAnalysis","title":"Run different types of meta-analyses — runMetaAnalysis","text":"wrapper function allows simultaneously pool effect sizes using different meta-analytic approaches.","code":""},{"path":"/reference/runMetaAnalysis.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Run different types of meta-analyses — runMetaAnalysis","text":"","code":"runMetaAnalysis(data,                  # Models to run                 which.run = c(\"overall\", \"combined\",                               \"lowest.highest\", \"outliers\",                               \"influence\", \"rob\", \"threelevel\",                               \"threelevel.che\"),                                                # Effect size measure                 es.measure = c(\"g\", \"RR\"),                 es.type = c(\"precalculated\", \"raw\"),                 es.var = ifelse(identical(es.measure[1], \"g\"),                                  \".g\", \".log_rr\"),                 se.var = ifelse(identical(es.measure[1], \"g\"),                                  \".g_se\", \".log_rr_se\"),                 es.binary.raw.vars =                    c(\".event_arm1\", \".event_arm2\",                     \".totaln_arm1\", \".totaln_arm2\"),                                      # Estimator of the heterogeneity variance                 method.tau = \"REML\",                 method.tau.ci = \"Q-Profile\",                 i2.ci.boot = FALSE,                 nsim.boot = 5e3,                 hakn = TRUE,                                  # Data specifications                 study.var = \"study\",                 arm.var.1 = \"condition_arm1\",                 arm.var.2 = \"condition_arm2\",                 measure.var = \"instrument\",                 low.rob.filter = \"rob > 2\",                 round.digits = 2,                 rob.data = NULL,                                  # Model specifications                 which.combine = c(\"arms\", \"studies\"),                 which.combine.var = \"multi_arm1\",                 which.outliers = c(\"overall\", \"combined\"),                 which.influence = c(\"overall\", \"combined\"),                 which.rob = c(\"overall\", \"combined\"),                 nnt.cer = 0.2,                 rho.within.study = 0.6,                 phi.within.study = 0.9,                 w1.var = ifelse(identical(es.measure[1], \"g\"),                                  \"n_arm1\", \"totaln_arm1\"),                 w2.var = ifelse(identical(es.measure[1], \"g\"),                                  \"n_arm2\", \"totaln_arm2\"),                 time.var = \"time_weeks\",                 vcov = c(\"simple\", \"complex\"),                 near.pd = FALSE,                 use.rve = TRUE,                                  # Output                 html = TRUE,                                  # Additional arguments                 ...)"},{"path":"/reference/runMetaAnalysis.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Run different types of meta-analyses — runMetaAnalysis","text":"data data.frame. Effect size data wide format, created calculateEffectSizes. .run character. Selection models calculated. See 'Details'. es.measure character. meta-analyses calculated using bias-corrected standardized mean difference (\"g\"; default), using risk ratios (\"RR\")? Meta-analyses conducted using comparisons contain non NA values es.var se.var columns. es.type character. pre-calculated raw event data (.e. Mantel-Haenszel method) used meta-analyses risk ratios? Can set \"precalculated\" (default) \"raw\". es.var character. Specifies name variable containing (pre- calculated) effect size data data. es.measure = \"g\", set .g default; \".log_rr\" used es.measure = \"RR\". default settings correspond standard output calculateEffectSizes(). se.var character. Specifies name variable containing (pre-calculated) standard errors (square root variance) effect size metric defined es.var. es.measure = \"g\", automatically set .g_se; es.measure = \"RR\", \".log_rr_se\" used. default settings correspond standard output calculateEffectSizes(). es.binary.raw.vars character vector, defining column names (1) raw event counts experimental group, (2) raw event counts control/reference group, (3) sample size experimental group, (4) sample size control/reference group stored. Defaults correspond standard output calculateEffectSizes(). method.tau character. character string indicating method used estimate -study variance (tau-squared) square root (tau). Either \"REML\" (default), \"DL\", \"PM\", \"ML\", \"HS\", \"SJ\", \"\", \"EB\", can abbreviated (see metagen). Use \"FE\" use fixed-effect/\"common effect\" model. method.tau.ci character. character string indicating method used estimate confidence interval -study heterogeneity variance \\(\\tau^2\\). Either \"Q-Profile\" (default recommended; Viechtbauer, 2017), \"BJ\", \"J\", \"PL\" can abbreviated. See metagen rma.uni details. i2.ci.boot logical. Confidence intervals \\(\\tau^2\\) calculated Q-Profile method directly applicable three-level models, two heterogeneity variance components estimated. default, argument therefore set FALSE, confidence intervals around \\(\\tau^2\\) \\(^2\\) provided \"threelevel\" \"threelevel.che\" model. argument set TRUE, parametric bootstrapping used calculate confidence intervals around - within-study heterogeneity estimates (\\(\\tau\\) \\(^2\\)). Please note can take several minutes, depending number effect sizes. correctPublicationBias() used i2.ci.boot TRUE, bootstrapping also used calculate confidence intervals around \\(G^2\\) statistic (Rücker et al., 2011) used limit meta-analysis (note \\(G^2\\) printed \\(^2\\) package). nsim.boot numeric Number bootstrap samples drawn i2.ci.boot TRUE. Defaults 5000. hakn logical. Knapp-Hartung adjustment effect size significance tests used? Default TRUE. study.var character. name variable data study IDs stored. arm.var.1 character. name variable data condition (e.g. \"guided iCBT\") first arm within comparison stored. arm.var.2 character. name variable data condition (e.g. \"wlc\") second arm within comparison stored. measure.var character. name variable data instrument used comparison stored. low.rob.filter character. filtering statement include studies \"low RoB \" analysis. Please note name variable must included column data. round.digits numeric. Number digits round (presented) results . Default 2. rob.data list. Optional list detailing risk bias data appended model (see Details). .combine character. multiple effect sizes within one study pooled \"arms\" (default) \"studies\" level? study multi-arm trial, setting .combine = \"arms\" aggregate effect sizes trial arm individually pooling; .combine.var argument can used control effects within study aggregated. .combine = \"studies\", one overall aggregated effect created study. setting preferable statistical perspective, since ensures pooled effects can assumed independent. .combine.var character. Additional grouping variable within studies used \"combined\" analysis .combine = \"arms\". specified variable differs within one study (defined study.var), effects aggregated separately unique value .combine.var. Defaults \"multi_arm1\", variable encodes multi-arm intervention conditions Metapsy data standard. .outliers character. model used conduct outlier analyses? Must \"overall\" \"combined\", \"overall\" default. .influence character. model used conduct influence analyses? Must \"overall\" \"combined\", \"overall\" default. .rob character. model used conduct \"low risk bias \" analyses? Must \"overall\" \"combined\", \"overall\" default. nnt.cer numeric. Value 0 1, indicating assumed control group event rate used calculating NNTs via Furukawa-Leucht method. rho.within.study numeric. Value 0 1, indicating assumed correlation effect sizes within studies. relevant combine effect sizes \"combined\" analysis type, used estimate variance-covariance matrices needed conditional hierarchical effects three-level model. Default 0.6. phi.within.study numeric. Value 0 1, indicating assumed one-week autocorrelation effect sizes. used vcov=\"complex\" approximate variance-covariance matrices needed \"combined\" \"threelevel.che\" model. Default 0.9. See \"Details\". w1.var character. Name variable data sample sizes first arm stored. See \"Details\". w2.var character. Name variable data sample sizes second arm stored. See \"Details\". time.var character. Name variable data assessment time point stored. expressed weeks since randomization; units (e.g. days, months) also possible phi.within.study specified accordingly. See \"Details\". vcov character. \"combined\" \"threelevel.che\" model, variance-covariance matrices (representing dependency structure data) approximated using heterogeneous compound symmetry (\"simple\"; default) unstructured matrix structure (\"complex\")? See \"Details\". near.pd logical. least one study variance-covariance matrices constructed vcov=\"complex\" positive definite/invertible, nearPD function used compute nearest positive definite matrix? Default FALSE. use.rve logical. robust variance estimation used calculate confidence intervals tests three-level models? TRUE default. html logical. HTML table created results? Default TRUE. ... Additional arguments.","code":""},{"path":"/reference/runMetaAnalysis.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Run different types of meta-analyses — runMetaAnalysis","text":"Returns object class \"runMetaAnalysis\". object includes, among things, data.frame name summary, results summarized - including studies removed analysis steps. objects \"raw\" model objects returned selected analysis types. allows conduct operations models specifically (e.g. run meta-regression plugging one model objects meta:::update.meta.","code":""},{"path":"/reference/runMetaAnalysis.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Run different types of meta-analyses — runMetaAnalysis","text":"runMetaAnalysis function wrapper several types meta-analytic models typically used. allows run models one step order generate results somewhat closer \"publication-ready\". default, following models calculated: \"overall\". Runs generic inverse-variance (random-effects) model. included effect sizes treated independent. es.measure = \"RR\" es.type = \"raw\", Mantel-Haenszel method used pooling instead. \"combined\". Pools effect sizes within one study (defined study.var) pooling. ensures effect sizes independent (.e., unit--analysis error & double-counting avoided). combine effects, one assume correlation effect sizes within studies, empirical estimates typically available. \"lowest.highest\". Runs meta-analysis, () lowest (ii) highest effect size within study included. \"outlier\". Runs meta-analysis without statistical outliers (.e. effect sizes confidence interval overlap confidence intervall overall effect). \"influence\". Runs meta-analysis without influential cases (see influence.rma.uni details). \"rob\". Runs meta-analysis low-RoB studies included. \"threelevel\". Runs multilevel (three-level) meta-analysis model, effect sizes nested studies. \"threelevel.che\". Runs multilevel (three-level) meta-analysis model, effect sizes nested studies. Variance-covariance matrices study two effect sizes estimated using rho.within.study assumed overall within-study correlation. imputation allows run \"correlated hierarchical effects\" (CHE) model, typically good approximation data sets unknown /complex dependence structures. Internally, overall, combined, lowest.highest, outlier, influence rob models fitted calling meta::metagen() meta::metabin() function, respectively, {meta} (Balduzzi, Rücker & Schwarzer, 2019). threelevel threelevel.che models implemented using metafor::rma.mv() {metafor} (Viechtbauer, 2005). Outlier selection implemented using dmetar::find.outliers() function, influence analyses using dmetar::InfluenceAnalysis() function. latter function wrapper metafor::influence.rma.uni(). \\(~\\)","code":""},{"path":"/reference/runMetaAnalysis.html","id":"simple-or-complex-variance-covariance-approximation","dir":"Reference","previous_headings":"","what":"Simple or complex variance-covariance approximation","title":"Run different types of meta-analyses — runMetaAnalysis","text":"vcov argument controls effect size dependencies within data approximated using \"simple\" (default) \"complex\" (potentially accurate) method. argument relevant \"combined\" \"threelevel.che\" models. default \"simple\" method constructs variance-covariance matrices \\(\\Sigma_k\\) study using constant sampling correlation \\(\\rho\\) (defined rho.within.study), identical across studies, outcomes, time points. simplifying assumption part formulation CHE model originally provided Pustejovsky Tipton (2022). Naturally, employing common value \\(\\rho\\) across studies may reasonable analyses, information may available better approximate effect size dependencies collected data. Setting vcov \"complex\" allows assume correlations effect sizes may differ conditional type dependency. means variance-covariance matrix \\(\\Sigma_k\\) study \\(k\\) approximated unstructured matrix varying \\(\\rho_{ij}\\) (instead heterogeneous compound symmetry matrix fixed \\(\\rho\\), used vcov=\"simple\"). \\[\\begin{array}{ccc}\\texttt{vcov=\"simple\"} & \\texttt{vcov=\"complex\"} & \\\\ \\Sigma_k = \\begin{bmatrix} \\sigma^2_1 \\\\ \\rho \\sigma_2 \\sigma_1 & \\sigma^2_2 & & \\\\ \\rho \\sigma_3 \\sigma_1 & \\rho \\sigma_3 \\sigma_2 & \\sigma^2_3 & \\\\ \\rho \\sigma_4 \\sigma_1 & \\rho \\sigma_4 \\sigma_2 & \\rho \\sigma_4 \\sigma_3 & \\sigma^2_4 \\end{bmatrix} & \\Sigma_k = \\begin{bmatrix} \\sigma^2_1 & & & \\\\ \\rho_{21} \\sigma_2 \\sigma_1 & \\sigma^2_2 & & \\\\ \\rho_{31} \\sigma_3 \\sigma_1 & \\rho_{32} \\sigma_3 \\sigma_2 & \\sigma^2_3 & \\\\ \\rho_{41} \\sigma_4 \\sigma_1 & \\rho_{42} \\sigma_4 \\sigma_2 & \\rho_{43} \\sigma_4 \\sigma_3 & \\sigma^2_4 \\end{bmatrix} &  \\end{array}\\] example, setting vcov = \"complex\" allows additionally incorporate assumed correlations specific multiple testing time (e.g. correlations effects post-test long-term follow-). value provided phi.within.study represents (auto-)correlation coefficient \\(\\phi\\), serves rough estimate re-test correlation 1 week. vector follow-lengths provided time.var, allows model gradual decrease correlation measurements time. Furthermore, possible calculate correlation coefficient \\(\\rho_w\\) multi-arm trials, directly proportional size individual trial arm. trial arms size, meaning arm's weight \\(w\\) identical, \\(\\rho_w\\) known 0.5. Multiarm weights \\(w\\) (thus \\(\\rho_w\\)) can derived w1.var w2.var variables, containing sample size study arm, provided. Using complex approximation method increases risk least one studies' \\(\\Sigma_k\\) matrix positive definite. case, function automatically switches back constant sampling correlation approximation. \\(~\\)","code":""},{"path":"/reference/runMetaAnalysis.html","id":"replacement-functions","dir":"Reference","previous_headings":"","what":"Replacement functions","title":"Run different types of meta-analyses — runMetaAnalysis","text":"model fitted using runMetaAnalysis, replacement functions defined function argument. allows quickly tweak one analysis settings, implemented rerun function called. Say saved results runMetaAnalysis object m. , example, want check results using different estimator \\(\\tau^2\\), leaving settings , run e.g. method.tau(m) <- \"PM\", followed rerun(m). provide results using Paule-Mandel estimator. list available setting replacement functions provided . \\(~\\)","code":""},{"path":"/reference/runMetaAnalysis.html","id":"risk-of-bias-data","dir":"Reference","previous_headings":"","what":"Risk of Bias data","title":"Run different types of meta-analyses — runMetaAnalysis","text":"Using rob.data argument, possible specify variables data set provided data contain Risk Bias (ROB) assessment information. specified, allows generate forest plots added ROB information using plot.runMetaAnalysis(). ROB information added way can also used create ROB summary plots using createRobSummary(). object provided rob.data must list element elements: domains: vector characters, specifying variables contain ratings different ROB domains (e.g. allocation concealment, missing data handling, ...). domain.names (Optional): vector characters length domains, provides long-format labels included domain. overall.rob (Optional): single character specifying variable data contains overall ROB rating. categories: vector characters, specifying ROB ratings coded selected variables (e.g., \"low, \"high\", \"unclear\"). symbols (Optional): vector single-letter characters (symbols) used plotting ROB rating forest plot. colors (Optional): vector characters length categories, specifying colors rating code. concrete usage examples functionality, see \"Examples\". details see Get Started vignette.","code":""},{"path":[]},{"path":"/reference/runMetaAnalysis.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Run different types of meta-analyses — runMetaAnalysis","text":"Mathias Harrer mathias.h.harrer@gmail.com, Paula Kuper paula.r.kuper@gmail.com, Pim Cuijpers p.cuijpers@vu.nl","code":""},{"path":"/reference/runMetaAnalysis.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Run different types of meta-analyses — runMetaAnalysis","text":"","code":"if (FALSE) { data(\"depressionPsyCtr\") library(meta)  depressionPsyCtr %>%   checkDataFormat() %>%   checkConflicts() %>%   calculateEffectSizes() %>%    filterPoolingData(condition_arm2 %in%                        c(\"wl\", \"other ctr\")) -> data  # Run the meta-analyses runMetaAnalysis(data) -> res  # Use replacement function to show results for # differing settings method.tau(res) <- \"PM\" hakn(res) <- FALSE rerun(res)  # Show summary res  # Show forest plot (by default, \"overall\" is used) plot(res)  # Show forest plot of specific analysis plot(res, \"outliers\") plot(res, \"threelevel\") plot(res, \"baujat\") plot(res, \"influence\") plot(res, \"lowest.highest\")  # Extract specific model and do further calculations # (e.g. meta-regression on 'year') metaRegression(res$model.overall, ~ scale(year))  # Conduct a subgroup analysis subgroupAnalysis(res, country)  # Correct for publication bias/small-study effects correctPublicationBias(res)  # For the combined analysis, set which.combine to # \"studies\" here, so that all effects in a study are aggregated # first before pooling data %>%    runMetaAnalysis(which.combine = \"studies\") %>%    plot(\"combined\")    # Define ROB data to be added to the models robData = list(   # Names of ROB variables included in 'data'   domains = c(\"sg\", \"ac\", \"ba\", \"itt\"),   # Long-format labels for each ROB domain   domain.names = c(\"Sequence Generation\",                     \"Allocation Concealment\",                     \"Blinding of Assessors\",                     \"ITT Analyses\"),   # Codes used to rate the risk of bias (sr=self-report)   categories = c(\"0\", \"1\", \"sr\"),   # Symbols that should be used for these codes in forest plots   symbols = c(\"-\", \"+\", \"s\"),   # Colors to be used in forest plots for each of these codes   colors = c(\"red\", \"green\", \"yellow\"))  # Re-run model with appended ROB data res = runMetaAnalysis(data, rob.data = robData)   # Generate forest plot with ROB data plot(res, \"combined\")  # Create a summary plot createRobSummary(res,                   name.low = \"1\",                   name.high = \"0\",                   name.unclear = \"sr\",                  which.run = \"combined\")  # Run meta-analysis using raw response rate data data %>%    runMetaAnalysis(es.measure = \"RR\",                   es.type = \"raw\") }"},{"path":"/reference/selectArguments.html","id":null,"dir":"Reference","previous_headings":"","what":"Select available arguments in function — selectArguments","title":"Select available arguments in function — selectArguments","text":"Select available arguments function","code":""},{"path":"/reference/selectArguments.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Select available arguments in function — selectArguments","text":"","code":"selectArguments(f, dots)"},{"path":"/reference/selectOutlierModel.html","id":null,"dir":"Reference","previous_headings":"","what":"Select which model should be used for outliers analysis — selectOutlierModel","title":"Select which model should be used for outliers analysis — selectOutlierModel","text":"Select model used outliers analysis","code":""},{"path":"/reference/selectOutlierModel.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Select which model should be used for outliers analysis — selectOutlierModel","text":"","code":"selectOutlierModel(which.run, mGeneral, mComb, which.outliers)"},{"path":"/reference/sendMessage.html","id":null,"dir":"Reference","previous_headings":"","what":"Send message after fitting model — sendMessage","title":"Send message after fitting model — sendMessage","text":"Send message fitting model","code":""},{"path":"/reference/sendMessage.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Send message after fitting model — sendMessage","text":"","code":"sendMessage(   obj,   model.name = NULL,   which.run = NULL,   .type.es = NULL,   es.type = NULL )"},{"path":"/reference/setColnames.html","id":null,"dir":"Reference","previous_headings":"","what":"Set colnames — setColnames","title":"Set colnames — setColnames","text":"Set colnames","code":""},{"path":"/reference/setColnames.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Set colnames — setColnames","text":"","code":"setColnames(x, value)"},{"path":"/reference/subgroupAnalysis.html","id":null,"dir":"Reference","previous_headings":"","what":"Run subgroup analyses — subgroupAnalysis","title":"Run subgroup analyses — subgroupAnalysis","text":"function allows simultaneously conduct different subgroup analyses using runMetaAnalysis objects.","code":""},{"path":"/reference/subgroupAnalysis.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Run subgroup analyses — subgroupAnalysis","text":"","code":"subgroupAnalysis(.model,                  ...,                  .which.run = .model$which.run[1],                  .round.digits = 2,                  .nnt.cer = NULL,                  .tau.common = FALSE,                  .html = TRUE)"},{"path":"/reference/subgroupAnalysis.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Run subgroup analyses — subgroupAnalysis","text":".model object class \"runMetaAnalysis\", created runMetaAnalysis. ... <dplyr_data_masking>. number subgroup variables included original dataset provided runMetaAnalysis, separated commas. ..run model .model used subgroup analyses. Uses default analysis .model value specified user. .round.digits numeric. Number digits round (presented) results . Default 2. .nnt.cer numeric. Value 0 1, indicating assumed control group event rate used calculating NNTs via Furukawa-Leucht method. set NULL (default), value saved .model (re-)used. .tau.common logical. common (TRUE) subgroup-specific (FALSE) estimate -study heterogeneity calculated analyzing subgroups? FALSE default. Note subgroup analyses based \"multilevel\" models automatically assume common heterogeneity estimates. .html logical. HTML table created results? Default TRUE.","code":""},{"path":"/reference/subgroupAnalysis.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Run subgroup analyses — subgroupAnalysis","text":"Returns object class \"subgroupAnalysis\". object includes, among things, data.frame name summary, subgroup analysis results summarized. objects \"raw\" subgroup analysis model objects returned. allows conduct operations subgroup analysis specifically.","code":""},{"path":"/reference/subgroupAnalysis.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Run subgroup analyses — subgroupAnalysis","text":"details see Get Started vignette.","code":""},{"path":[]},{"path":"/reference/subgroupAnalysis.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Run subgroup analyses — subgroupAnalysis","text":"Mathias Harrer mathias.h.harrer@gmail.com, Paula Kuper paula.r.kuper@gmail.com, Pim Cuijpers p.cuijpers@vu.nl","code":""},{"path":"/reference/subgroupAnalysis.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Run subgroup analyses — subgroupAnalysis","text":"","code":"if (FALSE) { data(\"depressionPsyCtr\")  depressionPsyCtr %>%   checkDataFormat() %>%   checkConflicts() %>%   calculateEffectSizes() %>%    filterPoolingData(condition_arm2 %in%                        c(\"wl\", \"other ctr\")) -> data  # Run the meta-analyses runMetaAnalysis(data) -> res  # Subgroup analysis subgroupAnalysis(res, condition_arm2, country,                  .which.run = \"combined\",                  .tau.common = TRUE) -> sg plot(sg, \"condition_arm2\") plot(sg, \"country\") }"},{"path":"/reference/summary.runMetaAnalysis.html","id":null,"dir":"Reference","previous_headings":"","what":"Show details of 'runMetaAnalysis' class objects — summary.runMetaAnalysis","title":"Show details of 'runMetaAnalysis' class objects — summary.runMetaAnalysis","text":"S3 method showing analysis settings objects class runMetaAnalysis.","code":""},{"path":"/reference/summary.runMetaAnalysis.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Show details of 'runMetaAnalysis' class objects — summary.runMetaAnalysis","text":"","code":"# S3 method for runMetaAnalysis summary(object, forest = TRUE, ...)"},{"path":"/reference/summary.runMetaAnalysis.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Show details of 'runMetaAnalysis' class objects — summary.runMetaAnalysis","text":"object object class runMetaAnalysis. forest logical. summary forest plot returned? TRUE default. ... Additional arguments.","code":""},{"path":"/reference/summary.runMetaAnalysis.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Show details of 'runMetaAnalysis' class objects — summary.runMetaAnalysis","text":"Mathias Harrer mathias.h.harrer@gmail.com, Paula Kuper paula.r.kuper@gmail.com, Pim Cuijpers p.cuijpers@vu.nl","code":""},{"path":"/reference/testBaselineImbalance.html","id":null,"dir":"Reference","previous_headings":"","what":"Test for baseline imbalances — testBaselineImbalance","title":"Test for baseline imbalances — testBaselineImbalance","text":"function returns SMD baseline imbalance tests, along 99% confidence intervals. cluster argument specified, p-values can adjusted using methods available stats::p.adjust().","code":""},{"path":"/reference/testBaselineImbalance.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Test for baseline imbalances — testBaselineImbalance","text":"","code":"testBaselineImbalance(   m_arm1,   m_arm2,   sd_arm1,   sd_arm2,   n_arm1,   n_arm2,   cluster,   study,   data = NULL,   p.adj = \"holm\",   ... )"},{"path":"/reference/testBaselineImbalance.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Test for baseline imbalances — testBaselineImbalance","text":"m_arm1 vector baseline mean(s) first arm. m_arm2 vector baseline mean(s) second arm. sd_arm1 vector baseline standard deviation(s) first arm. sd_arm2 vector baseline standard deviation(s) second arm. n_arm1 vector baseline sample size(s) first arm. n_arm2 vector baseline sample size(s) second arm. cluster optional vector length m_arm1, m_arm2, etc., encoding larger cluster/study comparison belongs . specified, p values comparisons adjusted according method provided p.adj argument. study optional vector study labels. data optional data.frame includes effect size data. p.adj character string, specifying type p-value adjustment. available options, see \"Details\" section stats::p.adjust(). Defaults \"holm\". ... Additional arguments.","code":""},{"path":"/reference/testBaselineImbalance.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Test for baseline imbalances — testBaselineImbalance","text":"","code":"if (FALSE) { # Load example data that follows the Metapsy data standard data(\"depressionPsyCtr\")  # This is an unexported function, so we need the metapsyTools::: prefix # Test for differences without p-value adjustment metapsyTools:::testBaselineImbalance(   bl_mean_arm1, bl_mean_arm2,    bl_sd_arm1, bl_sd_arm2,    bl_n_arm1, bl_n_arm2,    data = depressionPsyCtr,   study = study)  # Provide cluster variable: p-values are adjusted within clusters metapsyTools:::testBaselineImbalance(   bl_mean_arm1, bl_mean_arm2,    bl_sd_arm1, bl_sd_arm2,    bl_n_arm1, bl_n_arm2,    data = depressionPsyCtr,   cluster = study,   study = study)  # Change adjustment method metapsyTools:::testBaselineImbalance(   bl_mean_arm1, bl_mean_arm2,    bl_sd_arm1, bl_sd_arm2,    bl_n_arm1, bl_n_arm2,    data = depressionPsyCtr,   cluster = study,   study = study, p.adj = \"bonferroni\") }"},{"path":"/reference/testRandomizedProportion.html","id":null,"dir":"Reference","previous_headings":"","what":"Test if the randomized proportion differs from the original allocation ratio — testRandomizedProportion","title":"Test if the randomized proportion differs from the original allocation ratio — testRandomizedProportion","text":"function returns one-sample proportion test allows examine included sample study deviated significantly form intended allocation ratio.","code":""},{"path":"/reference/testRandomizedProportion.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Test if the randomized proportion differs from the original allocation ratio — testRandomizedProportion","text":"","code":"testRandomizedProportion(   n_arm1,   n_arm2,   study,   data = NULL,   ratio = \"1:1\",   ... )"},{"path":"/reference/testRandomizedProportion.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Test if the randomized proportion differs from the original allocation ratio — testRandomizedProportion","text":"n_arm1 vector sample size first trial arm stored. n_arm2 vector sample size second trial arm stored. study optional vector study labels. data optional data.frame sample size data included. ratio single string character vector expected allocation ratio. ratio separated colon, e.g. \"1:3, left side indicates first trial arm (n_arm1) right side indicates second trial arm (n_arm2). Defaults \"1:1. ... Additional arguments.","code":""},{"path":"/reference/testRandomizedProportion.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Test if the randomized proportion differs from the original allocation ratio — testRandomizedProportion","text":"","code":"if (FALSE) { # Load example data that follows the Metapsy data standard data(\"depressionPsyCtr\")  # This is an unexported function, so we need the metapsyTools::: prefix # Test if all studies follow the 1:1 allocation ratio metapsyTools:::testRandomizedProportion(   n_arm1, n_arm2, data = depressionPsyCtr, study = study)   # Provide a comparison-specific allocation ratio ratio <- c(\"1:1\", \"3:1\", \"4:5\") metapsyTools:::testRandomizedProportion(   n_arm1, n_arm2, data = depressionPsyCtr[1:3,],    study = study, ratio = ratio)  }"},{"path":"/reference/tryCatch2.html","id":null,"dir":"Reference","previous_headings":"","what":"tryCatch alternative that saves the error message — tryCatch2","title":"tryCatch alternative that saves the error message — tryCatch2","text":"tryCatch alternative saves error message Try function catch errors","code":""},{"path":"/reference/tryCatch2.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"tryCatch alternative that saves the error message — tryCatch2","text":"","code":"tryCatch2(expr)  tryCatch2(expr)"},{"path":"/reference/tryCatch2.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"tryCatch alternative that saves the error message — tryCatch2","text":"expr R expression.","code":""},{"path":"/reference/updateMeta.html","id":null,"dir":"Reference","previous_headings":"","what":"Import 'update.meta' for internal use — updateMeta","title":"Import 'update.meta' for internal use — updateMeta","text":"function imports update.meta function meta package, ceased exported function since version 7.0-0.","code":""},{"path":"/reference/updateMeta.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Import 'update.meta' for internal use — updateMeta","text":"","code":"updateMeta(...)"},{"path":"/reference/updateMeta.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Import 'update.meta' for internal use — updateMeta","text":"... Arguments forwarded update.meta.","code":""}]
