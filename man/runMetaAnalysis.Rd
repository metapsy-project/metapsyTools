% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/runMetaAnalysis.R
\name{runMetaAnalysis}
\alias{runMetaAnalysis}
\title{Run different types of meta-analyses}
\usage{
runMetaAnalysis(data,
                which.run = c("overall", "combined",
                              "lowest.highest", "outliers",
                              "influence", "rob", "threelevel",
                              "threelevel.che"),
                es.measure = c("g", "RR"),
                es.type = c("precalculated", "raw"),
                es.var = ifelse(identical(es.measure[1], "g"), 
                                ".g", ".log_rr"),
                se.var = ifelse(identical(es.measure[1], "g"), 
                                ".g_se", ".log_rr_se"),
                es.binary.raw.vars = 
                  c(".event_arm1", ".event_arm2",
                    ".totaln_arm1", ".totaln_arm2"),
                method.tau = "REML",
                hakn = TRUE,
                study.var = "study",
                extra.grouping.var = NULL,
                arm.var.1 = "condition_arm1",
                arm.var.2 = "condition_arm2",
                measure.var = "instrument",
                low.rob.filter = "rob > 2",
                method.tau.ci = "Q-Profile",
                round.digits = 2,
                which.outliers = c("overall", "combined"),
                which.influence = c("overall", "combined"),
                which.rob = c("overall", "combined"),
                nnt.cer = 0.2,
                rho.within.study = 0.5,
                use.rve = TRUE,
                html = TRUE,
                ...)
}
\arguments{
\item{data}{\code{data.frame}. Effect size data in the wide format, as
created by \code{\link{calculateEffectSizes}}.}

\item{which.run}{\code{character}. Selection of models to be calculated.
See 'Details'.}

\item{es.measure}{\code{character}. Should meta-analyses be calculated using the
bias-corrected standardized mean difference (\code{"g"}; default), or using
risk ratios (\code{"RR"})? Meta-analyses will only be conducted using comparisons
that contain non \code{NA} values in the \code{es.var} and \code{se.var} columns.}

\item{es.type}{\code{character}. Should pre-calculated or raw event data (i.e.
the Mantel-Haenszel method) be used for meta-analyses of risk ratios?
Can be set to \code{"precalculated"} (default) or \code{"raw"}.}

\item{es.var}{\code{character}. Specifies the name of the variable containing the (pre-
calculated) effect size data in \code{data}. When \code{es.measure = "g"}, this is set to
\code{.g} by default; \code{".log_rr"} is used when \code{es.measure = "RR"}. The default settings
correspond with the standard output of \code{\link[=calculateEffectSizes]{calculateEffectSizes()}}.}

\item{se.var}{\code{character}. Specifies the name of the variable containing the (pre-calculated)
standard errors (square root of the variance) of the effect size metric defined
in \code{es.var}. If \code{es.measure = "g"}, this is automatically set to \code{.g_se}; if
\code{es.measure = "RR"}, \code{".log_rr_se"} is used. The default settings
correspond with the standard output of \code{\link[=calculateEffectSizes]{calculateEffectSizes()}}.}

\item{es.binary.raw.vars}{\code{character} vector, defining the column names in
which the (1) raw event counts in the experimental group, (2) raw event counts in the
control/reference group, (3) sample size in the experimental group, and (4) sample size
of the control/reference group are stored.
Defaults correspond with the standard output of \code{\link[=calculateEffectSizes]{calculateEffectSizes()}}.}

\item{method.tau}{\code{character}. A character string indicating
which method is used to estimate the between-study variance (tau-squared)
and its square root (tau). Either \code{"REML"} (default), \code{"DL"},
\code{"PM"}, \code{"ML"}, \code{"HS"}, \code{"SJ"}, \code{"HE"}, or \code{"EB"}, can be abbreviated (see
\code{\link[meta]{metagen}}). Use \code{"FE"} to use a fixed-effect/"common effect" model.}

\item{hakn}{\code{logical}. Should the Knapp-Hartung adjustment for effect size significance tests be used? Default is \code{TRUE}.}

\item{study.var}{\code{character}. The name of the variable in \code{data} in which the study IDs are stored.}

\item{extra.grouping.var}{\code{character}. Additional grouping variable within studies to be used for the \code{"combined"}
analysis. This is useful, for example, to \emph{not} pool the effects of different treatment arms within multi-arm trials.
\code{NULL} by default.}

\item{arm.var.1}{\code{character}. The name of the variable in \code{data} in which the condition (e.g. "guided iCBT")
of the \emph{first} arm within a comparison are stored.}

\item{arm.var.2}{\code{character}. The name of the variable in \code{data} in which the condition (e.g. "wlc")
of the \emph{second} arm within a comparison are stored.}

\item{measure.var}{\code{character}. The name of the variable in \code{data}
in which the instrument used for the comparison is stored.}

\item{low.rob.filter}{\code{character}. A filtering statement by which to
include studies for the "low RoB only" analysis. Please note that the name of
the variable must be included as a column in \code{data}.}

\item{method.tau.ci}{\code{character}. A character string indicating which method is used to estimate the
confidence interval of tau/tau-squared. Either \code{"Q-Profile"} (default and recommended),
\code{"BJ"}, \code{"J"}, or \code{"PL"} can be abbreviated. See \code{\link[meta]{metagen}} for details.}

\item{round.digits}{\code{numeric}. Number of digits to round the (presented) results by. Default is \code{2}.}

\item{which.outliers}{\code{character}. Which model should be used to conduct outlier analyses? Must be
\code{"overall"} or \code{"combined"}, with \code{"overall"} being the default.}

\item{which.influence}{\code{character}. Which model should be used to conduct influence analyses? Must be
\code{"overall"} or \code{"combined"}, with \code{"overall"} being the default.}

\item{which.rob}{\code{character}. Which model should be used to conduct the "low risk of bias only" analyses? Must be
\code{"overall"} or \code{"combined"}, with \code{"overall"} being the default.}

\item{nnt.cer}{\code{numeric}. Value between 0 and 1, indicating the assumed control group event rate to be used
for calculating NNTs via the Furukawa-Leucht method.}

\item{rho.within.study}{\code{numeric}. Value between 0 and 1, indicating the assumed correlation of effect sizes
within studies. This is relevant to combine effect sizes for the \code{"combined"} analysis type, and used to estimate
the variance-covariance matrices needed for the conditional and hierarchical effects three-level model. Default is \code{0.5}.}

\item{use.rve}{\code{logical}. Should robust variance estimation be used to calculate confidence intervals and tests of three-level models?
\code{TRUE} by default.}

\item{html}{\code{logical}. Should an HTML table be created for the results? Default is \code{TRUE}.}

\item{...}{Additional arguments.}
}
\value{
Returns an object of class \code{"runMetaAnalysis"}. This object includes, among other things,
a \code{data.frame} with the name \code{summary}, in which all results are summarized - including the
studies which were removed for some analysis steps. Other objects are the "raw" model objects returned
by all selected analysis types. This allows to conduct further operations on some models specifically (e.g.
run a meta-regression by plugging one of the model objects in \code{update.meta}.
}
\description{
This wrapper function allows to simultaneously pool effect sizes using
different meta-analytic approaches.
}
\details{
The \code{runMetaAnalysis} function is a wrapper for several types of meta-analytic models
that are typically used. It allows to run all of these models in one step in order to generate results
that are somewhat closer to being "publication-ready".

By default, the following models are calculated:

\itemize{
\item \code{"overall"}. Runs a generic inverse-variance (random-effects) model. All included
effect sizes are treated as independent. When \code{es.measure = "RR"} and \code{es.type = "raw"},
the Mantel-Haenszel method is used for pooling instead.
\item \code{"combined"}. Pools all effect sizes within one study (defined by \code{study.var}) before
pooling. This ensures that all effect sizes are independent (i.e., unit-of-analysis error &
double-counting is avoided). To combine the effects, one has to assume a correlation of effect sizes
within studies, empirical estimates of which are typically not available.
\item \code{"lowest.highest"}. Runs a meta-analysis, but with only (i) the lowest and (ii) highest
effect size within each study included.
\item \code{"outlier"}. Runs a meta-analysis without statistical outliers (i.e. effect sizes for which
the confidence interval does not overlap with the confidence intervall of the overall effect).
\item \code{"influence"}. Runs a meta-analysis without influential cases (see \code{\link[metafor]{influence.rma.uni}} for
details).
\item \code{"rob"}. Runs a meta-analysis with only low-RoB studies included.
\item \code{"threelevel"}. Runs a multilevel (three-level) meta-analysis model, with effect sizes nested
in studies.
\item \code{"threelevel.che"}. Runs a multilevel (three-level) meta-analysis model, with effect sizes nested
in studies. Variance-covariance matrices of each study with two or more effect sizes are estimated using
\code{rho.within.study} as the assumed overall within-study correlation. This imputation allows to run a "correlated and
hierarchical effects" (CHE) model, which is typically a good approximation for data sets with unknown and/or
complex dependence structures.
}
For more details see the \href{https://tools.metapsy.org/articles/metapsytools}{Get Started} vignette.
}
\examples{
\dontrun{
data("depressionPsyCtr")
library(meta)

depressionPsyCtr \%>\%
  checkDataFormat() \%>\%
  checkConflicts() \%>\%
  calculateEffectSizes() \%>\% 
  filterPoolingData(condition_arm2 \%in\% 
                      c("wl", "other ctr")) -> data

# Run the meta-analyses
runMetaAnalysis(data) -> res

# Show summary
res

# Show forest plot (by default, "overall" is used)
plot(res)

# Show forest plot of specific analysis
plot(res, "outliers")
plot(res, "threelevel")
plot(res, "baujat")
plot(res, "influence")
plot(res, "lowest.highest")

# Extract specific model and do further calculations
# (e.g. meta-regression on 'year')
metaRegression(res$model.overall, ~ scale(year))

# Conduct a subgroup analysis
subgroupAnalysis(res, country)

# Correct for publication bias/small-study effects
correctPublicationBias(res)

# For the combined analysis, we provide an extra variable to
# 'extra.grouping.var' so that different treatment arm 
# comparisons in multiarm trials are NOT pooled
data \%>\% 
  runMetaAnalysis(extra.grouping.var = "condition_arm1") \%>\% 
  plot("combined")

# Run meta-analysis using raw response rate data
data \%>\% 
  runMetaAnalysis(es.measure = "RR",
                  es.type = "raw")
}

}
\seealso{
\code{\link{calculateEffectSizes}},
\code{\link{subgroupAnalysis}}. \code{\link{correctPublicationBias}},
\code{\link{metaRegression}}
}
\author{
Mathias Harrer \email{mathias.h.harrer@gmail.com},
Paula Kuper \email{paula.r.kuper@gmail.com}, Pim Cuijpers \email{p.cuijpers@vu.nl}
}
